---
title: "Minimal groups analysis"
author: "Matt Jaquiery (matt.jaquiery@psy.ox.ac.uk)"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
  html_notebook:
    includes:
      after_body: ../src/toc_menu.html
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: inline
---

July 2019

[Script run `r Sys.time()`]


```{r prematter, include = F}

library(testthat)

library(tidyverse)

library(BayesFactor)
library(BayesMed)

library(prettyMD)

# opts_chunk$set('echo' = F)

set.seed(20190723)

# Plot setup
theme_set(theme_light() + 
            theme(panel.grid.major.x = element_blank()))

```

## Load data

```{r loadData}

studyVersion <- "1-0-0"
studyName <- "minGroups"

exclude <- list(maxAttnCheckFails = 0, # pass all attn checks
                requireComplete = T,   # complete experiment
                maxTrialRT = 60000,    # trials take < 1 minute
                minTrials = 11,        # at least 11 trials completed
                minChangeRate = .1,    # some advice taken on 10%+ of trials
                participantOutliers = data.frame(
                  varName = c("timeEnd", "responseError", "responseCorrect"),
                  zThresh = 3),        # |z-score| for these variables < 3
                multipleAttempts = T)  # exclude multiple attempts

skipLoadData <- F

source("src/02 Exclusions.R")

```

## Exclusions

```{r exclusions}

tmp <- suppressWarnings(left_join(exclusions, okayIds, by = "pid"))

tmp$condition <- factor(tmp$condition, labels = c("colourB_InFirst",
                                                  "colourB_OutFirst",
                                                  "colourA_InFirst",
                                                  "colourA_OutFirst"))

table(tmp$excluded, tmp$condition)

```

Our final participant list consists of `r length(unique(PP$pid))` participants who completed an average of `r num2str(mean(aggregate(number ~ pid, PP, function(x) sum(x) / 2)$number))` trials each.

## Task performance

```{r bindAdvisors}

# bind feedback property from participants
advisors <- advisors[advisors$pid %in% PP$pid, ]
advisors <- left_join(advisors, unique(PP[c("pid", "feedback")]), "pid")

# drop practice advisors
advisors <- advisors[advisors$idDescription != "Practice", ]

```

First we offer a characterisation of the task, to provide the reader with a sense of how the participants performed. 

### Decisions

Participants offered estimates of the year in which various events took place. The correct answers were always between 1900 and 2000, although the timeline on which participants responded went from 1890 to 2010 in order to allow extra room for advice. Participants answered by dragging a marker onto a timeline which covered a range of 11 years (e.g. 1940-1950). Participants were informed that a correct answer was one in which the marker covered the year in which the event took place.

#### Correctness

Responses are regarded as **correct** if the target year is included within the marker range.

```{r accuracy}

tmp <- markerBreakdown(responseCorrect, decisions)
num2str.tibble(tmp$first, isProportion = T, precision = 3)
num2str.tibble(tmp$last, isProportion = T, precision = 3)

```

```{r accuracyGraph}

ggplot(aggregate(responseCorrect ~ 
                   responseMarker + decision + pid,
                 decisions, mean), 
       aes(x = decision, y = responseCorrect)) +
  geom_violin(alpha = .25, colour = NA, fill = "grey75") +
  geom_boxplot(fill = NA, outlier.color = NA) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5) +
  scale_linetype_manual(values = c("dashed")) + 
  labs(x = "response marker width (years)", 
       y = "p(response correct)")

```

#### Error (estimate mean)

The **error** is calcualted as the distance from the centre of the answer marker to the correct year. It is thus possible for **correct** answers to have non-zero error, and it is likely that the error for correct answers scales with the marker size.

```{r err}

tmp <- markerBreakdown(responseError, decisions)
num2str.tibble(tmp$first)
num2str.tibble(tmp$last)

```

```{r errGraph}

ggplot(aggregate(responseError ~ 
                   responseMarker + decision + pid,
                 decisions, mean), 
       aes(x = decision, y = responseError)) +
  geom_violin(alpha = .25, colour = NA, fill = "grey75") +
  geom_boxplot(fill = NA, outlier.color = NA) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5) +
  scale_linetype_manual(values = c("dashed")) + 
  labs(x = "response marker width (years)", 
       y = "|target - response marker centre| (years)")

```

### Timing

We can look at the response time - the difference between the time the response is opened and the time the response is received.  

```{r time}

decisions$rt <- decisions$responseTimeEstimate - decisions$timeResponseOpen

tmp <- markerBreakdown(rt, decisions)
num2str.tibble(tmp$first)
num2str.tibble(tmp$last)

```

```{r timeGraph}

ggplot(aggregate(rt ~ 
                   responseMarker + decision + pid,
                 decisions, mean), 
       aes(x = decision, 
           y = rt / 1000)) +
  geom_violin(alpha = .25, colour = NA, fill = "grey75") +
  geom_boxplot(fill = NA, outlier.color = NA) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5) +
  scale_linetype_manual(values = c("dashed")) + 
  labs(x = "response marker width (years)", 
       y = "response time (s)")

```

## Advisor performance

The advice offered should be equivalent between in/out group advisors.

### Accuracy

```{r adviceAccuracy}

tmp <- NULL
for (a in advisorNames) {
  eq <- as.formula(paste0("cbind(", a, ".accurate, ", 
                          a, ".error) ~ pid"))
  r <- aggregate(eq, AdvisedTrial, mean, na.rm = T)
  
  colnames(r) <- c("pid", "accuracy", "error")
  r$advisor = a
  
  tmp <- rbind(tmp, as.tibble(r))
}

prop2str(as.tibble(aggregate(cbind(accuracy, error) ~ advisor, 
                             tmp, 
                             mean, na.rm = T)), 
         precision = 3)

```

```{r adviceAccuracyGraph}

for (v in unique(tmp$var)) 
  print(
    ggplot(tmp[tmp$var == v, ], aes(x = advisor, y = value, colour = pid)) +
      geom_violin(colour = NA, fill = "grey75", alpha = .25) +
      geom_boxplot(outlier.colour = NA, fill = NA, aes(group = advisor)) +
      geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
      geom_point(alpha = .5, aes(colour = pid)) +
      stat_summary(geom = "line", fun.y = mean,
                   aes(group = 1, linetype = "mean"), size = 1.5) +
      labs(y = v)
  )

```

### Agreement

```{r adviceAgreement}

tmp <- NULL
for (a in advisorNames) {
  eq <- as.formula(paste0(a, ".agree ~ pid"))
  r <- aggregate(eq, AdvisedTrial, mean, na.rm = T)
  
  colnames(r) <- c("pid", "agreement")
  r$advisor <- a
  tmp <- rbind(tmp, r)
}

prop2str(as.tibble(aggregate(agreement ~ advisor, 
                             tmp, mean, na.rm = T)), 
         precision = 3)

```

```{r adviceAgreementGraph}

ggplot(tmp, aes(x = advisor, y = agreement, colour = pid)) +
  geom_violin(colour = NA, fill = "grey75", alpha = .25) +
  geom_boxplot(outlier.colour = NA, fill = NA, aes(group = advisor)) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5)

```

### Distance

Distance is the continuous version of agreement - the difference between the centre of the advice and the centre of the initial estimate. 

```{r adviceDistance}

tmp <- NULL
for (a in advisorNames) {
  eq <- as.formula(paste0(a, ".distance ~ pid"))
  r <- aggregate(eq, AdvisedTrial, mean, na.rm = T)
  
  colnames(r) <- c("pid", "distance")
  r$advisor = a
  
  tmp <- rbind(tmp, as.tibble(r))
}

prop2str(as.tibble(aggregate(distance ~ advisor, 
                             tmp, 
                             mean, na.rm = T)), 
         precision = 3)

```

```{r adviceDistanceGraph}

ggplot(tmp, aes(x = advisor, y = distance, colour = pid)) +
  geom_violin(colour = NA, fill = "grey75", alpha = .25) +
  geom_boxplot(outlier.colour = NA, fill = NA, aes(group = advisor)) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5)

```

### Influence

The measure of influence is weight-on-advice. This is well-defined for values between 0 and 1 (trucated otherwise), and is
$$\text{WoA} = (\text{final} - \text{inital}) / (\text{advice} - \text{initial})$$
, or the degree to which the final decision moves towards the advised answer.

Influence is the primary outcome measure, and is thus expected to differ between advisors and feedback conditions.

```{r woa}

tmp <- NULL
for (a in advisorNames) {
  eq <- as.formula(paste0(a, ".woa ~ pid"))
  r <- aggregate(eq, AdvisedTrial, mean, na.rm = T)
  
  colnames(r) <- c("pid", "WoA")
  r$advisor <- a
  tmp <- rbind(tmp, r)
}

prop2str(as.tibble(aggregate(WoA ~ advisor, tmp, mean, na.rm = T)), 
         precision = 3)

```

```{r woaGraph}

ggplot(tmp, aes(x = advisor, y = WoA, colour = pid)) +
  geom_violin(colour = NA, fill = "grey75", alpha = .25) +
  geom_boxplot(outlier.colour = NA, fill = NA, aes(group = advisor)) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5)

```

##### WoA distribution

It's good to keep a general eye on the distribution of weight-on-advice on a trial-by-trial basis. 

```{r woaDistribution}

ggplot(AdvisedTrial, aes(woa)) + 
  geom_histogram(stat = "count") +
  facet_grid(feedback ~ advisor0idDescription, labeller = label_both)

```

## Questionnaire data

```{r questionnaires}

tmp <- debrief.advisors[debrief.advisors$pid %in% AdvisedTrial$pid, ]
for (i in seq(nrow(tmp))) {
  tmp$sameGroup[i] <- as.character(
    advisors$idDescription[advisors$pid == tmp$pid[i] &
                             advisors$id == tmp$advisorId[i]])
}

tmp <- gather(tmp, key = "Q", value = "rating", 
              c("knowledge", "helpfulness", "consistency", "trustworthiness"))

ggplot(tmp, aes(x = sameGroup, y = rating)) +
  geom_violin(colour = NA, fill = "grey75", alpha = .25) +
  geom_boxplot(outlier.colour = NA, fill = NA, aes(group = advisor)) +
  geom_line(alpha = .5, aes(colour = pid, group = pid)) + 
  geom_point(alpha = .5, aes(colour = pid)) +
  stat_summary(geom = "line", fun.y = mean,
               aes(group = 1, linetype = "mean"), size = 1.5) +
  facet_wrap(. ~ Q, labeller = label_both)

```

## Hypothesis testing

The hypotheses being tested here are:  

1. Participants will place higher weight on the advice of in-group advisors
  
2. Participants weighting of advisors by group will be mediated by reports of perceived advisor benevolence

### Group differences

Participants have different weight-on-advice for ingroup as opposed to outgroup advisors.

```{r h1, results='asis'}

tmp <- aggregate(inGroup.woa ~ pid, AdvisedTrial, mean, na.rm = T)
tmp$outGroup.woa <- 
  aggregate(outGroup.woa ~ pid, AdvisedTrial, mean, na.rm = T)$outGroup.woa

r <- md.ttestBF(tmp$inGroup.woa, tmp$outGroup.woa, 
              c("*M*|inGroup", "*M*|outGroup"), paired = T)
cat(r)

```

### Mediation by benevolence

```{r h2, results='asis'}

tmp <- aggregate(advisor0woa ~ pid + advisor0idDescription + advisor0id, 
                 AdvisedTrial, mean, na.rm = T)
names(tmp) <- c("pid", "sameGroup", "id", "WoA")

for (i in seq(nrow(tmp))) {
  tmp$benevolence[i] <- debrief.advisors$helpfulness[
    debrief.advisors$pid %in% tmp$pid[i] &
      debrief.advisors$advisorId %in% tmp$id[i]
  ]
}

jzs_med(independent = tmp$sameGroup, 
        dependent = tmp$WoA, 
        mediator = tmp$benevolence, 
        standardize = T)

```

## Credits 

### Acknowledgements

Thanks as always to Nick Yeung and the other folks at the [ACC Lab](https://www.psy.ox.ac.uk/research/attention-cognitive-control-lab).

### R Packages

```{r results = 'asis'}
# list packages
packageNames <- (.packages())
# don't include very core package
packageNames <- packageNames[!(packageNames %in% 
                                 rownames(installed.packages(
                                   priority = "base")))]
# but do include the base package
packageNames <- c("base", packageNames)
out <- NULL
for (p in packageNames) {
  out <- rbind(out, data.frame('Package' = p, 
                               'Citations' = paste(format(citation(p), 
                                                          style = 'textVersion'), 
                                                   collapse = '<br/><br/>')))
}

kable(out)
```

### Funding

Matt Jaquiery is funded by a studentship from the [Medical Research Council](https://mrc.ukri.org/) (reference 1943590) and the University of Oxford [Department of Experimental Psychology](https://www.psy.ox.ac.uk/) (reference 17/18_MSD_661552).

### Technical details  

```{r results = 'hold'}
cat(paste('Time stamp:', Sys.time(), '\n\n'))
cat('Runtime \n')
proc.time()
cat('\n')
sessionInfo()
```