}
# analyse(multiverse[[length(multiverse)]], datafile = cleanDataFile, scriptfile = scriptFile)
# Run in parallel
nCores <- detectCores() - 2
cl <- makeCluster(nCores)
# clusterApply(cl, multiverse[length(multiverse)], fun = analyse, datafile = cleanDataFile, scriptfile = scriptFile)
clusterApply(cl, multiverse[length(multiverse)], fun = analyse, datafile = cleanDataFile, scriptfile = scriptFile)
#' Run the ANOVA
#' @param exclusions dataframe of exclusion options
#' @param datafile file containing the workspace to use
#' @param scriptfile file contianing the exclusions script
#' @param studyVersion version of the study being examined
#'
#' @return list
#' incompleteCases - cases dropped due to incompleteness
#' n - number of cases included
#' ANOVA - ANOVA results dataframe
analyse <- function(exclude, datafile, scriptfile, studyVersion) {
load(datafile)
results <- list(exclude = exclude, studyVersion = studyVersion)
# hoist variables
assign("skipLoadData", T, .GlobalEnv)
for (v in ls()) {
assign(v, get(v), .GlobalEnv)
}
# run exclusions
source(scriptfile)
offBrand <- AdvisedTrial[AdvisedTrial$advisor0offBrand == T, ]
df <- aggregate(advisor0woa ~
pid + feedback + advisor0idDescription + firstAdvisor,
offBrand, mean, na.rm = T)
df$feedback <- factor(df$feedback)
x <- 0
# remove incomplete cases
for (p in unique(df$pid)) {
if (nrow(df[df$pid == p, ]) != 2) {
x <- x + 1
df <- df[df$pid != p, ]
}
}
results$incompleteCases <- x
results$n <- length(unique(df$pid))
# refactor pid
df$pid <- factor(df$pid)
r <- suppressWarnings(
ez::ezANOVA(df, advisor0woa, pid,
within = advisor0idDescription,
between = list(feedback, firstAdvisor),
detailed = F,
type = 2)
)
results$ANOVA <- r$ANOVA
results
}
clusterApply(cl, multiverse[length(multiverse)], fun = analyse, datafile = cleanDataFile, scriptfile = scriptFile)
startTime <- Sys.time()
results <- clusterApply(cl, multiverse,
fun = analyse,
datafile = cleanDataFile,
scriptfile = scriptFile)
trials <- tmp[, c("pid", "dotDifference", "correctAnswer",
"initialAnswer", "initialConfidence",
"timeInitialStimOn", "timeInitialStimOff",
"timeInitialResponse",
"initialCorrect", "practice",
"id", "block", "folderName")]
trials$subjectId <- as.numeric(as.factor(trials$pid))
# Joshua's confidence database format ---------------------------------------
# separate by experiment name
ex <- list()
for (n in unique(trials$folderName))
ex[[n]] <- trials[trials$folderName == n, ]
source('./adviceUsage.R')
# drop unwanted columns
trials <- tmp[, c("pid", "dotDifference", "correctAnswer",
"initialAnswer", "initialConfidence",
"timeInitialStimOn", "timeInitialStimOff",
"timeInitialResponse",
"initialCorrect", "practice",
"id", "block", "folderName")]
trials$subjectId <- as.numeric(as.factor(trials$pid))
# Joshua's confidence database format ---------------------------------------
# separate by experiment name
ex <- list()
for (n in unique(trials$folderName))
ex[[n]] <- trials[trials$folderName == n, ]
names(ex)
unique(as.numeric(trials$pid))
unique(as.numeric(factor(trials$pid)))
unique(as.numeric(factor(trials$pid[2000])))
unique(as.numeric(factor(trials$pid[10000])))
trials$pid <- as.numeric(as.factor(trials$pid))
nrow(ex)
length(ex)
nrow(df)
df <- ex[[1]]
nrow(df)
trial <- df[1, ]
x <- 1
i <- 1
trial <- df[x, ]
unique(df$initialConfidence)
range(df$timeInitialResponse)
i <- 0
Datasets <- data.frame(
"Dataset key" = 0,
"Dataset name" = "Matt",
"Researcher" = "Matt Jaquiery",
"Notes" = "Data come from initial decisions on the dots task, as used in the Exploring Social Metacognition study (https://osf.io/qtngm/). Confidence and decision are made simultaneously, by indicating the extent to which the participant is sure there were more dots on the right/left.",
"Frames per second" = NA,
"Confidence scale lower limit" = 1,
"Num confidence options" = 50,
"Minimum decision time" = NA,
"Maximum decision time" = NA
)
Trials <- data.frame(
"Dataset key" = integer(),
"Trial key" = integer(),
"Participant num" = integer(),
"Block num" = integer(),
"Trial num" = integer(),
"Stimulus category" = integer(),
"Response" = integer(),
"Accuracy" = integer(),
"Confidence" = integer(),
"Response time" = double(),
"Stimulus presentation time" = double(),
"Confidence time" = double()
)
Evidence <- data.frame(
"Trial key" = integer(),
"Frame number" = integer(),
"Evidence for stim 1" = integer(),
"Evidence for stim 2" = integer()
)
for (df in ex) {
for (x in seq(nrow(df))) {
i <- i + 1
trial <- df[x, ]
out <- data.frame(
"Dataset key" = 0,
"Trial key" = i,
"Participant num" = trial$pid,
"Block num" = trial$block,
"Trial num" = trial$id,
"Stimulus category" = trial$correctAnswer + 1,
"Response" = trial$initialAnswer + 1,
"Accuracy" = as.numeric(trial$correctAnswer == trial$initialAnswer),
"Confidence" = trial$initialConfidence,
"Response time" = (trial$timeInitialResponse - trial$timeInitialStimOn) / 1000,
"Stimulus presentation time" = (trial$timeInitialStimOff - trial$timeInitialStimOn) / 1000,
"Confidence time" = (trial$timeInitialResponse - trial$timeInitialStimOn) / 1000
)
# Evidence
if (trial$correctAnswer) {  # answer = left
left <- 200 + trial$dotDifference
right <- 200 - trial$dotDifference
} else {
left <- 200 - trial$dotDifference
right <- 200 + trial$dotDifference
}
tmp <- data.frame(
"Trial key" = i,
"Frame number" = 0,
"Evidence for stim 1" = left,
"Evidence for stim 2" = right
)
Trials <- rbind(Trials, out)
Evidence <- rbind(Evidence, tmp)
}
}
Datasets <- data.frame(
"Dataset key" = 0,
"Dataset name" = "Matt",
"Researcher" = "Matt Jaquiery",
"Notes" = "Data come from initial decisions on the dots task, as used in the Exploring Social Metacognition study (https://osf.io/qtngm/). Confidence and decision are made simultaneously, by indicating the extent to which the participant is sure there were more dots on the right/left.",
"Frames per second" = NA,
"Confidence scale lower limit" = 1,
"Num confidence options" = 50,
"Minimum decision time" = NA,
"Maximum decision time" = NA
)
Trials <- data.frame(
"Dataset key" = integer(),
"Trial key" = integer(),
"Participant num" = integer(),
"Block num" = integer(),
"Trial num" = integer(),
"Stimulus category" = integer(),
"Response" = integer(),
"Accuracy" = integer(),
"Confidence" = integer(),
"Response time" = double(),
"Stimulus presentation time" = double(),
"Confidence time" = double()
)
Evidence <- data.frame(
"Trial key" = integer(),
"Frame number" = integer(),
"Evidence for stim 1" = integer(),
"Evidence for stim 2" = integer()
)
Datasets <- data.frame(
"Dataset key" = 0,
"Dataset name" = "Matt",
"Researcher" = "Matt Jaquiery",
"Notes" = "Data come from initial decisions on the dots task, as used in the Exploring Social Metacognition study (https://osf.io/qtngm/). Confidence and decision are made simultaneously, by indicating the extent to which the participant is sure there were more dots on the right/left.",
"Frames per second" = NA,
"Confidence scale lower limit" = 1,
"Num confidence options" = 50,
)
Trials <- data.frame(
"Dataset key" = integer(),
"Trial key" = integer(),
"Participant num" = integer(),
"Block num" = integer(),
"Trial num" = integer(),
"Stimulus category" = integer(),
"Response" = integer(),
"Accuracy" = integer(),
"Confidence" = integer(),
"Response time" = double(),
"Stimulus presentation time" = double(),
"Confidence time" = double(),
"Minimum decision time" = integer(),
"Maximum decision time" = integer()
)
Evidence <- data.frame(
"Trial key" = integer(),
"Frame number" = integer(),
"Evidence for stim 1" = integer(),
"Evidence for stim 2" = integer()
)
# separate by experiment name
ex <- list()
for (n in unique(trials$folderName))
ex[[n]] <- trials[trials$folderName == n, ]
i <- 0
# Could paralleize this if necessary (stitch back together adjusting trial keys)
for (df in ex) {
out <- data.frame(
"Dataset key" = 0,
"Trial key" = i + seq(nrow(df)),
"Participant num" = df$pid,
"Block num" = df$block,
"Trial num" = df$id,
"Stimulus category" = df$correctAnswer + 1,
"Response" = df$initialAnswer + 1,
"Accuracy" = as.numeric(df$correctAnswer == df$initialAnswer),
"Confidence" = df$initialConfidence,
"Response time" = (df$timeInitialResponse - df$timeInitialStimOn) / 1000,
"Stimulus presentation time" = (df$timeInitialStimOff - df$timeInitialStimOn) / 1000,
"Confidence time" = (df$timeInitialResponse - df$timeInitialStimOn) / 1000,
"Minimum decision time" = NA,
"Maximum decision time" = NA
)
# Evidence
left <- ifelse(df$correctAnswer,
200 + df$dotDifference,
200 - df$dotDifference)
right <- ifelse(df$correctAnswer,
200 - df$dotDifference,
200 + df$dotDifference)
tmp <- data.frame(
"Trial key" = i + seq(nrow(df)),
"Frame number" = 0,
"Evidence for stim 1" = left,
"Evidence for stim 2" = right
)
Trials <- rbind(Trials, out)
Evidence <- rbind(Evidence, tmp)
i <- i + nrow(df)
}
data <- data[complete.cases(data), ]
trials <- trials[complete.cases(trials), ]
Datasets <- data.frame(
"Dataset key" = 0,
"Dataset name" = "Matt",
"Researcher" = "Matt Jaquiery",
"Notes" = "Data come from initial decisions on the dots task, as used in the Exploring Social Metacognition study (https://osf.io/qtngm/). Confidence and decision are made simultaneously, by indicating the extent to which the participant is sure there were more dots on the right/left.",
"Frames per second" = NA,
"Confidence scale lower limit" = 1,
"Num confidence options" = 50,
)
Trials <- data.frame(
"Dataset key" = integer(),
"Trial key" = integer(),
"Participant num" = integer(),
"Block num" = integer(),
"Trial num" = integer(),
"Stimulus category" = integer(),
"Response" = integer(),
"Accuracy" = integer(),
"Confidence" = integer(),
"Response time" = double(),
"Stimulus presentation time" = double(),
"Confidence time" = double(),
"Minimum decision time" = integer(),
"Maximum decision time" = integer()
)
Evidence <- data.frame(
"Trial key" = integer(),
"Frame number" = integer(),
"Evidence for stim 1" = integer(),
"Evidence for stim 2" = integer()
)
# separate by experiment name
ex <- list()
for (n in unique(trials$folderName))
ex[[n]] <- trials[trials$folderName == n, ]
i <- 0
# Could paralleize this if necessary (stitch back together adjusting trial keys)
for (df in ex) {
out <- data.frame(
"Dataset key" = 0,
"Trial key" = i + seq(nrow(df)),
"Participant num" = df$pid,
"Block num" = df$block,
"Trial num" = df$id,
"Stimulus category" = df$correctAnswer + 1,
"Response" = df$initialAnswer + 1,
"Accuracy" = as.numeric(df$correctAnswer == df$initialAnswer),
"Confidence" = df$initialConfidence,
"Response time" = (df$timeInitialResponse - df$timeInitialStimOn) / 1000,
"Stimulus presentation time" = (df$timeInitialStimOff - df$timeInitialStimOn) / 1000,
"Confidence time" = (df$timeInitialResponse - df$timeInitialStimOn) / 1000,
"Minimum decision time" = NA,
"Maximum decision time" = NA
)
# Evidence
left <- ifelse(df$correctAnswer,
200 + df$dotDifference,
200 - df$dotDifference)
right <- ifelse(df$correctAnswer,
200 - df$dotDifference,
200 + df$dotDifference)
tmp <- data.frame(
"Trial key" = i + seq(nrow(df)),
"Frame number" = 0,
"Evidence for stim 1" = left,
"Evidence for stim 2" = right
)
Trials <- rbind(Trials, out)
Evidence <- rbind(Evidence, tmp)
i <- i + nrow(df)
}
write.csv(Datasets, "../data/Joshua_dotsdata_Matt_datasets.csv", row.names = F)
write.csv(Trials, "../data/Joshua_dotsdata_Matt_trials.csv", row.names = F)
write.csv(Evidence, "../data/Joshua_dotsdata_Matt_evidence.csv", row.names = F)
?write.csv
# save csv file
write.csv(Datasets, "../data/Joshua_dotsdata_Matt_datasets.csv",
row.names = F, na = "")
write.csv(Trials, "../data/Joshua_dotsdata_Matt_trials.csv",
row.names = F, na = "")
write.csv(Evidence, "../data/Joshua_dotsdata_Matt_evidence.csv",
row.names = F, na = "")
source('F:/xampp/htdocs/ExploringSocialMetacognition/analysis/exportDotsDataJoshua.R', echo=TRUE)
Datasets <- data.frame(
"Dataset key" = 0,
"Dataset name" = "Matt",
"Researcher" = "Matt Jaquiery",
"Notes" = "Data come from initial decisions on the dots task, as used in the Exploring Social Metacognition study (https://osf.io/qtngm/). Confidence and decision are made simultaneously, by indicating the extent to which the participant is sure there were more dots on the right/left.",
"Frames per second" = NA,
"Confidence scale lower limit" = 1,
"Num confidence options" = 50
)
Trials <- data.frame(
"Dataset key" = integer(),
"Trial key" = integer(),
"Participant num" = integer(),
"Block num" = integer(),
"Trial num" = integer(),
"Stimulus category" = integer(),
"Response" = integer(),
"Accuracy" = integer(),
"Confidence" = integer(),
"Response time" = double(),
"Stimulus presentation time" = double(),
"Confidence time" = double(),
"Minimum decision time" = integer(),
"Maximum decision time" = integer()
)
Evidence <- data.frame(
"Trial key" = integer(),
"Frame number" = integer(),
"Evidence for stim 1" = integer(),
"Evidence for stim 2" = integer()
)
# separate by experiment name
ex <- list()
for (n in unique(trials$folderName))
ex[[n]] <- trials[trials$folderName == n, ]
i <- 0
# Could paralleize this if necessary (stitch back together adjusting trial keys)
for (df in ex) {
out <- data.frame(
"Dataset key" = 0,
"Trial key" = i + seq(nrow(df)),
"Participant num" = df$pid,
"Block num" = df$block,
"Trial num" = df$id,
"Stimulus category" = df$correctAnswer + 1,
"Response" = df$initialAnswer + 1,
"Accuracy" = as.numeric(df$correctAnswer == df$initialAnswer),
"Confidence" = df$initialConfidence,
"Response time" = (df$timeInitialResponse - df$timeInitialStimOn) / 1000,
"Stimulus presentation time" = (df$timeInitialStimOff - df$timeInitialStimOn) / 1000,
"Confidence time" = (df$timeInitialResponse - df$timeInitialStimOn) / 1000,
"Minimum decision time" = NA,
"Maximum decision time" = NA
)
# Evidence
left <- ifelse(df$correctAnswer,
200 + df$dotDifference,
200 - df$dotDifference)
right <- ifelse(df$correctAnswer,
200 - df$dotDifference,
200 + df$dotDifference)
tmp <- data.frame(
"Trial key" = i + seq(nrow(df)),
"Frame number" = 0,
"Evidence for stim 1" = left,
"Evidence for stim 2" = right
)
Trials <- rbind(Trials, out)
Evidence <- rbind(Evidence, tmp)
i <- i + nrow(df)
}
# save csv file
write.csv(Datasets, "../data/Joshua_dotsdata_Matt_datasets.csv",
row.names = F, na = "")
write.csv(Trials, "../data/Joshua_dotsdata_Matt_trials.csv",
row.names = F, na = "")
write.csv(Evidence, "../data/Joshua_dotsdata_Matt_evidence.csv",
row.names = F, na = "")
repo <- "https://osf.io/s46pr/files/"
files <- NULL
con <- curl(repo)
library(curl) # fetching files from server
open(con, "rb")
con <- curl(repo)
open(con, "rb")
??curl
library("scrapeR")
install.packages("scrapeR")
??scrapeR
library(scrapeR) # fetching files from server
repo <- "https://osf.io/s46pr/files/"
osf <- scrape(repo)
osf <- scrape(repo, parse = F)
osf
osf <- scrape(url = repo, parse = F)
osf
osf <- scrape(url = repo, headers = T, parse = F)
scrape(url = repo, headers = T, parse = F)
scrape(url="http://cran.r-project.org/web/packages/",headers=TRUE,
parse=FALSE)
repo <- "http://osf.io/s46pr/files/"
scrape(url = repo, headers = T, parse = F)
repo <- "https://osf.io/s46pr/files/"
scrape(url = repo, headers = T, parse = F)
scrape(url = repo, headers = T, parse = F, follow = T)
osf <- scrape(url = repo, headers = T, parse = F, follow = T, verbose = T)
repo <- "https://osf.io/s46pr/files/"
iinstall.packages("rvest")
install.packages("rvest")
library(rvest)
read_html(repo)
install.packages("BayesMed")
# dependencies ------------------------------------------------------------
library(BayesMed)
library(tibble)
?rep
n <- 500
simData <- tibble(p = rep(seq(n), each = 2), # participant numbers
sigma = rep(abs(rnorm(n)), each = 2), # each participant gets idiosynratic noise
group = rep(seq(2), each = n)
)
simData
simData <- tibble(p = rep(seq(n), each = 2), # participant numbers
sigma = rep(abs(rnorm(n)), each = 2), # each participant gets idiosynratic noise
group = rep(seq(2), times = n)
)
simData
simData <- tibble(p = rep(seq(n), each = 2), # participant numbers
sigma = rep(abs(rnorm(n)), each = 2), # each participant gets idiosynratic noise
Group = rep(seq(2), times = n),
Q = rep(rnorm(n), each = 2) + # intercept
effectSizes$a[2] * Group + # group effect
rnorm(n * 2, sigma), # error
WoA = rep(rnorm(n), each = 2) +
effectSizes$b[2] * Q +
effectSizes$c[2] * Group +
rnorm(n * 2, sigma))
effectSizes <- tibble(a = c(.1, .3, .7),
b = c(.1, .3, .7),
c = c(.1, .3, .7))
simData <- tibble(p = rep(seq(n), each = 2), # participant numbers
sigma = rep(abs(rnorm(n)), each = 2), # each participant gets idiosynratic noise
Group = rep(seq(2), times = n),
Q = rep(rnorm(n), each = 2) + # intercept
effectSizes$a[2] * Group + # group effect
rnorm(n * 2, sigma), # error
WoA = rep(rnorm(n), each = 2) +
effectSizes$b[2] * Q +
effectSizes$c[2] * Group +
rnorm(n * 2, sigma))
simData
cor.test(simData$Group, simData$WoA)
cor.test(simData$Q, simData$WoA)
cor.test(simData$Group, simData$Q)
