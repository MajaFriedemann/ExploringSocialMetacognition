if(!tmp$isRepeat[i]) return(F)
return(tmp$grid[i] != tmp$grid[tmp$id == tmp$stimulusParent[i] & tmp$pid == tmp$pid[i]])
})
tmp$delta <- sapply(1:nrow(tmp), function(i) {
if(!tmp$isRepeat[i]) return(NA)
x <- tmp$initialCorrect[tmp$id == tmp$stimulusParent[i] & tmp$pid == tmp$pid[i]]
tmp$initialCorrect[i] - x
})
data <- aggregate(delta ~ pid + swapped, data = tmp[tmp$isRepeat, ], FUN = mean)
cat(md.ttestBF(data$delta[!data$swapped], data$delta[data$swapped], labels = c('*M*|same', '*M*|swapped'), paired = T))
aggregate(initialConfidence ~ pid, trials, length)
debriefRepQuiz
debriefRepQuiz$grid %in% trials$grid[trials$pid == debriefRepQuiz$pid]
# Correct for incidental repeats
debriefRepQuiz$actualRepeat <- debriefRepQuiz$grid %in% trials$grid[trials$pid == debriefRepQuiz$pid]
debriefRepQuiz
trials$pid[trials$grid == debriefRepQuiz$grid[1]]
for(pid in unique(debriefRepQuiz$pid))
debriefRepQuiz$actualRepeat[debriefRepQuiz$pid == pid] <- debriefRepQuiz$grid %in% trials$grid[trials$pid == pid]
# Correct for incidental repeats
for(pid in unique(debriefRepQuiz$pid)) {
debriefRepQuiz$actualRepeat[debriefRepQuiz$pid == pid] <-
debriefRepQuiz$grid[debriefRepQuiz$pid == pid] %in% trials$grid[trials$pid == pid]
}
debriefRepQuiz
# Correct for incidental repeats
debriefRepQuiz$actualRepeat <- NA
debriefRepQuiz$actualType <- NA
for(pid in unique(debriefRepQuiz$pid)) {
tmp <- debriefRepQuiz[debriefRepQuiz$pid == pid, ]
tmp$actualRepeat <- tmp$grid %in% trials$grid[trials$pid == pid]
tmp$actualType[tmp$actualRepeat] <- 'repeat'
tmp$actualType[!tmp$actualRepeat] <- tmp$type
debriefRepQuiz[debriefRepQuiz$pid == pid, ] <- tmp
}
tmp$actualType[tmp$actualRepeat]
tmp$actualRepeat
!tmp$actualRepeat
tmp$actualType[!tmp$actualRepeat]
for(pid in unique(debriefRepQuiz$pid)) {
tmp <- debriefRepQuiz[debriefRepQuiz$pid == pid, ]
tmp$actualRepeat <- tmp$grid %in% trials$grid[trials$pid == pid]
tmp$actualType[tmp$actualRepeat] <- 'repeat'
tmp$actualType[!tmp$actualRepeat] <- tmp$type[!tmp$actualRepeat]
debriefRepQuiz[debriefRepQuiz$pid == pid, ] <- tmp
}
debriefRepQuiz
df.dotQuiz <- aggregate(selected ~ pid + actualType, debriefRepQuiz, mean)
df.dotQuiz
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, alpha = .5) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style
ggplot(df.dotQuiz, aes(x = actualType, y = selected, colour = factor(pid))) +
geom_violin(colour = NA, alpha = .5) +
geom_point() +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style
ggplot(df.dotQuiz, aes(x = actualType, y = selected, colour = factor(pid))) +
geom_violin(colour = NA, alpha = .5) +
geom_point() +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected, colour = factor(pid), group = pid)) +
geom_violin(colour = NA, alpha = .5) +
geom_point() +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
folderName <- "G:\\Documents\\University\\Google Drive\\Temp\\data\\processed"
results <- loadFilesFromFolder(folderName)
results <- removeParticipantIds(results)
# folderName <- 'ESM_sim.R'
# source('src/ESM_sim.R')
# results <- simulateAdvisorChoice(16, aPairs = list('agr' = c(7,8)), tTypes = c(trialTypes$dual, trialTypes$change))
# unpack results
for(i in 1:length(results))
assign(names(results)[i], results[i][[1]])
cat(paste('Loaded data from', folderName))
trials <- cbind(trials, trialUtilityVariables(results))
all.trials <- trials
trials <- trials[trials$practice == F, ]
cat('Generated utility variables')
# Correct for incidental repeats
debriefRepQuiz$actualRepeat <- NA
debriefRepQuiz$actualType <- NA
for(pid in unique(debriefRepQuiz$pid)) {
tmp <- debriefRepQuiz[debriefRepQuiz$pid == pid, ]
tmp$actualRepeat <- tmp$grid %in% trials$grid[trials$pid == pid]
tmp$actualType[tmp$actualRepeat] <- 'repeat'
tmp$actualType[!tmp$actualRepeat] <- tmp$type[!tmp$actualRepeat]
debriefRepQuiz[debriefRepQuiz$pid == pid, ] <- tmp
}
df.dotQuiz <- aggregate(selected ~ pid + actualType, debriefRepQuiz, mean)
ggplot(df.dotQuiz, aes(x = actualType, y = selected, colour = factor(pid), group = pid)) +
geom_violin(colour = NA, alpha = .5) +
geom_point() +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
df.dotQuiz
mean(df.dotQuiz$selected[df.dotQuiz$actualType=='swapped'])
ggplot(df.dotQuiz, aes(x = actualType, y = selected, colour = factor(pid))) +
geom_violin(colour = NA, alpha = .5) +
geom_point() +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, alpha = .5) +
geom_point() +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, alpha = .5) +
geom_point(aes(colour = factor(pid))) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, fill='grey25', alpha = .5) +
geom_point(aes(colour = factor(pid))) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, fill='grey50', alpha = .5) +
geom_point(aes(colour = factor(pid))) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, fill='grey75', alpha = .5) +
geom_point(aes(colour = factor(pid))) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
ggplot(df.dotQuiz, aes(x = actualType, y = selected)) +
geom_violin(colour = NA, fill='grey75', alpha = .5) +
geom_point(aes(colour = factor(pid)), position = position_jitter(.1)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_normal, width = .25) +
stat_summary(geom = 'point', fun.y = mean, size = 3, shape = 18) +
scale_x_discrete(name = 'Grid type') +
scale_y_continuous(name = 'P(selected)', limits = c(0,1)) +
style.long
aggregate(selected ~ pid, debriefRepQuiz, mean)
mean(aggregate(selected ~ pid, debriefRepQuiz, mean)$selected)
debriefRepQuiz
round(mean(debriefRepQuiz$selected)*length(unique(debriefRepQuiz$id)),2)
knitr::opts_chunk$set(echo = F)
startTime <- Sys.time()
source('src/ESM_core.R')
folderName <- "G:\\Documents\\University\\Google Drive\\Temp\\data\\processed"
results <- loadFilesFromFolder(folderName)
results <- removeParticipantIds(results)
# folderName <- 'ESM_sim.R'
# source('src/ESM_sim.R')
# results <- simulateAdvisorChoice(16, aPairs = list('agr' = c(7,8)), tTypes = c(trialTypes$dual, trialTypes$change))
# unpack results
for(i in 1:length(results))
assign(names(results)[i], results[i][[1]])
cat(paste('Loaded data from', folderName))
trials <- cbind(trials, trialUtilityVariables(results))
all.trials <- trials
trials <- trials[trials$practice == F, ]
cat('Generated utility variables')
accuracy <- aggregate(finalCorrect ~ participantId,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
if(all(is.na(trials$finalAnswer)))
accuracy <- aggregate(initialCorrect ~ participantId, data = trials[!is.na(trials$initialCorrect), ], FUN = mean)
# trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer
# trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer
participants$pid <- sapply(participants$id, function(x) which(unique(participants$id)==x))
library(scoring)
library(digest)
source('src/ESM_core.R')
# Load data
folderName <- "G:\\Documents\\University\\Google Drive\\Temp\\data\\processed"
results <- loadFilesFromFolder(folderName)
# unpack results
for(i in 1:length(results))
assign(names(results)[i], results[i][[1]])
# Calculate some utility variables
trials <- cbind(trials, trialUtilityVariables(results))
# trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer
# trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer
participants$pid <- sapply(participants$id, function(x) which(unique(participants$id)==x))
accuracy <- aggregate(finalCorrect ~ participantId,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
if(all(is.na(trials$finalAnswer)))
accuracy <- aggregate(initialCorrect ~ participantId, data = trials[!is.na(trials$initialCorrect), ], FUN = mean)
library(scoring)
library(digest)
source('src/ESM_core.R')
# Load data
folderName <- "G:\\Documents\\University\\Google Drive\\Temp\\data\\processed"
results <- loadFilesFromFolder(folderName)
# unpack results
for(i in 1:length(results))
assign(names(results)[i], results[i][[1]])
# Calculate some utility variables
trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer
trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer
participants$pid <- sapply(participants$id, function(x) which(unique(participants$id)==x))
accuracy <- aggregate(finalCorrect ~ participantId,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
if(all(is.na(trials$finalAnswer)))
accuracy <- aggregate(initialCorrect ~ participantId, data = trials[!is.na(trials$initialCorrect), ], FUN = mean)
# We use the Brier score
tmp <- trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'participantId')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
for(p in unique(tmp$participantId))
tmp$initialConfidence[tmp$participantId == p] <- scale(tmp$initialConfidence[tmp$participantId == p])
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp[!is.na(tmp$initialConfidence), ], group = 'participantId')
scores$brieravg
rawString <- '5c3c89e5e0ea82000145e99a
17/01/2019, 15:07
N/A
TIMED-OUT
5bcbc5140f10750001d79f75
17/01/2019, 16:00
00:19:01
MX5PC2Z4
AWAITING REVIEW
5993576fbf8bcf0001ab6762
17/01/2019, 17:56
N/A
RETURNED
5c10fe241f6f15000148ad15
17/01/2019, 17:56
00:15:38
MX5PC2Z4
AWAITING REVIEW
5bdb50e3ee652a0001efa0e0
17/01/2019, 17:56
00:27:49
MX5PC2Z4
AWAITING REVIEW
5bbd977270f8df0001c10bc5
18/01/2019, 03:50
00:27:08
MX5PC2Z4
AWAITING REVIEW
5c0244a7d183df000141f793
18/01/2019, 05:42
00:23:23
MX5PC2Z4
AWAITING REVIEW
5be421c4810cdd00015c59f1
18/01/2019, 05:42
00:19:04
MX5PC2Z4
AWAITING REVIEW
5b6743c46044cb0001b99c8e
18/01/2019, 05:45
00:16:22
MX5PC2Z4
AWAITING REVIEW
5bdbce5593c9ba0001ef52a0
18/01/2019, 05:42
N/A
RETURNED
£0.50
5b7eda62ff1109000172ab7c
18/01/2019, 05:42
00:27:38
MX5PC2Z4
AWAITING REVIEW
5baacbfc0ebc370001bdb799
18/01/2019, 05:42
00:24:35
MX5PC2Z4
AWAITING REVIEW
5c0c90e7632102000147c3cc
18/01/2019, 05:50
N/A
TIMED-OUT
599f0d29ec626e0001d53f47
18/01/2019, 06:46
00:35:28
NOCODE
AWAITING REVIEW
5ba8b89d9629a90001b3fd13
18/01/2019, 12:08
00:17:01
NOCODE
APPROVED
5be3252a2dedc30001869bf8
18/01/2019, 12:08
00:15:15
MX5PC2Z4
AWAITING REVIEW
5c1575e62a407b0001ff2a4c
18/01/2019, 12:08
00:13:16
MX5PC2Z4
AWAITING REVIEW
5922d44a20a50a000194d340
18/01/2019, 12:08
00:20:12
MX5PC2Z4
AWAITING REVIEW
5c0333c84e1b7b00016a83fd
18/01/2019, 12:55
00:21:22
MX5PC2Z4
AWAITING REVIEW
5c23c651d9435800010b7e48
18/01/2019, 12:56
00:31:55
NOCODE
APPROVED
5b917dc54ef69f0001a2e74c
18/01/2019, 12:56
00:19:23
MX5PC2Z4
AWAITING REVIEW
5c33a787ad0c730001ec926d
18/01/2019, 12:57
00:32:48
MX5PC2Z4
AWAITING REVIEW
5bf6070c3b6cdc00010fb284
18/01/2019, 13:03
00:27:54
MX5PC2Z4
AWAITING REVIEW
5b6f25b73585d200014f85eb
18/01/2019, 12:55
00:32:27
NOCODE
AWAITING REVIEW
5c06d2bfb1ab3b00019ebb96
18/01/2019, 14:46
00:16:18
MX5PC2Z4
AWAITING REVIEW
5962a5b29955ee00015bce98
18/01/2019, 14:47
00:16:36
MX5PC2Z4
AWAITING REVIEW
5c10ccb06d1ac9000101dd34
18/01/2019, 14:46
00:13:56
MX5PC2Z4
AWAITING REVIEW
5c3f4ccd410e97000128d1cd
18/01/2019, 14:46
00:14:14
MX5PC2Z4
AWAITING REVIEW
5bb62f1a3e969700019bd44d '
if(exists('rawString')) {
prolificIds <- NULL
matches <- gregexpr('5[a-z0-9]{23}', rawString)
for(x in matches[[1]])
prolificIds <- c(prolificIds, substr(rawString, x, x+23))
}
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes == pid]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F, #participants$excluded[participants$pid==pid],
extra = debrief$answer[debrief$participantId==pid & debrief$id == 3]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'accuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp[i, paste0('q', dim)] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp[i, paste0('q', dim)]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
names(scores$brieravg)
scores$brieravg
length(names(scores$brieravg))
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes == pid]
proId
scores$brieravg[i]
pid
prolificId
tmp
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F, #participants$excluded[participants$pid==pid],
extra = debrief$answer[debrief$participantId==pid & debrief$id == 3]))
pid
proId
scores$brieravg[i]
accuracy[accuracy$participantId == pid, 2]
debrief$answer[debrief$participantId==pid & debrief$id == 3]
data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F, #participants$excluded[participants$pid==pid],
extra = debrief$answer[debrief$participantId==pid & debrief$id == 3])
data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2])
data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F, #participants$excluded[participants$pid==pid])
)
data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F)
debrief
pid
debrief$participantId==pid
debrief$participantId==pid & debrief$id == 3
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F, #participants$excluded[participants$pid==pid],
extra = debrief$answer[debrief$participantId==pid & debrief$id == 2]))
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes == pid]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$participantId == pid, 2],
excluded = F, #participants$excluded[participants$pid==pid],
extra = debrief$answer[debrief$participantId==pid & debrief$id == 2]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'accuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp[i, paste0('q', dim)] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp[i, paste0('q', dim)]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
