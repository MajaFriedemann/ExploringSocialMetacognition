for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i]))
else
print(paste0('PID',pid,'has no prolific hash associated'))
}
tmp
}
# We use the Brier score
tmp <- all.trials[,c('initialCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/100
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp, group = 'pid')
scores$brieravg
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
tmp
}
markers <- quantile(tmp)
markers <- quantile(tmp$brieravg)
markers
rev(markers)
markers <- quantile(tmp$brieravg)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers > tmp$brieravg[i])[1]
}
tmp
markers <- quantile(tmp$brieravg)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
}
tmp
markers
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/length(markers)*(quantile-1)
}
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/length(markers)*(tmp$quantile[i]-1)
}
tmp
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/length(markers-1)*(tmp$quantile[i]-1)
}
tmp
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/length(markers+1)*(tmp$quantile[i]-1)
}
tmp
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/length(markers-1)*(tmp$quantile[i]-1)
}
tmp
200/length(markers-1)
(tmp$quantile[i]-1)
40*4
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/length(markers)*(tmp$quantile[i])
}
tmp
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- 200 - 200/(length(markers)-1)*(tmp$quantile[i]-1)
}
tmp
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp[,c('prolificId','reward')]
participants$timeStart
sapply(participants$timeStart,time)
sapply(participants$timeStart,as.POSIXct)
sapply(participants$timeStart,as.POSIXlt)
sapply(participants$timeStart,as.POSIXlt, 'GMT')
x <- participants$timeStart[1]
x
as.POSIXct(x)
as.Date(x)
as.POSIXct(x, origin='1970-01-01')
anytime::anytime(x)
install.packages('anytime')
anytime::anytime(x)
typeof(x)
as.POSIXct(x[[1]])
typeof(drop(x))
x[[1]]
x <- x[[1]]
as.POSIXct(x)
as.POSIXct(x, origin='1970-01-01')
anytime::anytime(x)
anytime::anydate(x)
anytime::anytime(x/1000)
as.POSIXct(x/1000, origin='1970-01-01')
# For convenience the long participant Id is shortened to a simple number:
participants$timeStart <- sapply(participants$timeStart, function(x)as.POSIXct(x[[1]]/1000, origin='1970-01-01'))
participants$timeStart
participants$timeStart[1]
participants$timeEnd[1]
participants$timeEnd[1][[1]]
participants$timeEnd[1][[1]]/1000
as.POSIXct(participants$timeEnd[1][[1]]/1000)
as.POSIXct(participants$timeEnd[1][[1]]/1000, origin='1970-01-01')
sapply(participants$timeEnd,function(x)as.POSIXct(x[[1]]/1000, origin='1970-01-01'))
sapply(participants$timeEnd,function(x)x[[1]]/1000)
sapply(sapply(participants$timeEnd,function(x)x[[1]]/1000),as.POSIXct,origin='1970-01-01')
sapply(sapply(participants$timeEnd,function(x)x[[1]]/1000),anytime::anytime)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R')
x <- 1:100
x <- x%%5
x
x <- factor(x)
x
x <- recode(x, "0='zero';1='one';2='two';3='three';4='high'")
x <- car::recode(x, "0='zero';1='one';2='two';3='three';4='high'")
x
which(x==high)
which(x=='high')
which(x=="high")
ifelse(x=="high",1,0)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R')
names(!(jsonData$participants %in% names(participants)))
names(jsonData$participants)
names(!(jsonData %in% names(participants)))
names(jsonData)
names(participants)
names(jsonData)[!names(jsonData) %in% names(participants)]
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R')
names(participants)
names(jsonData)
!names(jsonData) %in% c('advisors', 'questionnaires', 'trials')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R')
View(participants)
participants <- rbind(participants, as.data.frame(t(jsonData[!names(jsonData) %in% c('advisors',
'questionnaires',
'trials')])))
names(participants)
names(jsonData)
which(!names(jsonData) %in% names(participants))
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoiceBonuses.R', echo=TRUE)
prolificIds <- c('5b530bb7b3c9400001f23db9', '5b44cb0e8fc6fc0001323e60')
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
markers <- quantile(tmp$brieravg)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp[,c('prolificId','reward')]
prolificIds[!(prolificIds %in% tmp$prolificId)]
}
prolificIds[!(prolificIds %in% tmp$prolificId)]
tmp[,c('prolificId','reward')]
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
markers <- quantile(tmp$brieravg)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
print(tmp[,c('prolificId','reward')])
prolificIds[!(prolificIds %in% tmp$prolificId)]
}
participants$excluded
participants$debriefComments
participants[, c(debriefComments, participantId)
]
participants[, c('debriefComments', 'participantId')]
participants[, c('participantId')]
participants[, c('debriefComments')]
participants[, c('participantId', 'debriefComments')]
participants[, c('id', 'debriefComments')]
digest('d6f673f7fb68b6da87bbaff7403d530abf62c6ce', algo = 'sha1', serialize = F)
prolificIds
prolificIdHashes
print(tmp[,c('prolificId','reward')])
participants[, c('id', 'excluded')]
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R', echo=TRUE)
print('Load data')
if(exists('trials'))
rm(trials)
if(exists('participants'))
rm(participants)
if(exists('advisors'))
rm(advisors)
if(exists('questionnaires'))
rm(questionnaires)
files <- list.files(folderName)
folderName <- '../AdvisorChoice/data/processed/'
participants <- NULL
trials <- NULL
advisors <- NULL
questionnaires <- NULL
i <- 1
fileName <- paste(folderName, files[[i]], sep='/')
folderName <- '../AdvisorChoice/data/processed/'
files <- list.files(folderName)
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
jsonData$id
i <- 2
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
jsonData$id
i <- 3
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
jsonData$id
files
i <- 7
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
jsonData$id
files <- list.files(folderName)
fileName <- paste(folderName, files[[i]], sep='/')
i <- 8
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
jsonData$generalisedTrustQuestionnaire
genTrustQ <- NULL
genTrustQ <- rbind(genTrustQ, jsonData$generalisedTrustQuestionnaire)
View(genTrustQ)
print('Load data')
if(exists('trials'))
rm(trials)
if(exists('participants'))
rm(participants)
if(exists('advisors'))
rm(advisors)
if(exists('questionnaires'))
rm(questionnaires)
if(exists('genTrustQ'))
rm(genTrustQ)
folderName <- '../AdvisorChoice/data/processed/'
files <- list.files(folderName)
participants <- NULL
trials <- NULL
advisors <- NULL
questionnaires <- NULL
genTrustQ <- NULL
for (i in seq(length(files))) {
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
# store all columns in participants table except the three last
# (trials, advisors, and questionnaires are stored separately)
# Patch for missing data in practice
if(!('debriefComments' %in% names(jsonData)))
jsonData <- c(list(debriefComments = 'NA'), jsonData)
participants <- rbind(participants,
as.data.frame(t(jsonData[!names(jsonData) %in% c('advisors',
'questionnaires',
'trials',
'generalisedTrustQuestionnaire')])))
# store the trials in the trials table
trials <- rbind(trials, jsonData$trials)
advisors <- rbind(advisors, jsonData$advisors)
questionnaires <- rbind(questionnaires, jsonData$questionnaires)
if(('generalisedTrustQuestionnaire' %in% names(jsonData)))
genTrustQ <- rbind(genTrustQ, jsonData$generalisedTrustQuestionnaire)
}
rm(jsonData, files, fileName, folderName, json)
print('Load data')
if(exists('trials'))
rm(trials)
if(exists('participants'))
rm(participants)
if(exists('advisors'))
rm(advisors)
if(exists('questionnaires'))
rm(questionnaires)
if(exists('genTrustQ'))
rm(genTrustQ)
folderName <- '../AdvisorChoice/data/processed/'
files <- list.files(folderName)
participants <- NULL
trials <- NULL
advisors <- NULL
questionnaires <- NULL
genTrustQ <- NULL
for (i in seq(length(files))) {
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
# store all columns in participants table except the three last
# (trials, advisors, and questionnaires are stored separately)
# Patch for missing data in practice
if(!('debriefComments' %in% names(jsonData)))
jsonData <- c(list(debriefComments = 'NA'), jsonData)
participants <- rbind(participants,
as.data.frame(t(jsonData[!names(jsonData) %in% c('advisors',
'questionnaires',
'trials',
'generalisedTrustQuestionnaire')])))
# store the trials in the trials table
trials <- rbind(trials, jsonData$trials)
advisors <- rbind(advisors, jsonData$advisors)
questionnaires <- rbind(questionnaires, jsonData$questionnaires)
if(('generalisedTrustQuestionnaire' %in% names(jsonData)))
genTrustQ <- rbind(genTrustQ, jsonData$generalisedTrustQuestionnaire)
}
rm(jsonData, files, fileName, folderName, json)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R', echo=TRUE)
genTrustQ$participantId
sapply(genTrustQ$participantId, tmp)
genTrustQ$pid
genTrustQ$answer
genTrustQ$answer[genTrustQ$order==0]
# The first general trust question is reverse coded
genTrustQ$answer[genTrustQ$order==0] <- 100 - as.numeric(genTrustQ$answer[genTrustQ$order==0])
genTrustQ$answer
# The first general trust question is reverse coded
genTrustQ$answer <- as.numeric(genTrustQ$answer)
genTrustQ$answer[genTrustQ$order==0] <- 100 - genTrustQ$answer[genTrustQ$order==0]
genTrustQ$answer
questionnaires$timepoint
# Generalised Trust is a measure of the propensity to trust, so we expect it to
# correlate with the initial scores for the advisor questionnaires
tmp <- questionnaires[questionnaires$timepoint==1,]
tmp
# Generalised Trust is a measure of the propensity to trust, so we expect it to
# correlate with the initial scores for the advisor questionnaires
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + pid,
data = questionnaires[questionnaires$timepoint==1,],
FUN = mean)
tmp
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x])
tmp
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
tmp
# Generalised trust should also correlate with influence given that influence is
# supposedly a manifestation of trust
tmp <- aggregate(influence ~ pid,
data = trials,
FUN = mean)
# Generalised trust should also correlate with influence given that influence is
# supposedly a manifestation of trust
tmp <- aggregate(influence ~ pid,
data = trials,
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
tmp
c.xi.ii <- cor.test(tmp$influence, tmp$genTrust)
aggregate(influence ~ confidenceCategory + pid, data = trials, FUN = length)
ggplot(trials, aes(x = id, y = initialConfidence, colour = pid)) + geom_smooth()
ggplot(trials, aes(x = id, y = initialConfidence, colour = as.factor(pid))) + geom_smooth()
ggplot(trials, aes(x = id, y = initialConfidence, colour = as.factor(pid))) + geom_smooth(method = 'lm')
aggregate(influence ~ pid, data = aggregate(influence ~ confidenceCategory + pid, data = trials, FUN = length), FUN = mean)
aggregate(influence ~ confidenceCategory, data = aggregate(influence ~ confidenceCategory + pid, data = trials, FUN = length), FUN = mean)
cor.test(trials$initialConfidence, trials$id)
cor.test(trials$confidenceCategory, trials$id)
ggplot(trials, aes(x = id, y = confidenceCategory, colour = as.factor(pid))) + geom_smooth(method = 'lm')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R', echo=TRUE)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R', echo=TRUE)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R', echo=TRUE)
sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .9)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
#return(F)
# TODO ####
# Clarify the numbers on the rules below
# Between 30 and 50% of trials must be medium confidence
if(cCs$pid[cCs$confidenceCategory==confidenceCategories$medium] < length(ts)*.3
| cCs$pid[cCs$confidenceCategory==confidenceCategories$medium] > length(ts)*.5)
return('Confidence.med')
# Other categories must contain between 20 and 40% of trials
cCs[cCs$confidenceCategory==confidenceCategories$medium, ] <- NULL
if(any(cCs$pid < length(ts)*.2) | any(cCs$pid > length(ts)*.4))
return('Confidence.hiLow')
return(F)
})
sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .9)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
#return(F)
# TODO ####
# Clarify the numbers on the rules below
# Between 30 and 50% of trials must be medium confidence
if(cCs$pid[cCs$confidenceCategory==confidenceCategories$medium] < length(ts)*.3
| cCs$pid[cCs$confidenceCategory==confidenceCategories$medium] > length(ts)*.5)
return('Confidence.med')
print(pid)
# Other categories must contain between 20 and 40% of trials
cCs[cCs$confidenceCategory==confidenceCategories$medium, ] <- NULL
if(any(cCs$pid < length(ts)*.2) | any(cCs$pid > length(ts)*.4))
return('Confidence.hiLow')
return(F)
})
pid <- 3
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .9)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
nrow(cCs)
(cCs$pid[cCs$confidenceCategory==confidenceCategories$medium] < length(ts)*.3
| cCs$pid[cCs$confidenceCategory==confidenceCategories$medium] > length(ts)*.5)
cCs[cCs$confidenceCategory==confidenceCategories$medium, ] <- NULL
cCs[cCs$confidenceCategory==confidenceCategories$medium, ]
cCs
sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .9)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
# Clarify the numbers on the rules below
# All confidence categories must have at least 5% of the number of trials
if(any(cCs$pid < length(ts)*.05))
return('Confidence.cat')
return(F)
})
unique(trials$warnings)
length(trials)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoice.R', echo=TRUE)
nrow(trials)
unique(trials$warnings)
sum(trials$warnings!='')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoiceBonuses.R', echo=TRUE)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoiceBonuses.R', echo=TRUE)
?correlationBF
?BayesFactor::correlationBF
BayesFactor::BFInfo()
update.packages('BayesFactor')
library(BayesFactor)
BFInfo()
install.packages(c("afex", "arm", "BayesFactor", "bayesplot", "BDgraph", "bindr", "bindrcpp", "broom", "callr", "car", "caTools", "cluster", "cowplot", "curl", "data.table", "DBI", "dbplyr", "DescTools", "devtools", "digest", "doBy", "dplyr", "emmeans", "evaluate", "foreign", "Formula", "GGally", "ggplot2", "ggpubr", "ggrepel", "ggridges", "ggsci", "git2r", "glasso", "glmmTMB", "glue", "gnm", "gtools", "haven", "highr", "htmlTable", "htmlwidgets", "igraph", "iterators", "jmv", "jmvcore", "knitr", "lavaan", "lme4", "lmerTest", "lmtest", "lubridate", "MASS", "Matrix", "mgcv", "modelr", "modeltools", "munsell", "mvtnorm", "network", "nlme", "OpenMx", "packrat", "pillar", "plogr", "PMCMR", "prediction", "progress", "psych", "purrr", "qgraph", "quantreg", "R.oo", "Rcpp", "RcppEigen", "RCurl", "readxl", "reprex", "rJava", "rjson", "rlang", "rmarkdown", "rockchalk", "roxygen2", "rpart", "rpf", "rsconnect", "RSiena", "selectr", "semTools", "sjlabelled", "sjmisc", "sjstats", "snakecase", "statnet.common", "stringdist", "stringi", "stringr", "survival", "TH.data", "tibble", "tidyr", "TMB", "utf8", "viridis", "viridisLite", "withr", "xlsx", "XML", "yaml", "zoo"))
install.packages(c("afex", "arm", "BayesFactor", "bayesplot", "BDgraph", "bindr", "bindrcpp", "broom", "callr", "car", "caTools", "cluster", "cowplot", "curl", "data.table", "DBI", "dbplyr", "DescTools", "devtools", "digest", "doBy", "dplyr", "emmeans", "evaluate", "foreign", "Formula", "GGally", "ggplot2", "ggpubr", "ggrepel", "ggridges", "ggsci", "git2r", "glasso", "glmmTMB", "glue", "gnm", "gtools", "haven", "highr", "htmlTable", "htmlwidgets", "igraph", "iterators", "jmv", "jmvcore", "knitr", "lavaan", "lme4", "lmerTest", "lmtest", "lubridate", "MASS", "Matrix", "mgcv", "modelr", "modeltools", "munsell", "mvtnorm", "network", "nlme", "OpenMx", "packrat", "pillar", "plogr", "PMCMR", "prediction", "progress", "psych", "purrr", "qgraph", "quantreg", "R.oo", "Rcpp", "RcppEigen", "RCurl", "readxl", "reprex", "rJava", "rjson", "rlang", "rmarkdown", "rockchalk", "roxygen2", "rpart", "rpf", "rsconnect", "RSiena", "selectr", "semTools", "sjlabelled", "sjmisc", "sjstats", "snakecase", "statnet.common", "stringdist", "stringi", "stringr", "survival", "TH.data", "tibble", "tidyr", "TMB", "utf8", "viridis", "viridisLite", "withr", "xlsx", "XML", "yaml", "zoo"))
install.packages(c("afex", "arm", "BayesFactor", "bayesplot", "BDgraph", "bindr", "bindrcpp", "broom", "callr", "car", "caTools", "cluster", "cowplot", "curl", "data.table", "DBI", "dbplyr", "DescTools", "devtools", "digest", "doBy", "dplyr", "emmeans", "evaluate", "foreign", "Formula", "GGally", "ggplot2", "ggpubr", "ggrepel", "ggridges", "ggsci", "git2r", "glasso", "glmmTMB", "glue", "gnm", "gtools", "haven", "highr", "htmlTable", "htmlwidgets", "igraph", "iterators", "jmv", "jmvcore", "knitr", "lavaan", "lme4", "lmerTest", "lmtest", "lubridate", "MASS", "Matrix", "mgcv", "modelr", "modeltools", "munsell", "mvtnorm", "network", "nlme", "OpenMx", "packrat", "pillar", "plogr", "PMCMR", "prediction", "progress", "psych", "purrr", "qgraph", "quantreg", "R.oo", "Rcpp", "RcppEigen", "RCurl", "readxl", "reprex", "rJava", "rjson", "rlang", "rmarkdown", "rockchalk", "roxygen2", "rpart", "rpf", "rsconnect", "RSiena", "selectr", "semTools", "sjlabelled", "sjmisc", "sjstats", "snakecase", "statnet.common", "stringdist", "stringi", "stringr", "survival", "TH.data", "tibble", "tidyr", "TMB", "utf8", "viridis", "viridisLite", "withr", "xlsx", "XML", "yaml", "zoo"))
