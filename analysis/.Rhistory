scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and correctness') +
style
gg.iii.ii
#   3.iii) Initial block agreement by contingency ####
print('3.iii Initial block agreement by contingency')
# Initial block is forced trials
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + initialCorrect,
data = trials[trials$type==trialTypes$force, ], FUN = mean)
tmp.aov <- aov(advisorAgrees ~ confidenceCategory * adviceType * initialCorrect +
Error(pid / (confidenceCategory + adviceType + initialCorrect)), data = tmp)
summary(tmp.aov)
#   3.iv) Graph: initial block agreement by contingency ####
print('3.iv Graph of intial block agreement by contingency')
gg.iii.iv <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and correctness\n on forced trials') +
style
gg.iii.iv
print('3.iv.i Graph of agreement by block on initialCorrect trials')
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + typeName,
data = trials[trials$initialCorrect==T, ], FUN = mean)
tmp.aov <- aov(advisorAgrees ~ confidenceCategory * adviceType * typeName +
Error(pid / (confidenceCategory + adviceType + typeName)), data = tmp)
summary(tmp.aov)
gg.iii.iv.i <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~typeName, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and block\n on initially correct trials') +
style
gg.iii.iv.i
#   3.v) Trial count by contingency ####
print('3.v Trial count by contingency')
# Let's also check we got appropriate numbers of trials in each of the bins for
# each participant
df.iii.v <- aggregate(practice ~
pid + confidenceCategory + adviceType + initialCorrect + advisorAgrees,
data = trials, FUN = length)
print(df.iii.v)
#   3.vi) Graph: trial count by contingency ####
print('3.vi Graph of trial count by contingency')
gg.iii.vi <- ggplot(df.iii.v, aes(y = practice, x = as.factor(confidenceCategory),
colour = as.factor(adviceType), shape = as.factor(advisorAgrees))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Trial Count') +
scale_shape_discrete(name = 'Advisor Agreement', labels = c('Disagree', 'Agree')) +
labs(title = 'Observed trial count for dis/agreement from each advisor by initial decision confidence\n and correctness') +
style
gg.iii.vi
# 4) Exclusions ####
print('Running exclusions')
# Exclusion rules:
# Proportion of correct initial judgements must be (.60 < cor1/n < .90)
#NB:practice trials are INCLUDED in this since they are used in part for
#determining confidence calibration
participants$excluded <- sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .85)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
# Clarify the numbers on the rules below
# All confidence categories must have at least 5% of the number of trials
if(any(cCs$pid < length(ts)*.05))
return('Confidence.cat')
return(F)
})
all.participants <- participants
participants <- participants[participants$excluded==F, ]
# Remove excluded participants' data from other data frames
trials <- trials[trials$pid %in% participants$pid, ]
advisors <- advisors[advisors$pid %in% participants$pid, ]
questionnaires <- questionnaires[questionnaires$pid %in% participants$pid, ]
df.iv <- aggregate(pid ~ excluded, data = all.participants, FUN = length)
names(df.iv) <- c('exclusionReason', 'count')
print(df.iv)
#   0.i) Libraries ####
if(!require(jsonlite)) {
install.packages("jsonlite")
library(jsonlite)
}
if(!require(BayesFactor)) {
install.packages('BayesFactor')
library(BayesFactor)
}
if(!require(tidyverse)) {
install.packages('tidyverse')
library(tidyverse)
}
if(!require(reshape2)) {
install.packages('reshape2')
library(reshape2)
}
if(!require(lme4)) {
install.packages('lme4')
library(lme4)
}
if(!require(lsr)) {
install.packages('lsr')
library(lsr)
}
#   0.ii) Functions ####
# Print the results of a t-test as we would like to see them reported in a paper
prettyPrint <- function(results, d = NULL) {
es <- NULL
if(!is.null(d))
es <- paste0(' , d=', round(d,2))
print(paste0('t(',results$parameter,')=',round(results$statistic,2),
' [',round(attr(results$conf.int, "conf.level")*100),'%CI: ',
round(results$conf.int[[1]],2), ', ', round(results$conf.int[[2]],2),'],',
' p=',round(results$p.value,3), es))
}
# Print the mean and CIs of a vector
printMean <- function(vector, label = 'Mean', doPrint = T, conf.int = .95, na.rm = F, decimals = 2) {
mu <- mean(vector, na.rm = na.rm)
s <- sd(vector, na.rm = na.rm)
n <- length(vector)
error <- qnorm(1-(1-conf.int)/2)*s/sqrt(n) # 95% confidence interval width
ci.low <- mu - error
ci.high <- mu + error
r <- round(range(vector, na.rm = na.rm), decimals)
print(paste0(label,'=', round(mu,decimals), ' [', round(conf.int,decimals)*100, '%CI: ',
round(ci.low,decimals), ', ', round(ci.high,decimals),'] [Range: ',
r[[1]], ', ', r[[2]], ']'))
}
# Return the advice type of an advisor for participant with row number=pid
getAdviceTypeById <- function(aid, pid, advisor.data.frame) {
type <- advisor.data.frame[which(advisor.data.frame$participantId==pid),]
type <- type[which(type$id==aid),]
if (length(type) > 0)
return(type$adviceType)
return(NA)
}
# Return a vector of advice types for trial list t
getAdviceType <- function (t, participant.data.frame, advisor.data.frame, forceRecalculate = FALSE) {
# shortcut if we already calculated this
if('adviceType' %in% colnames(t) && !forceRecalculate)
return(t$adviceType)
out <- vector(length=dim(t)[1])
for (i in seq(length(out))) {
if (t$advisorId[i]==0) {
# no advisor
out[i] <- NA;
} else {
pid <- t$participantId[i]
out[i] <- getAdviceTypeById(t$advisorId[i], pid, advisor.data.frame)
}
}
return(out)
}
#' Find the confidence shift in a given trial
#' @param t trial list
#' @param rawShift whether to report the confidence shift without adjusting for the assymetric scale
#' @param forceRecalulate if true, simply return the appropriate column from t if it exists already
#' @return a vector of confidence shifts for trial list t
getConfidenceShift <- function (t, rawShift = FALSE, forceRecalculate = FALSE) {
scaleMaximum <- 50
# shortcut if we already calculated this
if('confidenceShift' %in% colnames(t) && !forceRecalculate)
return(t$confidenceShift)
out <- vector(length=dim(t)[1])
for (i in seq(length(out))) {
if (is.na(t$finalConfidence[i])) { # no advisor
out[i] <- NA
} else {
max.shift <- scaleMaximum - t$initialConfidence[i]
if(t$initialAnswer[i]==t$finalAnswer[i])
out[i] <- t$finalConfidence[i]-t$initialConfidence[i] # same side
else
out[i] <- -1 * (t$finalConfidence[i]+t$initialConfidence[i]) # switched sliders, so went to 0 on the first one
out[i] <- ifelse((abs(out[i]) > max.shift) & rawShift == F, max.shift*sign(out[i]), out[i])
}
}
return(out)
}
# Return a vector of influence for trial list t
#' @param t trial list
#' @param rawShift whether to report the influence without adjusting for the assymetric scale
#' @param forceRecalulate if true, simply return the appropriate column from t if it exists already
#' @return a vector of influence for trial list t
getInfluence <- function (t, rawShift = FALSE, forceRecalculate = FALSE) {
# shortcut if we already calculated this
if('influence' %in% colnames(t) && !forceRecalculate)
return(t$influence)
out <- vector(length=dim(t)[1])
for (i in seq(length(out))) {
if (t$advisorId[i] == 0) { # no advisor
out[i] <- NA
} else {
if (t$advisorAgrees[i])
out[i] <- getConfidenceShift(t[i,], rawShift, forceRecalculate) # amount confidence increased
else
out[i] <- -1 * getConfidenceShift(t[i,], rawShift, forceRecalculate) # -1 * amount confidence increased
}
}
return(out)
}
#' Get the name of the advice type
#' @param adviceType the advice type to fetch the name for
#' @param long whether to return the long name
#' @return string of the advice type, or NA by default
getAdviceTypeName <- function(adviceType, long = FALSE) {
if(length(adviceType)>1) {
out <- NULL
for(aT in adviceType)
out <- c(out, getAdviceTypeName(aT))
return(out)
}
if(adviceType==adviceTypes$neutral)
return(ifelse(long, 'neutral', 'Ntl'))
if(adviceType==adviceTypes$AiC)
return(ifelse(long,'Agree-in-confidence', 'AiC'))
if(adviceType==adviceTypes$AiU)
return(ifelse(long,'Agree-in-uncertainty', 'AiU'))
if(adviceType==adviceTypes$HighAcc)
return(ifelse(long,'High accuracy', 'HighAcc'))
if(adviceType==adviceTypes$LowAcc)
return(ifelse(long,'Low accuracy', 'LowAcc'))
return(ifelse(long, 'None', NA))
}
#   0.iii) Globals ####
# advice types: neutral, agree-in-confidence, and agree-in-uncertainty
adviceTypes <- list(neutral=0, AiC=3, AiU=4, HighAcc=5, LowAcc=6)
trialTypes <- list(catch=0, force=1, choice=2)
confidenceCategories <- list(low=0, medium=1, high=2)
# Advisor questionnaire dimensions
questionnaireDimensions <- list(accurate=1,
like=2,
trust=3,
influence=4)
# The Advisor portraits have properties which might affect ratings, so we should investigate these:
portraitDetails <- data.frame(
portraitId = 1:5,
category = factor(c('w', 'b', 'w', 'b', 'w')),
blackProp = c(0, .99, 0, .99, .01),
age = c(28.7, 24.9, 23.3, 24.6, 23.7)
)
# styling for ggplots
style <- theme_light() +
theme(panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = 'top')
style.long <- style + theme(legend.position = 'none')
# 1) Load data  ####
#   1.i) Load data ####
print('Load data')
if(exists('trials'))
rm(trials)
if(exists('participants'))
rm(participants)
if(exists('advisors'))
rm(advisors)
if(exists('questionnaires'))
rm(questionnaires)
if(exists('genTrustQ'))
rm(genTrustQ)
folderName <- '../AdvisorChoice/data/processed/'
files <- list.files(folderName)
participants <- NULL
trials <- NULL
advisors <- NULL
questionnaires <- NULL
genTrustQ <- NULL
for (i in seq(length(files))) {
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
# store all columns in participants table except the three last
# (trials, advisors, and questionnaires are stored separately)
# Patch for missing data in practice
if(!('debriefComments' %in% names(jsonData)))
jsonData <- c(list(debriefComments = 'NA'), jsonData)
participants <- rbind(participants,
as.data.frame(t(jsonData[!names(jsonData) %in% c('advisors',
'questionnaires',
'trials',
'generalisedTrustQuestionnaire')])))
# store the trials in the trials table
trials <- rbind(trials, jsonData$trials)
advisors <- rbind(advisors, jsonData$advisors)
questionnaires <- rbind(questionnaires, jsonData$questionnaires)
if(('generalisedTrustQuestionnaire' %in% names(jsonData)))
genTrustQ <- rbind(genTrustQ, jsonData$generalisedTrustQuestionnaire)
}
rm(jsonData, files, fileName, folderName, json)
#   1.ii) Calculate utility variables ####
print('Calculate utility variables')
trials$adviceType <- getAdviceType(trials, participants, advisors) # adviceType > trials table
trials$confidenceShift <- getConfidenceShift(trials) #  amount the confidence changes
trials$confidenceShiftRaw <- getConfidenceShift(trials,T,T) # as above, without symmetry adjustment
trials$influence <- getInfluence(trials) # amount the confidence changes in the direction of the advice
trials$rawInfluence <- getInfluence(trials, T, T) # as above, without symmetry adjustment
trials$switch <- trials$initialAnswer != trials$finalAnswer # whether participant switched response
trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer # whether the initial answer is correct
trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer # whether the final answer is correct
# Sometimes it helps to see confidence arranged from sure left to sure right (-100 to 100)
trials$initialConfSpan <- ifelse(trials$initialAnswer==0,trials$initialConfidence*-1,trials$initialConfidence)
trials$finalConfSpan <- ifelse(trials$finalAnswer==0,trials$finalConfidence*-1,trials$finalConfidence)
# Was the response to the advice irrational?
trials$irrational <- (trials$advisorAgrees & trials$confidenceShift < 0) |
(!trials$advisorAgrees & trials$confidenceShift > 0)
# Convert times to seconds since the 70 epoch
participants$timeStart <- sapply(participants$timeStart, function(x)x[[1]]/1000)
participants$timeEnd <- sapply(participants$timeEnd, function(x)x[[1]]/1000)
# For convenience the long participant Id is shortened to a simple number:
participants$pid <- which(as.character(participants$id) == participants$id)
tmp <- function(x) participants$pid[which(participants$id == x)]
trials$pid <- sapply(trials$participantId, tmp)
questionnaires$pid <- sapply(questionnaires$participantId, tmp)
advisors$pid <- sapply(advisors$participantId, tmp)
genTrustQ$pid <- sapply(genTrustQ$participantId, tmp)
# adviceType > questionnaire table
aT <- vector(length = dim(questionnaires)[1])
timepoint <- aT
for (i in 1:dim(questionnaires)[1]) {
aT[[i]] <- getAdviceTypeById(questionnaires$advisorId[i], questionnaires$participantId[i], advisors)
# get the time point of the questionnaire (1=prospective, 2=retrospective)
timepoint[i] <- 1 +
as.numeric(questionnaires$afterTrial[i] >
mean(questionnaires$afterTrial[questionnaires$pid == questionnaires$pid[i]
& questionnaires$advisorId == questionnaires$advisorId[i]]))
}
questionnaires$adviceType <- aT
questionnaires$timepoint <- timepoint
# Stick the name and portrait data into the questionnaires table
questionnaires$advisorName <- factor(sapply(1:nrow(questionnaires), function(i)
advisors$name[advisors$pid==questionnaires$pid[i]
& advisors$id == questionnaires$advisorId[i]]))
questionnaires$advisorPortrait <- sapply(1:nrow(questionnaires), function(i) {
x <- advisors$portraitSrc[advisors$pid==questionnaires$pid[i]
& advisors$id == questionnaires$advisorId[i]]
x <- sub('assets/image/advisor', '', x, fixed = T)
as.factor(sub('.jpg', '', x, fixed = T))
})
# Add on the source data
questionnaires$advisorAge <- sapply(questionnaires$advisorPortrait, function(i) portraitDetails$age[i])
questionnaires$advisorCategory <- sapply(questionnaires$advisorPortrait, function(i) portraitDetails$category[i])
# The first general trust question is reverse coded
genTrustQ$answer <- as.numeric(genTrustQ$answer)
genTrustQ$answer[genTrustQ$order==0] <- 100 - genTrustQ$answer[genTrustQ$order==0]
#   1.iii) Split off real trials ####
print('Separate real trials from practice')
all.trials <- trials
trials <- trials[which(!trials$practice),]
all.questionnaires <- questionnaires
questionnaires <- questionnaires[which(questionnaires$adviceType!=0),]
all.advisors <- advisors
advisors <- advisors[which(advisors$adviceType!=0),]
# 2) Demographics ####
print('Demographics')
print('Demographic data are not collected and therefore not analysed')
# 3) Manipulation checks ####
print('Manipulation checks')
#   3.i) Overall agreement by contingency ####
# These advisors don't show contingent agreement, so there shouldn't be much
# here. This is retained mostly for comparison purposes
print('3.i Overall agreement by contingency')
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + initialCorrect, data = trials, FUN = mean)
aov.iii.i <- aov(advisorAgrees ~ confidenceCategory * adviceType * initialCorrect +
Error(pid / (confidenceCategory + adviceType + initialCorrect)), data = tmp)
print(summary(aov.iii.i))
#   3.ii) Graph: overall agreement by contingency ####
print('3.ii Graph of overall agreement by contingency')
w <- 0.8
gg.iii.ii <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and correctness') +
style
gg.iii.ii
#   3.iii) Initial block agreement by contingency ####
print('3.iii Initial block agreement by contingency')
# Initial block is forced trials
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + initialCorrect,
data = trials[trials$type==trialTypes$force, ], FUN = mean)
tmp.aov <- aov(advisorAgrees ~ confidenceCategory * adviceType * initialCorrect +
Error(pid / (confidenceCategory + adviceType + initialCorrect)), data = tmp)
summary(tmp.aov)
#   3.iv) Graph: initial block agreement by contingency ####
print('3.iv Graph of intial block agreement by contingency')
gg.iii.iv <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and correctness\n on forced trials') +
style
gg.iii.iv
print('3.iv.i Graph of agreement by block on initialCorrect trials')
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + typeName,
data = trials[trials$initialCorrect==T, ], FUN = mean)
tmp.aov <- aov(advisorAgrees ~ confidenceCategory * adviceType * typeName +
Error(pid / (confidenceCategory + adviceType + typeName)), data = tmp)
summary(tmp.aov)
gg.iii.iv.i <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~typeName, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and block\n on initially correct trials') +
style
gg.iii.iv.i
#   3.v) Trial count by contingency ####
print('3.v Trial count by contingency')
# Let's also check we got appropriate numbers of trials in each of the bins for
# each participant
df.iii.v <- aggregate(practice ~
pid + confidenceCategory + adviceType + initialCorrect + advisorAgrees,
data = trials, FUN = length)
#print(df.iii.v)
#   3.vi) Graph: trial count by contingency ####
print('3.vi Graph of trial count by contingency')
gg.iii.vi <- ggplot(df.iii.v, aes(y = practice, x = as.factor(confidenceCategory),
colour = as.factor(adviceType), shape = as.factor(advisorAgrees))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Trial Count') +
scale_shape_discrete(name = 'Advisor Agreement', labels = c('Disagree', 'Agree')) +
labs(title = 'Observed trial count for dis/agreement from each advisor by initial decision confidence\n and correctness') +
style
gg.iii.vi
# 4) Exclusions ####
print('Running exclusions')
# Exclusion rules:
# Proportion of correct initial judgements must be (.60 < cor1/n < .90)
#NB:practice trials are INCLUDED in this since they are used in part for
#determining confidence calibration
participants$excluded <- sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .85)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
# Clarify the numbers on the rules below
# All confidence categories must have at least 5% of the number of trials
if(any(cCs$pid < length(ts)*.05))
return('Confidence.cat')
return(F)
})
all.participants <- participants
participants <- participants[participants$excluded==F, ]
# Remove excluded participants' data from other data frames
trials <- trials[trials$pid %in% participants$pid, ]
advisors <- advisors[advisors$pid %in% participants$pid, ]
questionnaires <- questionnaires[questionnaires$pid %in% participants$pid, ]
df.iv <- aggregate(pid ~ excluded, data = all.participants, FUN = length)
names(df.iv) <- c('exclusionReason', 'count')
print(df.iv)
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoiceAccuracy.R')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoiceAccuracy.R')
source('F:/www/vhosts/localhost/ExploringSocialMetacognition/analysis/advisorChoiceAccuracy.R')
gg.iii.ii
gg.iii.iv
gg.iii.iv.i
gg.iii.vi
gg.v.iv
gg.vi.iii
g.vii.ii
gg.vii.ii
gg.viii.iii
gg.x.ii
gg.xi.i
gg.xi.ii
gg.xii
gg.xiii
