ts <- ts[!any(is.na(ts$initialConfidence), is.na(ts$initialCorrect)), ]
roc <- type2ROC(ts[ ,1], ts[ ,2], bins = 7)
df.type2 <- rbind(df.type2, data.frame(pid = factor(p), isRep = !x, conf = roc$x, pCorrect = roc$y))
}
}
tmp <- seq(0, 1, length.out = length(unique(df.type2$conf)))
tmp <- sapply(1:(length(tmp)-1), function(i) mean(c(tmp[i], tmp[i+1])))
df.type2$confProp <- sapply(df.type2$conf, function(x) tmp[which(levels(df.type2$conf) == x)])
tmp <- aggregate(pCorrect ~ conf + isRep, df.type2, mean)
# print neatly with rounding
tmp[ ,3] <- prop2str(tmp[ ,3])
kable(prop2str(tmp))
df.type2
tmp <- trials[trials$grid %in% trials$grid[!is.na(trials$stimulusParent)], ]
m <- is.na(tmp$stimulusParent)
df.type2 <- NULL
for(p in unique(trials$pid)) {
for(x in c(T, F)) {
ts <- tmp[m == x, c('initialCorrect', 'initialConfidence')]
ts <- ts[!is.na(ts$initialConfidence) & !is.na(ts$initialCorrect), ]
roc <- type2ROC(ts[ ,1], ts[ ,2], bins = 7)
df.type2 <- rbind(df.type2, data.frame(pid = factor(p), isRep = !x, conf = roc$x, pCorrect = roc$y))
}
}
tmp <- seq(0, 1, length.out = length(unique(df.type2$conf)))
tmp <- sapply(1:(length(tmp)-1), function(i) mean(c(tmp[i], tmp[i+1])))
df.type2$confProp <- sapply(df.type2$conf, function(x) tmp[which(levels(df.type2$conf) == x)])
tmp <- aggregate(pCorrect ~ conf + isRep, df.type2, mean)
# print neatly with rounding
tmp[ ,3] <- prop2str(tmp[ ,3])
kable(prop2str(tmp))
ggplot(df.type2, aes(x = confProp, y = pCorrect, colour = pid)) +
geom_abline(slope = 1, intercept = c(0,0), linetype = 'dashed', colour = 'black') +
geom_point() +
geom_line(alpha = .5, aes(group = pid)) +
facet_wrap(~'repeat', labeller = label_both) +
scale_x_continuous(limits = c(0,1)) +
coord_fixed() +
style.long +
theme(panel.spacing.x = unit(1, 'lines'))
ggplot(df.type2, aes(x = confProp, y = pCorrect, colour = pid)) +
geom_abline(slope = 1, intercept = c(0,0), linetype = 'dashed', colour = 'black') +
geom_point() +
geom_line(alpha = .5, aes(group = pid)) +
facet_wrap(~isRep, labeller = label_both) +
scale_x_continuous(limits = c(0,1)) +
coord_fixed() +
style.long +
theme(panel.spacing.x = unit(1, 'lines'))
if(!require(scoring)) {
install.packages('scoring')
library(scoring)
}
citation('scoring')
if(!require(digest)) {
install.packages('digest')
library(digest)
}
citation('digest')
# We use the Brier score
accuracy <- aggregate(finalCorrect ~ pid,
data = all.trials[!is.na(all.trials$finalCorrect), ],
FUN = mean)
tmp <- all.trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp, group = 'pid')
# We use the Brier score
accuracy <- aggregate(finalCorrect ~ pid,
data = all.trials[!is.na(all.trials$finalCorrect), ],
FUN = mean)
tmp <- all.trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp[!is.na(tmp$initialConfidence), ], group = 'pid')
scores
rawString <- "5c3a296afb7feb0001428a83
14/01/2019, 13:07
00:23:07
MX5PC2Z4
AWAITING REVIEW
5c377d7c10ecc800013b82d6
14/01/2019, 13:07
00:17:01
MX5PC2Z4
AWAITING REVIEW
5c3aea9cf5ebd500018551fa
14/01/2019, 13:11
N/A
RETURNED
5b06c34ed424fd0001eebda1
14/01/2019, 13:19
00:20:29
MX5PC2Z4
AWAITING REVIEW
5c3885dcf5ebd5000184defb "
if(exists('rawString')) {
prolificIds <- NULL
matches <- gregexpr('5[a-z0-9]{23}', rawString)
for(x in matches[[1]])
prolificIds <- c(prolificIds, substr(rawString, x, x+23))
}
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = all.participants$excluded[all.participants$pid==pid],
extra = all.participants$debriefComments[all.participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = all.participants$excluded[all.participants$pid==pid],
extra = all.participants$debriefComments[all.participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
results <- loadFilesFromFolder(folderName)
for(i in 1:length(results))
assign(names(results)[i], results[i][[1]])
trials <- cbind(trials, trialUtilityVariables(results))
all.trials <- trials
trials <- trials[trials$practice == F, ]
cat('Generated utility variables')
knitr::opts_chunk$set(echo = F)
startTime <- Sys.time()
source('src/ESM_core.R')
folderName <- "G:\\Documents\\University\\Google Drive\\Temp\\data\\processed"
results <- loadFilesFromFolder(folderName)
for(i in 1:length(results))
assign(names(results)[i], results[i][[1]])
if(!require(scoring)) {
install.packages('scoring')
library(scoring)
}
citation('scoring')
if(!require(digest)) {
install.packages('digest')
library(digest)
}
citation('digest')
# We use the Brier score
accuracy <- aggregate(finalCorrect ~ pid,
data = all.trials[!is.na(all.trials$finalCorrect), ],
FUN = mean)
tmp <- all.trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp[!is.na(tmp$initialConfidence), ], group = 'pid')
# We use the Brier score
accuracy <- aggregate(finalCorrect ~ pid,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
# We use the Brier score
trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer
accuracy <- aggregate(finalCorrect ~ pid,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
names(trials)
trials$pid <- sapply(trials$participantId, function(x) which(unique(trials$participantId)==x))
trials$pid
accuracy <- aggregate(finalCorrect ~ pid,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
tmp <- trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'pid')]
trials$initialCorrect <- trials$finalAnswer == trials$correctAnswer
tmp <- trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp[!is.na(tmp$initialConfidence), ], group = 'pid')
tmp
trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp[!is.na(tmp$initialConfidence), ], group = 'pid')
tmp
tmp <- trials[,c('initialCorrect', 'finalCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp[!is.na(tmp$initialConfidence), ], group = 'pid')
rawString <- '5c3a296afb7feb0001428a83
14/01/2019, 13:07
00:23:07
MX5PC2Z4
AWAITING REVIEW
5c377d7c10ecc800013b82d6
14/01/2019, 13:07
00:17:01
MX5PC2Z4
AWAITING REVIEW
5c3aea9cf5ebd500018551fa
14/01/2019, 13:11
N/A
RETURNED
5b06c34ed424fd0001eebda1
14/01/2019, 13:19
00:20:29
MX5PC2Z4
AWAITING REVIEW
5c3885dcf5ebd5000184defb '
if(exists('rawString')) {
prolificIds <- NULL
matches <- gregexpr('5[a-z0-9]{23}', rawString)
for(x in matches[[1]])
prolificIds <- c(prolificIds, substr(rawString, x, x+23))
}
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
prolificIds
unique(trials$participantId)
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$participantId[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
scores$brieravg
prolificIdHashes
unique(trials$participantId)
participants$id
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
proId
prolificIdHashes %in% participants$id[participants$pid==pid]
participants$id
participants$pid <- sapply(participants$id, function(x) which(unique(participants$id)==x))
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
proId
accuracy <- aggregate(finalCorrect ~ pid,
data = trials[!is.na(trials$finalCorrect), ],
FUN = mean)
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
accuracy <- aggregate(initialCorrect ~ pid, data = trials[!is.na(trials$initialCorrect), ], FUN = mean)
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
finalAccuracy = accuracy$finalCorrect[accuracy$pid == pid],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
pid
prolificId
proId
scores$brieravg[i]
accuracy
accuracy[accuracy$pid == pid, 2]
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% participants$id[participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
accuracy = accuracy[accuracy$pid == pid, 2],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
# ascribe bonuses based on performance
tmp$reward <- 0
for(dim in c('brieravg', 'finalAccuracy')) {
markers <- quantile(tmp[tmp$excluded==F, dim], na.rm = T)
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp[i, dim])[1]
tmp$reward[i] <- tmp$reward[i] + round(1 - 1/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
}
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
participants$excluded[participants$pid==pid]
participants$debriefComments[participants$pid==pid])
participants$debriefComments[participants$pid==pid]
