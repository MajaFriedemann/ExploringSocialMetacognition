meanAccuracy = cl$y,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.vi[,-(1:2)] <- round(df.vi[,-(1:2)],2)
kable(df.vi)
# Chunk 20
tmp <- aggregate(adviceType ~ pid,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.vi.i <- t.test(tmp$adviceType, mu=0.5)
d <- cohensD(tmp$adviceType, mu = 0.5)
tB.vi.i <- ttestBF(tmp$adviceType, mu = 0.5)
printMean(tmp$adviceType, 'Mean HighAcc pick rate')
print('Choice proportion HighAcc vs. chance level (.5)')
prettyPrint(t.vi.i, d)
print('Bayesian examination of above (prior = mean of 0.5, sd as empirically observed)')
print(tB.vi.i)
print(paste0('Evidence strength for preferential HighAcc picking: BF=', round(exp(tB.vi.i@bayesFactor$bf),3)))
# Chunk 21
tmp <- aggregate(adviceType ~ pid,
data = trials[trials$type==trialTypes$choice
& trials$confidenceCategory==confidenceCategories$medium, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.vi.ii <- t.test(tmp$adviceType, mu=0.5)
d <- cohensD(tmp$adviceType, mu=0.5)
tB.vi.ii <- ttestBF(tmp$adviceType, mu = 0.5)
printMean(tmp$adviceType, 'Mean HighAcc pick rate')
print('Choice proportion HighAcc vs. chance level (.5) for mid-confidence trials')
prettyPrint(t.vi.ii,d)
print('Bayesian examination of above (prior = mean of 0.5, sd as empirically observed)')
print(tB.vi.ii)
print(paste0('Evidence strength for preferential HighAcc picking: BF=', round(exp(tB.vi.ii@bayesFactor$bf),3)))
# Chunk 22
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
tmp.2 <- aggregate(adviceType ~ pid,
data = trials[trials$type == trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
gg.vi.iii <- ggplot(tmp, aes(x = factor(confidenceCategory), y = adviceType)) +
geom_hline(linetype = "dashed", color = "black", yintercept = .5, size = 1) +
geom_point(aes(color = factor(pid))) +
geom_line(aes(group = factor(pid), color = factor(pid))) +
stat_summary(geom = "errorbar", fun.data = "mean_cl_boot", width = 0.1) +
stat_summary(geom = "point", fun.y = "mean", shape = 23, fill = "black", size = 4) +
geom_point(position = position_jitter(w=0.03, h=0),
aes(x="Overall", color = factor(pid)),
data = tmp.2) +
stat_summary(geom = "errorbar", fun.data = "mean_cl_boot", width = 0.1,
aes(x="Overall"), data = tmp.2) +
stat_summary(geom = "point", fun.y = "mean", shape = 23, fill = "black", size = 4,
aes(x="Overall"), data = tmp.2) +
scale_y_continuous(limits = c(0,1), expand = c(0.05,0)) +
scale_x_discrete(expand = c(0,1), labels = c('Low', 'Medium',
'High', 'Overall')) +
scale_color_discrete(name = 'Participant') +
labs(title = "Advisor preference",
legend = NULL,
x = "Confidence",
y = "P(HighAcc advisor is chosen)") +
style.long
gg.vi.iii
# Chunk 23
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.i <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('2x2x2 Mixed ANOVA of advisor type x choice x agreement')
print(summary(aov.vii.i))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
# Chunk 24
tmp$adviceType <- factor(tmp$adviceType)
gg.vii.ii <- ggplot(tmp, aes(advisorAgrees, influence, color = adviceType, fill = adviceType)) +
geom_point(position = position_jitter(w=0.1, h=0), alpha = 0.5) +
stat_summary(geom = "errorbar",
fun.data = "mean_cl_boot",
width = 0.2) +
stat_summary(geom = "point",
fun.y = "mean",
shape = 23, size = 5) +
stat_summary(aes(group = adviceType), fun.y=mean, geom="line") +
facet_grid(.~hasChoice,
labeller = as_labeller(c('FALSE'='Forced trials','TRUE'='Choice trials'))) +
scale_color_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_x_discrete(name = 'Judge-advisor agreement', labels = c('Disagree', 'Agree')) +
labs(title = "Advice Influence",
legend = NULL,
y = "Influence of the advice") +
style
gg.vii.ii
# Chunk 25
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid,
data = trials[trials$confidenceCategory==confidenceCategories$medium
& trials$finalAnswer==trials$correctAnswer, ],
FUN = mean)
aov.vii.iii <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('As above, looking at only trials where intial decision was correct and made with middle confidence:')
print(summary(aov.vii.iii))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
# Chunk 26
tmp <- aggregate(rawInfluence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.iv <- aov(rawInfluence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('Original mixed ANOVA using raw influence scores')
print(summary(aov.vii.iv))
print('Means:')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$rawInfluence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$rawInfluence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$rawInfluence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$rawInfluence[!tmp$advisorAgrees], 'Mean|Disagree')
# Chunk 27
tmp <- trials
tmp$influenceChanges <- (tmp$rawInfluence - tmp$influence) != 0
tmp.2 <- aggregate(influenceChanges ~ pid, tmp, mean)
cl <- mean_cl_normal(tmp.2$influenceChanges)
rn <- range(tmp.2$influenceChanges)
df.vii.i <- data.frame('P(influenceChanges)'=cl$y,
clLow=cl$ymin, clHigh=cl$ymax,
rangeLow=rn[1], rangeHigh=rn[2])
kable(df.vii.i)
# Chunk 28
df.viii.i.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
x <- questionnaires[questionnaires$advisorCategory=='b',v]
y <- questionnaires[questionnaires$advisorCategory=='w',v]
bf <- ttestBF(x,y)
df.viii.i.i <- rbind(df.viii.i.i, data.frame(variable = v,
BF = exp(bf@bayesFactor$bf),
mu1 = mean(x),
mu2 = mean(y)))
}
kable(df.viii.i.i)
# Chunk 29
df.viii.i.ii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp <- correlationBF(questionnaires[,v], questionnaires[,'advisorAge'])
df.viii.i.ii <- rbind(df.viii.i.ii, data.frame(variable = v,
corellationBF = exp(tmp@bayesFactor$bf)))
}
kable(df.viii.i.ii)
# Chunk 30
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorPortrait + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iii <- rbind(df.viii.i.iii, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
kable(df.viii.i.iii)
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iv <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorName + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iv <- rbind(df.viii.i.iv, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
kable(df.viii.i.iv)
aov.viii.ii <- manova(cbind(ability, likeability, benevolence) ~ adviceType * timepoint,# + Error(pid),
data = questionnaires)
print(summary(aov.viii.ii))
df.viii.ii <- NULL
tmp <- questionnaires[ ,c('likeability', 'benevolence', 'ability', 'pid', 'adviceType', 'timepoint')]
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[ ,v]
tmp.2 <- aggregate(v ~ adviceType + timepoint + pid,
data = tmp,
FUN = mean)
for(aT in c(5,6)) {
if(aT == adviceTypes$neutral)
next()
for(tp in unique(tmp.2$timepoint)) {
x <- tmp.2$v[tmp.2$adviceType==aT & tmp.2$timepoint==tp]
df.viii.ii <- rbind(df.viii.ii, data.frame(domain = v,
adviceType=aT,
timepoint=tp,
mu=mean(x),
ci95low=mean_cl_normal(x)$ymin,
ci95hi =mean_cl_normal(x)$ymax))
}
}
}
df.viii.ii[ ,4:6] <- round(df.viii.ii[ ,4:6],2)
df.viii.ii$adviceType <- sapply(df.viii.ii$adviceType, getAdviceTypeName)
kable(df.viii.ii[order(df.viii.ii$timepoint), ])
# TODO ####
# tidy the hell out of this graph. Should allow easy discrimination
# between advice type assessment changes over time.
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
tmp <- melt(tmp, id.vars = c('adviceType', 'timepoint', 'pid'))
gg.viii.iii <- ggplot(tmp, aes(x = variable, y = value, colour = as.factor(timepoint))) +
geom_boxplot() +
scale_y_continuous(limits = c(0,100)) +
facet_grid(~ adviceType) +
style
gg.viii.iii
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.ix.i <- t.test(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
d <- cohensD(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high])
tB.ix.i <- ttestBF(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
print('Choice proportion HighAcc in low- vs high-confidence trials')
prettyPrint(t.ix.i,d)
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low], 'low')
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high], 'high')
print('Bayesian examination of above (prior = mean diff of 0, sd as empirically observed)')
print(tB.ix.i)
print(paste0('Evidence strength for differential high/low confidence picking strategy: BF=',
round(exp(tB.ix.i@bayesFactor$bf),3)))
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
# calculate difference scores
for(i in 1:nrow(tmp))
if(tmp$timepoint[i]==2)
tmp[i,4:6] <- tmp[i, 4:6] - tmp[tmp$timepoint==1
& tmp$pid == tmp$pid[i]
& tmp$adviceType == tmp$adviceType[i], 4:6]
tmp.2 <- aggregate(influence ~ adviceType + pid + hasChoice,
data = trials, FUN = mean)
tmp$influence <- sapply(1:nrow(tmp), function(i){tmp.2$influence[tmp.2$hasChoice
& tmp.2$pid == tmp$pid[i]
& tmp.2$adviceType == tmp$adviceType[i]]})
tmp$influence <- as.numeric(tmp$influence)
# The test is a regression with the change in subjective variables as predictors
lm.x.i <- lm(influence ~ ability + benevolence + likeability, data = tmp)
print(summary(lm.x.i))
tmp <- melt(tmp[tmp$timepoint==2, ], id.vars = c('adviceType', 'pid', 'timepoint', 'influence'),
measure.vars = c('likeability', 'ability', 'benevolence'),
variable.name = 'trustDimension', value.name = 'trust')
gg.x.ii <- ggplot(tmp, aes(x = trust, y = influence, colour = factor(adviceType))) +
geom_point(alpha = 0.33) +
geom_smooth(method = 'lm', aes(fill = factor(adviceType)), alpha = 0.1) +
facet_grid(trustDimension ~ .) +
coord_fixed(ratio = 3, expand = F) +
scale_x_continuous(name = 'Trust change') +
scale_y_continuous(name = 'Influence') +
scale_color_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
style
gg.x.ii
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ pid,
data = questionnaires[questionnaires$timepoint==1,],
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.i <- rbind(df.xi.i, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
kable(df.xi.i)
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ pid,
data = questionnaires[questionnaires$timepoint==1,],
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.i <- rbind(df.xi.i, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
kable(df.xi.i)
tmp.2 <- melt(tmp, id.vars = c('pid'), measure.vars = c('likeability', 'ability', 'benevolence'))
tmp.2$genTrust <- sapply(tmp.2$pid, function(x) tmp$genTrust[tmp$pid==x][1])
gg.xi.i <- ggplot(tmp.2, aes(x = genTrust, y = value)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
facet_grid(variable ~ .) +
style.long
gg.xi.i
tmp <- aggregate(cbind(influence, rawInfluence) ~ pid,
data = trials,
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.ii <- NULL
for(v in c('rawInfluence', 'influence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.ii <- rbind(df.xi.ii, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
kable(df.xi.ii)
gg.xi.ii <- ggplot(tmp, aes(x = genTrust, y = influence)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
style.long
gg.xi.ii
df.xii.i.i <- NULL
for(pid in unique(participants$pid)) {
tmp <- trials[trials$type==trialTypes$choice & trials$pid==pid, ]
df.xii.i.i <- rbind(df.xii.i.i, data.frame(pid,
HighAccPref=mean(tmp$adviceType==adviceTypes$HighAcc),
InfluenceDiff=(sum(tmp$influence[tmp$adviceType==adviceTypes$HighAcc]) -
sum(tmp$influence[tmp$adviceType==adviceTypes$LowAcc]))))
}
cor.test(df.xii.i.i$HighAccPref, df.xii.i.i$InfluenceDiff)
correlationBF(df.xii.i.i$HighAccPref, df.xii.i.i$InfluenceDiff)
gg.xii.i.i <- ggplot(df.xii.i.i, aes(x = HighAccPref, y = InfluenceDiff)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and preference for high-accuracy advisor') +
style.long
gg.xii.i.i
df.xii.i.ii <- NULL
for(pid in unique(participants$pid)) {
for(block in c(3,5)) {
# Look for the favourate advisor in each block and use the preference strength for that advisor
tmp <- trials[trials$block==block & trials$pid==pid, ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc)>.5, adviceTypes$HighAcc, adviceTypes$LowAcc)
df.xii.i.ii <- rbind(df.xii.i.ii, data.frame(pid,
PrefStrength=mean(tmp$adviceType==aid),
InfluenceDiff=(sum(tmp$influence[tmp$adviceType==aid]) -
sum(tmp$influence[tmp$adviceType!=aid]))))
}
}
df.xii.i.ii <- aggregate(. ~ pid, df.xii.i.ii, FUN = mean) # reaggregate
cor.test(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
correlationBF(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
gg.xii.i.ii <- ggplot(df.xii.i.ii, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and \npreference strength for preferred advisor') +
style.long
gg.xii.i.ii
df.xii.ii.i <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
df.xii.ii.i <- rbind(df.xii.ii.i,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
DotDiffCoef=lm(dotDifference ~ id, tmp)$coefficients[2]))
}
cor.test(df.xii.ii.i$HighAccPref, df.xii.ii.i$DotDiffCoef)
correlationBF(df.xii.ii.i$HighAccPref, df.xii.ii.i$DotDiffCoef)
gg.xii.ii.i <- ggplot(df.xii.ii.i, aes(x = HighAccPref, y = DotDiffCoef)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between dot difference increase and \nHighAcc advisor preference') +
style.long
gg.xii.ii.i
df.xii.ii.ii <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
df.xii.ii.ii <- rbind(df.xii.ii.ii,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
Resolution=lm(initialCorrect ~ initialConfidence, tmp)$coefficients[2]))
}
cor.test(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
correlationBF(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
gg.xii.ii.ii <- ggplot(df.xii.ii.ii, aes(x = HighAccPref, y = Resolution)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between metacognitive resolution and \nHighAcc advisor preference') +
style.long
gg.xii.ii.ii
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = .5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
labs(title = 'P(Correct) by confidence for initial responses') +
style.long
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$estimate, 'p'=x$p.value, 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$estimate, 'pDiff'=x2$p.value, 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
# 12) Predicting advisor from confidence ####
print('12 Predicting advisor from confidence')
df.xii <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
tmp$adviceType <- as.factor(tmp$adviceType)
ans <- glm(adviceType ~ initialConfidence, tmp, family = binomial(link = "logit"))
s <- summary(ans)
df.xii <- rbind(df.xii, data.frame(pid,
coef = s$coefficients[2,1],
p = s$coefficients[2,4]))
}
tmp <- df.xii
names(tmp)[2] <- 'y'
tmp$x <- 0
gg.xii <- ggplot(tmp, aes(x = p)) + geom_freqpoly(binwidth = 0.1)
gg.xii
# 13) Influence strength by confidence category ####
print('13 Influence strength by confidence category')
tmp <- aggregate(influence ~ confidenceCategory + pid, data = trials, FUN = mean)
gg.xiii <- ggplot(tmp, aes(x = confidenceCategory, y = influence)) +
geom_point(aes(colour = as.factor(pid)), alpha = 0.5) +
geom_smooth(method = 'lm',
aes(group = as.factor(pid), colour = as.factor(pid)),
se = F,
alpha = 0.2) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot) +
style.long
gg.xiii
summary(aov(influence ~ confidenceCategory, data = tmp))
# 14) Confidence autocorrelation plots by participant ####
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid == pid, ]
ggplot(tmp, aes(x = initialConfSpan, y = finalConfSpan)) +
geom_polygon(data = df.poly1, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_polygon(data = df.poly2, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_point(alpha = 0.2, aes(color = factor(finalCorrect))) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed', size = 1, color = 'black') +
scale_color_discrete(name = 'Final judgement', labels = c('Incorrect', 'Correct')) +
scale_x_continuous(limits = c(-50,50), expand = c(0,0)) +
scale_y_continuous(limits = c(-50,50), expand = c(0,0)) +
facet_grid(~advisorAgrees, labeller = as_labeller(c('FALSE'='Disagree', 'TRUE'='Agree'))) +
labs(title = paste('PID:', pid, 'Initial vs final confidence'),
legend = NULL,
x = 'Initial confidence',
y = "Final confidence") +
coord_fixed() +
style +
theme(panel.spacing = unit(1.5, 'lines'),
plot.margin = unit(c(0,1,0,0.5), 'lines'))
#ggsave(paste0('explore/autocorrelations/pid', pid, '.png'), width = 8.96, height = 5.97, units = 'in')
}
# 15) Examining dot difference ####
library(gganimate)
g <- ggplot(trials, aes(x = id, y = dotDifference)) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(0,246)) +
style.long +
labs(title = 'Participant {frame_time}') +
transition_time(pid)
animate(g, fps = 1)
ggplot(all.trials, aes(x = id, y = dotDifference, colour = as.factor(pid))) +
geom_line() +
geom_smooth(method = 'lm', se = F) +
scale_x_continuous(limits = c(0,246)) +
style.long
