trials$adviceType <- getAdviceType(trials, participants, advisors) # adviceType > trials table
trials$confidenceShift <- getConfidenceShift(trials) #  amount the confidence changes
trials$confidenceShiftRaw <- getConfidenceShift(trials,T,T) # as above, without symmetry adjustment
trials$influence <- getInfluence(trials) # amount the confidence changes in the direction of the advice
trials$rawInfluence <- getInfluence(trials, T, T) # as above, without symmetry adjustment
trials$switch <- trials$initialAnswer != trials$finalAnswer # whether participant switched response
trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer # whether the initial answer is correct
trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer # whether the final answer is correct
# Sometimes it helps to see confidence arranged from sure left to sure right (-100 to 100)
trials$initialConfSpan <- ifelse(trials$initialAnswer==0,trials$initialConfidence*-1,trials$initialConfidence)
trials$finalConfSpan <- ifelse(trials$finalAnswer==0,trials$finalConfidence*-1,trials$finalConfidence)
# Convert times to seconds since the 70 epoch
participants$timeStart <- sapply(participants$timeStart, function(x)x[[1]]/1000)
participants$timeEnd <- sapply(participants$timeEnd, function(x)x[[1]]/1000)
# For convenience the long participant Id is shortened to a simple number:
participants$pid <- which(as.character(participants$id) == participants$id)
tmp <- function(x) participants$pid[which(participants$id == x)]
trials$pid <- sapply(trials$participantId, tmp)
questionnaires$pid <- sapply(questionnaires$participantId, tmp)
advisors$pid <- sapply(advisors$participantId, tmp)
genTrustQ$pid <- sapply(genTrustQ$participantId, tmp)
# adviceType > questionnaire table
aT <- vector(length = dim(questionnaires)[1])
timepoint <- aT
for (i in 1:dim(questionnaires)[1]) {
aT[[i]] <- getAdviceTypeById(questionnaires$advisorId[i], questionnaires$participantId[i], advisors)
# get the time point of the questionnaire (1=prospective, 2=retrospective)
timepoint[i] <- 1 +
as.numeric(questionnaires$afterTrial[i] >
mean(questionnaires$afterTrial[questionnaires$pid == questionnaires$pid[i]
& questionnaires$advisorId == questionnaires$advisorId[i]]))
}
questionnaires$adviceType <- aT
questionnaires$timepoint <- timepoint
# Stick the name and portrait data into the questionnaires table
questionnaires$advisorName <- factor(sapply(1:nrow(questionnaires), function(i)
advisors$name[advisors$pid==questionnaires$pid[i]
& advisors$id == questionnaires$advisorId[i]]))
questionnaires$advisorPortrait <- sapply(1:nrow(questionnaires), function(i) {
x <- advisors$portraitSrc[advisors$pid==questionnaires$pid[i]
& advisors$id == questionnaires$advisorId[i]]
x <- sub('assets/image/advisor', '', x, fixed = T)
as.factor(sub('.jpg', '', x, fixed = T))
})
# Add on the source data
questionnaires$advisorAge <- sapply(questionnaires$advisorPortrait, function(i) portraitDetails$age[i])
questionnaires$advisorCategory <- sapply(questionnaires$advisorPortrait, function(i) portraitDetails$category[i])
# The first general trust question is reverse coded
genTrustQ$answer <- as.numeric(genTrustQ$answer)
genTrustQ$answer[genTrustQ$order==0] <- 100 - genTrustQ$answer[genTrustQ$order==0]
install.packages('yaml')
# 0) Support ####
#   0.i) Libraries ####
if(!require(jsonlite)) {
install.packages("jsonlite")
library(jsonlite)
}
if(!require(BayesFactor)) {
install.packages('BayesFactor')
library(BayesFactor)
}
if(!require(tidyverse)) {
install.packages('tidyverse')
library(tidyverse)
}
if(!require(reshape2)) {
install.packages('reshape2')
library(reshape2)
}
if(!require(lme4)) {
install.packages('lme4')
library(lme4)
}
#   0.ii) Functions ####
# Print the results of a t-test as we would like to see them reported in a paper
prettyPrint <- function(results) {
print(paste0('t(',results$parameter,')=',round(results$statistic,2),
' [',round(attr(results$conf.int, "conf.level")*100),'%CI: ',
round(results$conf.int[[1]],2), ', ', round(results$conf.int[[2]],2),'],',
' p=',round(results$p.value,3)))
}
# Return the advice type of an advisor for participant with row number=pid
getAdviceTypeById <- function(aid, pid, advisor.data.frame) {
type <- advisor.data.frame[which(advisor.data.frame$participantId==pid),]
type <- type[which(type$id==aid),]
if (length(type) > 0)
return(type$adviceType)
return(NA)
}
# Return a vector of advice types for trial list t
getAdviceType <- function (t, participant.data.frame, advisor.data.frame, forceRecalculate = FALSE) {
# shortcut if we already calculated this
if('adviceType' %in% colnames(t) && !forceRecalculate)
return(t$adviceType)
out <- vector(length=dim(t)[1])
for (i in seq(length(out))) {
if (t$advisorId[i]==0) {
# no advisor
out[i] <- NA;
} else {
pid <- t$participantId[i]
out[i] <- getAdviceTypeById(t$advisorId[i], pid, advisor.data.frame)
}
}
return(out)
}
#' Find the confidence shift in a given trial
#' @param t trial list
#' @param rawShift whether to report the confidence shift without adjusting for the assymetric scale
#' @param forceRecalulate if true, simply return the appropriate column from t if it exists already
#' @return a vector of confidence shifts for trial list t
getConfidenceShift <- function (t, rawShift = FALSE, forceRecalculate = FALSE) {
scaleMaximum <- 50
# shortcut if we already calculated this
if('confidenceShift' %in% colnames(t) && !forceRecalculate)
return(t$confidenceShift)
out <- vector(length=dim(t)[1])
for (i in seq(length(out))) {
if (is.na(t$finalConfidence[i])) { # no advisor
out[i] <- NA
} else {
max.shift <- scaleMaximum - t$initialConfidence[i]
if(t$initialAnswer[i]==t$finalAnswer[i])
out[i] <- t$finalConfidence[i]-t$initialConfidence[i] # same side
else
out[i] <- -1 * (t$finalConfidence[i]+t$initialConfidence[i]) # switched sliders, so went to 0 on the first one
out[i] <- ifelse(abs(out[i] > max.shift), max.shift*sign(out[i]), out[i])
}
}
return(out)
}
# Return a vector of influence for trial list t
#' @param t trial list
#' @param rawShift whether to report the influence without adjusting for the assymetric scale
#' @param forceRecalulate if true, simply return the appropriate column from t if it exists already
#' @return a vector of influence for trial list t
getInfluence <- function (t, rawShift = FALSE, forceRecalculate = FALSE) {
# shortcut if we already calculated this
if('influence' %in% colnames(t) && !forceRecalculate)
return(t$influence)
out <- vector(length=dim(t)[1])
for (i in seq(length(out))) {
if (t$advisorId[i] == 0) { # no advisor
out[i] <- NA
} else {
if (t$advisorAgrees[i])
out[i] <- getConfidenceShift(t[i,], rawShift, forceRecalculate) # amount confidence increased
else
out[i] <- -1 * getConfidenceShift(t[i,], rawShift, forceRecalculate) # -1 * amount confidence increased
}
}
return(out)
}
#' Get the name of the advice type
#' @param adviceType the advice type to fetch the name for
#' @param long whether to return the long name
#' @return string of the advice type, or NA by default
getAdviceTypeName <- function(adviceType, long = FALSE) {
if(adviceType==adviceTypes$neutral)
return(ifelse(long, 'neutral', 'Ntl'))
if(adviceType==adviceTypes$AiC)
return(ifelse(long,'Agree-in-confidence', 'AiC'))
if(adviceType==adviceTypes$AiU)
return(ifelse(long,'Agree-in-uncertainty', 'AiU'))
return(ifelse(long, 'None', NA))
}
#   0.iii) Globals ####
# advice types: neutral, agree-in-confidence, and agree-in-uncertainty
adviceTypes <- list(neutral=0, AiC=3, AiU=4)
trialTypes <- list(catch=0, force=1, choice=2)
confidenceCategories <- list(low=0, medium=1, high=2)
# Advisor questionnaire dimensions
questionnaireDimensions <- list(accurate=1,
like=2,
trust=3,
influence=4)
# The Advisor portraits have properties which might affect ratings, so we should investigate these:
portraitDetails <- data.frame(
portraitId = 1:5,
category = factor(c('w', 'b', 'w', 'b', 'w')),
blackProp = c(0, .99, 0, .99, .01),
age = c(28.7, 24.9, 23.3, 24.6, 23.7)
)
# styling for ggplots
style <- theme_light() +
theme(panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = 'top')
# 1) Load data  ####
#   1.i) Load data ####
print('Load data')
if(exists('trials'))
rm(trials)
if(exists('participants'))
rm(participants)
if(exists('advisors'))
rm(advisors)
if(exists('questionnaires'))
rm(questionnaires)
if(exists('genTrustQ'))
rm(genTrustQ)
folderName <- '../AdvisorChoice/data/processed/'
files <- list.files(folderName)
participants <- NULL
trials <- NULL
advisors <- NULL
questionnaires <- NULL
genTrustQ <- NULL
for (i in seq(length(files))) {
fileName <- paste(folderName, files[[i]], sep='/')
json <- readChar(fileName, file.info(fileName)$size)
jsonData <- fromJSON(json, simplifyVector = T, simplifyMatrix = T, simplifyDataFrame = T)
# store all columns in participants table except the three last
# (trials, advisors, and questionnaires are stored separately)
# Patch for missing data in practice
if(!('debriefComments' %in% names(jsonData)))
jsonData <- c(list(debriefComments = 'NA'), jsonData)
participants <- rbind(participants,
as.data.frame(t(jsonData[!names(jsonData) %in% c('advisors',
'questionnaires',
'trials',
'generalisedTrustQuestionnaire')])))
# store the trials in the trials table
trials <- rbind(trials, jsonData$trials)
advisors <- rbind(advisors, jsonData$advisors)
questionnaires <- rbind(questionnaires, jsonData$questionnaires)
if(('generalisedTrustQuestionnaire' %in% names(jsonData)))
genTrustQ <- rbind(genTrustQ, jsonData$generalisedTrustQuestionnaire)
}
rm(jsonData, files, fileName, folderName, json)
#   1.ii) Calculate utility variables ####
print('Calculate utility variables')
trials$adviceType <- getAdviceType(trials, participants, advisors) # adviceType > trials table
trials$confidenceShift <- getConfidenceShift(trials) #  amount the confidence changes
trials$confidenceShiftRaw <- getConfidenceShift(trials,T,T) # as above, without symmetry adjustment
trials$influence <- getInfluence(trials) # amount the confidence changes in the direction of the advice
trials$rawInfluence <- getInfluence(trials, T, T) # as above, without symmetry adjustment
trials$switch <- trials$initialAnswer != trials$finalAnswer # whether participant switched response
trials$initialCorrect <- trials$initialAnswer == trials$correctAnswer # whether the initial answer is correct
trials$finalCorrect <- trials$finalAnswer == trials$correctAnswer # whether the final answer is correct
# Sometimes it helps to see confidence arranged from sure left to sure right (-100 to 100)
trials$initialConfSpan <- ifelse(trials$initialAnswer==0,trials$initialConfidence*-1,trials$initialConfidence)
trials$finalConfSpan <- ifelse(trials$finalAnswer==0,trials$finalConfidence*-1,trials$finalConfidence)
# Convert times to seconds since the 70 epoch
participants$timeStart <- sapply(participants$timeStart, function(x)x[[1]]/1000)
participants$timeEnd <- sapply(participants$timeEnd, function(x)x[[1]]/1000)
# For convenience the long participant Id is shortened to a simple number:
participants$pid <- which(as.character(participants$id) == participants$id)
tmp <- function(x) participants$pid[which(participants$id == x)]
trials$pid <- sapply(trials$participantId, tmp)
questionnaires$pid <- sapply(questionnaires$participantId, tmp)
advisors$pid <- sapply(advisors$participantId, tmp)
genTrustQ$pid <- sapply(genTrustQ$participantId, tmp)
# adviceType > questionnaire table
aT <- vector(length = dim(questionnaires)[1])
timepoint <- aT
for (i in 1:dim(questionnaires)[1]) {
aT[[i]] <- getAdviceTypeById(questionnaires$advisorId[i], questionnaires$participantId[i], advisors)
# get the time point of the questionnaire (1=prospective, 2=retrospective)
timepoint[i] <- 1 +
as.numeric(questionnaires$afterTrial[i] >
mean(questionnaires$afterTrial[questionnaires$pid == questionnaires$pid[i]
& questionnaires$advisorId == questionnaires$advisorId[i]]))
}
questionnaires$adviceType <- aT
questionnaires$timepoint <- timepoint
# Stick the name and portrait data into the questionnaires table
questionnaires$advisorName <- factor(sapply(1:nrow(questionnaires), function(i)
advisors$name[advisors$pid==questionnaires$pid[i]
& advisors$id == questionnaires$advisorId[i]]))
questionnaires$advisorPortrait <- sapply(1:nrow(questionnaires), function(i) {
x <- advisors$portraitSrc[advisors$pid==questionnaires$pid[i]
& advisors$id == questionnaires$advisorId[i]]
x <- sub('assets/image/advisor', '', x, fixed = T)
as.factor(sub('.jpg', '', x, fixed = T))
})
# Add on the source data
questionnaires$advisorAge <- sapply(questionnaires$advisorPortrait, function(i) portraitDetails$age[i])
questionnaires$advisorCategory <- sapply(questionnaires$advisorPortrait, function(i) portraitDetails$category[i])
# The first general trust question is reverse coded
genTrustQ$answer <- as.numeric(genTrustQ$answer)
genTrustQ$answer[genTrustQ$order==0] <- 100 - genTrustQ$answer[genTrustQ$order==0]
genTrustQ$answer[genTrustQ$order==0]
100 - genTrustQ$answer[genTrustQ$order==0]
genTrustQ$answer[genTrustQ$order==0] <- 100 - genTrustQ$answer[genTrustQ$order==0]
genTrustQ$answer[genTrustQ$order==0] <- 100 - genTrustQ$answer[genTrustQ$order==0]
#   1.iii) Split off real trials ####
print('Separate real trials from practice')
all.trials <- trials
trials <- trials[which(!trials$practice),]
all.questionnaires <- questionnaires
questionnaires <- questionnaires[which(questionnaires$adviceType!=0),]
all.advisors <- advisors
advisors <- advisors[which(advisors$adviceType!=0),]
# 2) Demographics ####
print('Demographics')
print('Demographic data are not collected and therefore not analysed')
# 3) Manipulation checks ####
print('Manipulation checks')
#   3.i) Overall agreement by contingency ####
# We need to check the advisors did what they were supposed to do, i.e. that the
# AiC advisors agreed more on confident trials, and the AiU advisors agreed more
# on unconfident trials. We'll do this using agreement rate as the outcome of an
# ANOVA, and plugging in confidence, correctness, and advice type as predictors.
# We should see no main effect of advice type, but an interaction between
# confidence and advice type. Correctness should have a strong main effect.
print('3.i Overall agreement by contingency')
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + initialCorrect, data = trials, FUN = mean)
aov.iii.i <- aov(advisorAgrees ~ confidenceCategory * adviceType * initialCorrect +
Error(pid / (confidenceCategory + adviceType + initialCorrect)), data = tmp)
print(summary(aov.iii.i))
#   3.ii) Graph: overall agreement by contingency ####
print('3.ii Graph of overall agreement by contingency')
w <- 0.8
gg.iii.ii <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and correctness') +
style
gg.iii.ii
#   3.iii) Initial block agreement by contingency ####
print('3.iii Initial block agreement by contingency')
# Initial block is forced trials
tmp <- aggregate(advisorAgrees ~ pid + confidenceCategory + adviceType + initialCorrect,
data = trials[trials$type==trialTypes$force, ], FUN = mean)
tmp.aov <- aov(advisorAgrees ~ confidenceCategory * adviceType * initialCorrect +
Error(pid / (confidenceCategory + adviceType + initialCorrect)), data = tmp)
summary(tmp.aov)
#   3.iv) Graph: initial block agreement by contingency ####
print('3.iv Graph of intial block agreement by contingency')
gg.iii.iv <- ggplot(tmp, aes(y = advisorAgrees, x = as.factor(confidenceCategory), colour = as.factor(adviceType))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Advisor Agreement') +
labs(title = 'Observed agreement rate for each advisor by initial decision confidence and correctness\n on forced trials') +
style
gg.iii.iv
#   3.v) Trial count by contingency ####
print('3.v Trial count by contingency')
# Let's also check we got appropriate numbers of trials in each of the bins for
# each participant
df.iii.v <- aggregate(practice ~
pid + confidenceCategory + adviceType + initialCorrect + advisorAgrees,
data = trials, FUN = length)
print(df.iii.v)
#   3.vi) Graph: trial count by contingency ####
print('3.vi Graph of trial count by contingency')
gg.iii.vi <- ggplot(df.iii.v, aes(y = practice, x = as.factor(confidenceCategory),
colour = as.factor(adviceType), shape = as.factor(advisorAgrees))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Trial Count') +
scale_shape_discrete(name = 'Advisor Agreement', labels = c('Disagree', 'Agree')) +
labs(title = 'Observed trial count for dis/agreement from each advisor by initial decision confidence\n and correctness') +
style
gg.iii.vi
print('Running exclusions')
# Exclusion rules:
# Proportion of correct initial judgements must be (.60 < cor1/n < .90)
#NB:practice trials are INCLUDED in this since they are used in part for
#determining confidence calibration
participants$excluded <- sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .85)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
# Clarify the numbers on the rules below
# All confidence categories must have at least 5% of the number of trials
if(any(cCs$pid < length(ts)*.05))
return('Confidence.cat')
return(F)
})
participants$excluded
unique(trials$confidenceCategory)
unique(trials$initialConfidence)
df.poly1 <- data.frame(    # These polygon points define a parellelogram marking the limits for the capped influence
x=c(-50, 0, 0),
y=c(-50, -50, 50)
)
df.poly2 <- df.poly1 * -1
gg.v.iv <- ggplot(trials, aes(x = initialConfSpan, y = finalConfSpan)) +
geom_polygon(data = df.poly1, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_polygon(data = df.poly2, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_point(alpha = 0.2, aes(color = factor(finalCorrect))) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed', size = 1, color = 'black') +
scale_color_discrete(name = 'Final judgement', labels = c('Incorrect', 'Correct')) +
scale_x_continuous(limits = c(-50,50), expand = c(0,0)) +
scale_y_continuous(limits = c(-50,50), expand = c(0,0)) +
facet_grid(~advisorAgrees, labeller = as_labeller(c('FALSE'='Disagree', 'TRUE'='Agree'))) +
labs(title = "Initial vs final confidence",
legend = NULL,
x = 'Initial confidence',
y = "Final confidence") +
coord_fixed() +
style +
theme(panel.spacing = unit(1.5, 'lines'),
plot.margin = unit(c(0,1,0,0.5), 'lines'))
gg.v.iv
unique(trials$warnings)
prolificIds <- c('5b61d0768de04c000171cf1b', '5b4c402ff7310800013b7025', '5b5d218649e37900015f868d', '5b5f1cd27757ed000198dcb0', '5b3512c6415e920001b55046', '5b6099e1f5bc590001183069')
library(scoring)
library(digest)
# We use the Brier score
tmp <- all.trials[,c('initialCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp, group = 'pid')
scores$brieravg
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
markers <- quantile(tmp$brieravg[tmp$excluded==F])
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
print(tmp[,c('prolificId','reward')])
prolificIds[!(prolificIds %in% tmp$prolificId)]
}
all.participants <- participants
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
markers <- quantile(tmp$brieravg[tmp$excluded==F])
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
print(tmp[,c('prolificId','reward')])
prolificIds[!(prolificIds %in% tmp$prolificId)]
}
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
excluded = participants$excluded[participants$pid==pid],
extra = participants$debriefComments[participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
markers <- quantile(tmp$brieravg[tmp$excluded==F])
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
print(tmp[,c('prolificId','reward')])
print(tmp[,c('prolificId','reward','extra')])
tmp
prolificIds[!(prolificIds %in% tmp$prolificId)]
print(tmp[,c('prolificId','reward')])
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
tmp$reward <- .5
tmp$reward[length(tmp$extra) > 5] <- 1.5
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
tmp$reward[2,4] <- 1.5
tmp$reward[c(2,4)] <- 1.5
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
