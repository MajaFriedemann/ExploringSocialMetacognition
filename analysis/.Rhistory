}
}
cor.test(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
correlationBF(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
gg.xii.i.ii <- ggplot(df.xii.i.ii, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and \npreference strength for preferred advisor') +
style.long
gg.xii.i.ii
ggplot(all.trials, aes(x = id, y = dotDifference)) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(0,246)) +
style.long +
facet_wrap(.~pid)
ggplot(all.trials, aes(x = id, y = dotDifference, colour = as.factor(pid))) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(0,246)) +
style.long
ggplot(all.trials, aes(x = id, y = dotDifference, colour = as.factor(pid))) +
geom_line() +
geom_smooth(method = 'lm', se = F) +
scale_x_continuous(limits = c(0,246)) +
style.long
tmp <- trials[trials$pid==pid, ]
x <- lm(dotDifference ~ id, tmp)
x$coefficients
x$coefficients[2]
df.xii.ii.i <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
df.xii.ii.i <- rbind(df.xii.ii.i,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
DotDiffCoef=lm(dotDifference ~ id, tmp)$coefficents[2]))
}
lm(dotDifference ~ id, tmp)$coefficents[2]
lm(dotDifference ~ id, tmp)$coefficients[2]
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
df.xii.ii.i <- rbind(df.xii.ii.i,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
DotDiffCoef=lm(dotDifference ~ id, tmp)$coefficients[2]))
}
cor.test(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
cor.test(df.xii.ii.i$PrefStrength, df.xii.i.ii$InfluenceDiff)
cor.test(df.xii.ii.i$HighAccPref, df.xii.ii.i$DotDiffCoef)
correlationBF(df.xii.ii.i$HighAccPref, df.xii.ii.i$DotDiffCoef)
gg.xii.ii.i <- ggplot(df.xii.i.ii, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between dot difference increase and \nHighAcc advisor preference') +
style.long
gg.xii.ii.i
gg.xii.ii.i <- ggplot(df.xii.ii.i, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between dot difference increase and \nHighAcc advisor preference') +
style.long
gg.xii.ii.i
gg.xii.ii.i <- ggplot(df.xii.ii.i, aes(x = HighAccPref, y = DotDiffCoef)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between dot difference increase and \nHighAcc advisor preference') +
style.long
gg.xii.ii.i
gg.xii.i.ii <- ggplot(df.xii.i.ii, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and \npreference strength for preferred advisor') +
style.long
gg.xii.i.ii
gg.xii.i.ii <- ggplot(df.xii.i.ii, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and \npreference strength for preferred advisor') +
style.long
gg.xii.i.ii
gg.xii.i.i <- ggplot(df.xii.i.i, aes(x = HighAccPref, y = InfluenceDiff)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and preference for high-accuracy advisor') +
style.long
gg.xii.i.i
gg.xii.ii.i <- ggplot(df.xii.ii.i, aes(x = HighAccPref, y = DotDiffCoef)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between dot difference increase and \nHighAcc advisor preference') +
style.long
gg.xii.ii.i
tmp <- trials[trials$pid==pid, ]
r <- lm(initialCorrect ~ initialConfidence, tmp)
r$coefficients
plot(initialCorrect ~ initialConfidence, tmp)
ggplot(tmp, aes(y=initialCorrect, x=initialConfidence) + geom_smooth(method = 'lm')
}
```
ggplot(tmp, aes(y=initialCorrect, x=initialConfidence)) + geom_smooth(method = 'lm')
?cast
ggplot(tmp, aes(y=initialCorrect, x=initialConfidence)) +
geom_smooth(method = method = "glm", method.args = list(family = "binomial"))
ggplot(tmp, aes(y=initialCorrect, x=initialConfidence)) +
geom_smooth(method = "glm", method.args = list(family = "binomial"))
tmp$initialCorrect
ggplot(tmp, aes(y=as.numeric(initialCorrect), x=initialConfidence)) +
geom_smooth(method = "glm", method.args = list(family = "binomial"))
ggplot(tmp, aes(y=as.numeric(initialCorrect), x=initialConfidence)) +
geom_point( ) +
geom_smooth(method = "glm", method.args = list(family = "binomial"))
ggplot(tmp, aes(y=as.numeric(initialCorrect), x=initialConfidence)) +
geom_smooth(method = "lm", method.args = list(family = "binomial"))
ggplot(tmp, aes(y=as.numeric(initialCorrect), x=initialConfidence)) +
geom_smooth(method = "lm")
r$coefficients
df.xii.ii.ii <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
r <- lm(initialCorrect ~ initialConfidence, tmp)
r$coefficients[2]
df.xii.ii.ii <- rbind(df.xii.ii.ii,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==choice]==adviceTypes$HighAcc),
Resolution=lm(initialCorrect ~ initialConfidence, tmp)$coefficients[2]))
}
cor.test(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
correlationBF(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
df.xii.ii.ii <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
r <- lm(initialCorrect ~ initialConfidence, tmp)
r$coefficients[2]
df.xii.ii.ii <- rbind(df.xii.ii.ii,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
Resolution=lm(initialCorrect ~ initialConfidence, tmp)$coefficients[2]))
}
cor.test(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
correlationBF(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
gg.xii.ii.ii <- ggplot(df.xii.ii.ii, aes(x = HighAccPref, y = Resolution)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between metacognitive resolution and \nHighAcc advisor preference') +
style.long
gg.xii.ii.ii
ggplot(df.xii.ii.ii, aes(x = 1:50), colour = as.factor(pid)) +
stat_function(function(x,z)x*z, args=(z=df.xii.ii.ii$Resolution)) +
style.long
ggplot(df.xii.ii.ii, aes(x = 1:50), colour = as.factor(pid)) +
stat_function(fun = function(x,z)x*z, args=(z=df.xii.ii.ii$Resolution)) +
style.long
ggplot(df.xii.ii.ii, aes(x = 1:50), colour = as.factor(pid)) +
stat_function(fun = function(x,z){x*z}, args=(z=df.xii.ii.ii$Resolution)) +
style.long
ggplot(df.xii.ii.ii, aes(x = 1:50), colour = as.factor(pid)) +
stat_function(fun = function(x,z){x*z}, args=(z=Resolution)) +
style.long
ggplot(df.xii.ii.ii, aes(x = 1:50, colour = as.factor(pid))) +
stat_function(fun = function(x,z){x*z}, args=(z=Resolution)) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, alpha = .5) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, linetype = 'dotted') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, linetype = 'dotted') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, linetype = 'dashed') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
stat_summary(geom = 'line', method = 'lm') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
stat_summary(geom = 'line', fun.y = lm) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
stat_summary(geom = 'line', fun.data = lm) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
stat_summary(geom = 'line', fun.y = 'lm') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
geom_smooth(aes(x = initialConfidence, y = as.numeric(initialCorrect)), method = 'line') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
geom_smooth(aes(x = initialConfidence, y = as.numeric(initialCorrect)), method = 'lm') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
geom_smooth(aes(x = initialConfidence, y = as.numeric(initialCorrect)), method = 'lm', se = F) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)), method = 'lm', se = F) +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 0.5, alpha = .3) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = 1, alpha = .25) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = .5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = .5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
style.long
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = .5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
labs(title = 'P(Correct) by confidence for initial responses') +
style.long
gg.xii.ii.ii <- ggplot(df.xii.ii.ii, aes(x = HighAccPref, y = Resolution)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between metacognitive resolution and \nHighAcc advisor preference') +
style.long
gg.xii.ii.ii
?shiny::mainPanel
shiny::runApp('AccuracyCurves')
runApp('AccuracyCurves')
x<-correlationBF(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
x
x@bayesFactor
x@bayesFactor$bf
exp(x@bayesFactor$bf)
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc, adviceTypes$HighAcc, adviceTypes$LowAcc))
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$coefficients[2], 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$coefficients[2], 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$coefficients[2], 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$coefficients[2], 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
x
x$statistic
x$parameter
x$estimate
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$estimate, 'p'=x$statistic, 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$estimate, 'pDiff'=x2$statistic, 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
library(knitr)
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$estimate, 'p'=x$statistic, 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$estimate, 'pDiff'=x2$statistic, 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
cor.test(df.xiii$PrefLikeability,df.xiii$PrefStrength)
x$p.value
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$estimate, 'p'=x$p.value, 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$estimate, 'pDiff'=x2$p.value, 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
df.xii.i.ii
df.xii.i.ii <- aggregate(. ~ pid, df.xii.i.ii, fun = mean)
df.xii.i.ii <- NULL
for(pid in unique(participants$pid)) {
for(block in c(3,5)) {
# Look for the favourate advisor in each block and use the preference strength for that advisor
tmp <- trials[trials$block==block & trials$pid==pid, ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc)>.5, adviceTypes$HighAcc, adviceTypes$LowAcc)
df.xii.i.ii <- rbind(df.xii.i.ii, data.frame(pid,
PrefStrength=mean(tmp$adviceType==aid),
InfluenceDiff=(sum(tmp$influence[tmp$adviceType==aid]) -
sum(tmp$influence[tmp$adviceType!=aid]))))
}
}
df.xii.i.ii <- aggregate(. ~ pid, df.xii.i.ii, FUN = mean)
cor.test(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
correlationBF(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
