df.v.iv <- NULL
for(a in c(T,F)) {
v <- trials[trials$advisorAgrees == a, ]
i <- mean(v$confidenceShiftRaw > 0)
d <- mean(v$confidenceShiftRaw < 0)
n <- mean(v$confidenceShiftRaw == 0)
df.v.iv <- rbind(df.v.iv, data.frame(advisorAgrees = a,
increaseConfPerC = i,
noChangePerC = n,
decreaseConfPerC = d))
}
kable(df.v.iv)
# Chunk 18
df.v.v <- NULL
for(aT in c(5,6)) {
if(aT == adviceTypes$neutral)
next()
for(tp in unique(questionnaires$timepoint)) {
for(colName in c('likeability', 'ability', 'benevolence')) {
x <- aggregate(questionnaires[questionnaires$adviceType==aT & questionnaires$timepoint==tp, c('pid',colName)],
by = list(questionnaires$pid[questionnaires$adviceType==aT
& questionnaires$timepoint==tp]),
FUN = function(x){sum(as.numeric(x))/length(x)})[,colName]
cl <- mean_cl_normal(x)
rn <- range(x)
df.v.v <- rbind(df.v.v, data.frame(timepoint = tp,
question = colName,
adviceType = getAdviceTypeName(aT),
mean = cl$y,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
}
df.v.v[,-(1:3)] <- round(df.v.v[,-(1:3)],2)
kable(df.v.v)
# Chunk 19
df.vi <- NULL
for(agree in list(T,F,c(T,F))) {
for(aT in c(adviceTypes$HighAcc, adviceTypes$LowAcc, adviceTypes$neutral)) {
if(aT==adviceTypes$neutral)
aT <- c(adviceTypes$HighAcc, adviceTypes$LowAcc) # hack for including the total
tmp <- trials[trials$advisorAgrees %in% agree & trials$adviceType %in% aT, ]
tmp$adviceCorrect <- tmp$adviceSide == tmp$correctAnswer
x <- aggregate(adviceCorrect ~ pid,
tmp,
FUN = mean)$adviceCorrect
cl <- mean_cl_normal(x)
rn <- range(x)
df.vi <- rbind(df.vi, data.frame(agree = ifelse(length(agree)>1, 'Both', agree),
advisor = ifelse(length(aT)>1,'Both',getAdviceTypeName(aT)), # hack to label total
meanAccuracy = cl$y,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.vi[,-(1:2)] <- round(df.vi[,-(1:2)],2)
kable(df.vi)
# Chunk 20
tmp <- aggregate(adviceType ~ pid,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.vi.i <- t.test(tmp$adviceType, mu=0.5)
d <- cohensD(tmp$adviceType, mu = 0.5)
tB.vi.i <- ttestBF(tmp$adviceType, mu = 0.5)
printMean(tmp$adviceType, 'Mean HighAcc pick rate')
print('Choice proportion HighAcc vs. chance level (.5)')
prettyPrint(t.vi.i, d)
print('Bayesian examination of above (prior = mean of 0.5, sd as empirically observed)')
print(tB.vi.i)
print(paste0('Evidence strength for preferential HighAcc picking: BF=', round(exp(tB.vi.i@bayesFactor$bf),3)))
# Chunk 21
tmp <- aggregate(adviceType ~ pid,
data = trials[trials$type==trialTypes$choice
& trials$confidenceCategory==confidenceCategories$medium, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.vi.ii <- t.test(tmp$adviceType, mu=0.5)
d <- cohensD(tmp$adviceType, mu=0.5)
tB.vi.ii <- ttestBF(tmp$adviceType, mu = 0.5)
printMean(tmp$adviceType, 'Mean HighAcc pick rate')
print('Choice proportion HighAcc vs. chance level (.5) for mid-confidence trials')
prettyPrint(t.vi.ii,d)
print('Bayesian examination of above (prior = mean of 0.5, sd as empirically observed)')
print(tB.vi.ii)
print(paste0('Evidence strength for preferential HighAcc picking: BF=', round(exp(tB.vi.ii@bayesFactor$bf),3)))
# Chunk 22
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
tmp.2 <- aggregate(adviceType ~ pid,
data = trials[trials$type == trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
gg.vi.iii <- ggplot(tmp, aes(x = factor(confidenceCategory), y = adviceType)) +
geom_hline(linetype = "dashed", color = "black", yintercept = .5, size = 1) +
geom_point(aes(color = factor(pid))) +
geom_line(aes(group = factor(pid), color = factor(pid))) +
stat_summary(geom = "errorbar", fun.data = "mean_cl_boot", width = 0.1) +
stat_summary(geom = "point", fun.y = "mean", shape = 23, fill = "black", size = 4) +
geom_point(position = position_jitter(w=0.03, h=0),
aes(x="Overall", color = factor(pid)),
data = tmp.2) +
stat_summary(geom = "errorbar", fun.data = "mean_cl_boot", width = 0.1,
aes(x="Overall"), data = tmp.2) +
stat_summary(geom = "point", fun.y = "mean", shape = 23, fill = "black", size = 4,
aes(x="Overall"), data = tmp.2) +
scale_y_continuous(limits = c(0,1), expand = c(0.05,0)) +
scale_x_discrete(expand = c(0,1), labels = c('Low', 'Medium',
'High', 'Overall')) +
scale_color_discrete(name = 'Participant') +
labs(title = "Advisor preference",
legend = NULL,
x = "Confidence",
y = "P(HighAcc advisor is chosen)") +
style.long
gg.vi.iii
# Chunk 23
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.i <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('2x2x2 Mixed ANOVA of advisor type x choice x agreement')
print(summary(aov.vii.i))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
# Chunk 24
tmp$adviceType <- factor(tmp$adviceType)
gg.vii.ii <- ggplot(tmp, aes(advisorAgrees, influence, color = adviceType, fill = adviceType)) +
geom_point(position = position_jitter(w=0.1, h=0), alpha = 0.5) +
stat_summary(geom = "errorbar",
fun.data = "mean_cl_boot",
width = 0.2) +
stat_summary(geom = "point",
fun.y = "mean",
shape = 23, size = 5) +
stat_summary(aes(group = adviceType), fun.y=mean, geom="line") +
facet_grid(.~hasChoice,
labeller = as_labeller(c('FALSE'='Forced trials','TRUE'='Choice trials'))) +
scale_color_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_x_discrete(name = 'Judge-advisor agreement', labels = c('Disagree', 'Agree')) +
labs(title = "Advice Influence",
legend = NULL,
y = "Influence of the advice") +
style
gg.vii.ii
# Chunk 25
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid,
data = trials[trials$confidenceCategory==confidenceCategories$medium
& trials$finalAnswer==trials$correctAnswer, ],
FUN = mean)
aov.vii.iii <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('As above, looking at only trials where intial decision was correct and made with middle confidence:')
print(summary(aov.vii.iii))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
# Chunk 26
tmp <- aggregate(rawInfluence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.iv <- aov(rawInfluence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('Original mixed ANOVA using raw influence scores')
print(summary(aov.vii.iv))
print('Means:')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$rawInfluence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$rawInfluence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$rawInfluence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$rawInfluence[!tmp$advisorAgrees], 'Mean|Disagree')
# Chunk 27
tmp <- trials
tmp$influenceChanges <- (tmp$rawInfluence - tmp$influence) != 0
tmp.2 <- aggregate(influenceChanges ~ pid, tmp, mean)
cl <- mean_cl_normal(tmp.2$influenceChanges)
rn <- range(tmp.2$influenceChanges)
df.vii.i <- data.frame('P(influenceChanges)'=cl$y,
clLow=cl$ymin, clHigh=cl$ymax,
rangeLow=rn[1], rangeHigh=rn[2])
kable(df.vii.i)
# Chunk 28
df.viii.i.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
x <- questionnaires[questionnaires$advisorCategory=='b',v]
y <- questionnaires[questionnaires$advisorCategory=='w',v]
bf <- ttestBF(x,y)
df.viii.i.i <- rbind(df.viii.i.i, data.frame(variable = v,
BF = exp(bf@bayesFactor$bf),
mu1 = mean(x),
mu2 = mean(y)))
}
kable(df.viii.i.i)
# Chunk 29
df.viii.i.ii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp <- correlationBF(questionnaires[,v], questionnaires[,'advisorAge'])
df.viii.i.ii <- rbind(df.viii.i.ii, data.frame(variable = v,
corellationBF = exp(tmp@bayesFactor$bf)))
}
kable(df.viii.i.ii)
# Chunk 30
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorPortrait + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iii <- rbind(df.viii.i.iii, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
kable(df.viii.i.iii)
# Chunk 31
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iv <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorName + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iv <- rbind(df.viii.i.iv, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
kable(df.viii.i.iv)
# Chunk 32
aov.viii.ii <- manova(cbind(ability, likeability, benevolence) ~ adviceType * timepoint,# + Error(pid),
data = questionnaires)
print(summary(aov.viii.ii))
# Chunk 33
df.viii.ii <- NULL
tmp <- questionnaires[ ,c('likeability', 'benevolence', 'ability', 'pid', 'adviceType', 'timepoint')]
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[ ,v]
tmp.2 <- aggregate(v ~ adviceType + timepoint + pid,
data = tmp,
FUN = mean)
for(aT in c(5,6)) {
if(aT == adviceTypes$neutral)
next()
for(tp in unique(tmp.2$timepoint)) {
x <- tmp.2$v[tmp.2$adviceType==aT & tmp.2$timepoint==tp]
df.viii.ii <- rbind(df.viii.ii, data.frame(domain = v,
adviceType=aT,
timepoint=tp,
mu=mean(x),
ci95low=mean_cl_normal(x)$ymin,
ci95hi =mean_cl_normal(x)$ymax))
}
}
}
df.viii.ii[ ,4:6] <- round(df.viii.ii[ ,4:6],2)
df.viii.ii$adviceType <- sapply(df.viii.ii$adviceType, getAdviceTypeName)
kable(df.viii.ii[order(df.viii.ii$timepoint), ])
# Chunk 34
# TODO ####
# tidy the hell out of this graph. Should allow easy discrimination
# between advice type assessment changes over time.
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
tmp <- melt(tmp, id.vars = c('adviceType', 'timepoint', 'pid'))
gg.viii.iii <- ggplot(tmp, aes(x = variable, y = value, colour = as.factor(timepoint))) +
geom_boxplot() +
scale_y_continuous(limits = c(0,100)) +
facet_grid(~ adviceType) +
style
gg.viii.iii
# Chunk 35
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.ix.i <- t.test(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
d <- cohensD(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high])
tB.ix.i <- ttestBF(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
print('Choice proportion HighAcc in low- vs high-confidence trials')
prettyPrint(t.ix.i,d)
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low], 'low')
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high], 'high')
print('Bayesian examination of above (prior = mean diff of 0, sd as empirically observed)')
print(tB.ix.i)
print(paste0('Evidence strength for differential high/low confidence picking strategy: BF=',
round(exp(tB.ix.i@bayesFactor$bf),3)))
# Chunk 36
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
# calculate difference scores
for(i in 1:nrow(tmp))
if(tmp$timepoint[i]==2)
tmp[i,4:6] <- tmp[i, 4:6] - tmp[tmp$timepoint==1
& tmp$pid == tmp$pid[i]
& tmp$adviceType == tmp$adviceType[i], 4:6]
tmp.2 <- aggregate(influence ~ adviceType + pid + hasChoice,
data = trials, FUN = mean)
tmp$influence <- sapply(1:nrow(tmp), function(i){tmp.2$influence[tmp.2$hasChoice
& tmp.2$pid == tmp$pid[i]
& tmp.2$adviceType == tmp$adviceType[i]]})
tmp$influence <- as.numeric(tmp$influence)
# The test is a regression with the change in subjective variables as predictors
lm.x.i <- lm(influence ~ ability + benevolence + likeability, data = tmp)
print(summary(lm.x.i))
# Chunk 37
tmp <- melt(tmp[tmp$timepoint==2, ], id.vars = c('adviceType', 'pid', 'timepoint', 'influence'),
measure.vars = c('likeability', 'ability', 'benevolence'),
variable.name = 'trustDimension', value.name = 'trust')
gg.x.ii <- ggplot(tmp, aes(x = trust, y = influence, colour = factor(adviceType))) +
geom_point(alpha = 0.33) +
geom_smooth(method = 'lm', aes(fill = factor(adviceType)), alpha = 0.1) +
facet_grid(trustDimension ~ .) +
coord_fixed(ratio = 3, expand = F) +
scale_x_continuous(name = 'Trust change') +
scale_y_continuous(name = 'Influence') +
scale_color_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
style
gg.x.ii
# Chunk 38
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ pid,
data = questionnaires[questionnaires$timepoint==1,],
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.i <- rbind(df.xi.i, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
kable(df.xi.i)
# Chunk 39
tmp.2 <- melt(tmp, id.vars = c('pid'), measure.vars = c('likeability', 'ability', 'benevolence'))
tmp.2$genTrust <- sapply(tmp.2$pid, function(x) tmp$genTrust[tmp$pid==x][1])
gg.xi.i <- ggplot(tmp.2, aes(x = genTrust, y = value)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
facet_grid(variable ~ .) +
style.long
gg.xi.i
# Chunk 40
tmp <- aggregate(cbind(influence, rawInfluence) ~ pid,
data = trials,
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.ii <- NULL
for(v in c('rawInfluence', 'influence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.ii <- rbind(df.xi.ii, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
kable(df.xi.ii)
# Chunk 41
gg.xi.ii <- ggplot(tmp, aes(x = genTrust, y = influence)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
style.long
gg.xi.ii
# Chunk 42
df.xii.i.i <- NULL
for(pid in unique(participants$pid)) {
tmp <- trials[trials$type==trialTypes$choice & trials$pid==pid, ]
df.xii.i.i <- rbind(df.xii.i.i, data.frame(pid,
HighAccPref=mean(tmp$adviceType==adviceTypes$HighAcc),
InfluenceDiff=(sum(tmp$influence[tmp$adviceType==adviceTypes$HighAcc]) -
sum(tmp$influence[tmp$adviceType==adviceTypes$LowAcc]))))
}
cor.test(df.xii.i.i$HighAccPref, df.xii.i.i$InfluenceDiff)
correlationBF(df.xii.i.i$HighAccPref, df.xii.i.i$InfluenceDiff)
# Chunk 43
gg.xii.i.i <- ggplot(df.xii.i.i, aes(x = HighAccPref, y = InfluenceDiff)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and preference for high-accuracy advisor') +
style.long
gg.xii.i.i
# Chunk 44
df.xii.i.ii <- NULL
for(pid in unique(participants$pid)) {
for(block in c(3,5)) {
# Look for the favourate advisor in each block and use the preference strength for that advisor
tmp <- trials[trials$block==block & trials$pid==pid, ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc)>.5, adviceTypes$HighAcc, adviceTypes$LowAcc)
df.xii.i.ii <- rbind(df.xii.i.ii, data.frame(pid,
PrefStrength=mean(tmp$adviceType==aid),
InfluenceDiff=(sum(tmp$influence[tmp$adviceType==aid]) -
sum(tmp$influence[tmp$adviceType!=aid]))))
}
}
df.xii.i.ii <- aggregate(. ~ pid, df.xii.i.ii, FUN = mean) # reaggregate
cor.test(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
correlationBF(df.xii.i.ii$PrefStrength, df.xii.i.ii$InfluenceDiff)
# Chunk 45
gg.xii.i.ii <- ggplot(df.xii.i.ii, aes(x = PrefStrength, y = InfluenceDiff)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between influence difference and \npreference strength for preferred advisor') +
style.long
gg.xii.i.ii
# Chunk 46
df.xii.ii.i <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
df.xii.ii.i <- rbind(df.xii.ii.i,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
DotDiffCoef=lm(dotDifference ~ id, tmp)$coefficients[2]))
}
cor.test(df.xii.ii.i$HighAccPref, df.xii.ii.i$DotDiffCoef)
correlationBF(df.xii.ii.i$HighAccPref, df.xii.ii.i$DotDiffCoef)
# Chunk 47
gg.xii.ii.i <- ggplot(df.xii.ii.i, aes(x = HighAccPref, y = DotDiffCoef)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between dot difference increase and \nHighAcc advisor preference') +
style.long
gg.xii.ii.i
# Chunk 48
df.xii.ii.ii <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
df.xii.ii.ii <- rbind(df.xii.ii.ii,
data.frame(pid,
HighAccPref=mean(tmp$adviceType[tmp$type==trialTypes$choice]==adviceTypes$HighAcc),
Resolution=lm(initialCorrect ~ initialConfidence, tmp)$coefficients[2]))
}
cor.test(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
correlationBF(df.xii.ii.ii$HighAccPref, df.xii.ii.ii$Resolution)
# Chunk 49
gg.xii.ii.ii <- ggplot(df.xii.ii.ii, aes(x = HighAccPref, y = Resolution)) +
geom_vline(linetype = "dashed", color = "black", xintercept = .5, size = 1) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
labs(title = 'Correlation between metacognitive resolution and \nHighAcc advisor preference') +
style.long
gg.xii.ii.ii
# Chunk 50
ggplot(trials, aes(x = initialConfidence, y = as.numeric(initialCorrect), colour = as.factor(pid))) +
geom_smooth(method = 'lm', se = F, size = .5) +
geom_smooth(inherit.aes = F, aes(x = initialConfidence, y = as.numeric(initialCorrect)),
method = 'lm', se = T, colour = 'black', alpha = .3, linetype = 'dashed') +
labs(title = 'P(Correct) by confidence for initial responses') +
style.long
# Chunk 51
df.xiii <- NULL
for(pid in unique(participants$pid)) {
for(early in c(T,F)) { # split by advisor sets 1 and 2 (blocks 2&3, 4&5)
tmp <- trials[trials$pid==pid & trials$block %in% ifelse(early,2:3,4:5), ]
aid <- ifelse(mean(tmp$adviceType==adviceTypes$HighAcc), adviceTypes$HighAcc, adviceTypes$LowAcc)
# Find questionnaire ratings for advisors
tmp.2 <- questionnaires[questionnaires$pid==pid
& questionnaires$advisorId %in% unique(tmp$advisorId)
& questionnaires$timepoint==1, ]
# Calculate difference scores for each variable
for(i in 1:nrow(tmp.2)) {
for(v in c('likeability', 'ability', 'benevolence'))
tmp.2[i,paste0(v,'Diff')] <- questionnaires[questionnaires$pid==tmp.2$pid[i]
& questionnaires$advisorId==tmp.2$advisorId[i]
& questionnaires$timepoint==2, v] - tmp.2[i,v]
}
PrefStrength = mean(tmp$adviceType==aid)
PrefLikeability = tmp.2$likeability[tmp.2$adviceType==aid] - tmp.2$likeability[tmp.2$adviceType!=aid]
PrefAbility = tmp.2$ability[tmp.2$adviceType==aid] - tmp.2$ability[tmp.2$adviceType!=aid]
PrefBenevolence = tmp.2$benevolence[tmp.2$adviceType==aid] - tmp.2$benevolence[tmp.2$adviceType!=aid]
PrefLikeabilityDiff = tmp.2$likeabilityDiff[tmp.2$adviceType==aid] - tmp.2$likeabilityDiff[tmp.2$adviceType!=aid]
PrefAbilityDiff = tmp.2$abilityDiff[tmp.2$adviceType==aid] - tmp.2$abilityDiff[tmp.2$adviceType!=aid]
PrefBenevolenceDiff = tmp.2$benevolenceDiff[tmp.2$adviceType==aid] - tmp.2$benevolenceDiff[tmp.2$adviceType!=aid]
df.xiii <- rbind(df.xiii,
data.frame(pid, PrefStrength, PrefLikeability, PrefAbility, PrefBenevolence,
PrefLikeabilityDiff, PrefAbilityDiff, PrefBenevolenceDiff))
}
}
df.xiii <- aggregate(. ~ pid, df.xiii, FUN = mean)
df.xiii.2 <- NULL
for(v in c('Likeability', 'Ability', 'Benevolence')) {
x <- cor.test(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
bf <- correlationBF(df.xiii[ ,paste0('Pref',v)], df.xiii$PrefStrength)
x2 <- cor.test(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
bf2 <- correlationBF(df.xiii[ ,paste0('Pref',v,'Diff')], df.xiii$PrefStrength)
df.xiii.2 <- rbind(df.xiii.2,
data.frame(v, 'Correlation'=x$estimate, 'p'=x$p.value, 'BF'=exp(bf@bayesFactor$bf),
'DiffCorrelation'=x2$estimate, 'pDiff'=x2$p.value, 'DiffBF'=exp(bf2@bayesFactor$bf)))
}
kable(df.xiii.2)
ggplot(all.trials, aes(x = id, y = dotDifference, colour = as.factor(pid))) +
geom_line() +
geom_smooth(method = 'lm', se = F, data = all.trials[all.trials$block == max(all.trials$block), ]) +
scale_x_continuous(limits = c(0,249)) +
style.long +
labs(title = 'Difficulty (and trend for the final block) for Advisor Choice (accuracy)')
