# Let's also check we got appropriate numbers of trials in each of the bins for
# each participant
df.iii.v <- aggregate(practice ~
pid + confidenceCategory + adviceType + initialCorrect + advisorAgrees,
data = trials, FUN = length)
#print(df.iii.v)
gg.iii.vi <- ggplot(df.iii.v, aes(y = practice, x = as.factor(confidenceCategory),
colour = as.factor(adviceType), shape = as.factor(advisorAgrees))) +
stat_summary(geom = 'point', size = 3, fun.y = mean, position = position_dodge(w)) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot, position = position_dodge(w), size = 0.2) +
geom_point(alpha = 0.5, position = position_dodge(w)) +
facet_wrap(~initialCorrect, labeller = label_both) +
scale_x_discrete(name = 'Confidence Category', labels = c('Low', 'Med', 'High')) +
scale_color_discrete(name = 'Advice Type', labels = c('AiC', 'AiU')) +
scale_y_continuous(name = 'Trial Count') +
scale_shape_discrete(name = 'Advisor Agreement', labels = c('Disagree', 'Agree')) +
labs(title = 'Observed trial count for dis/agreement from each advisor by initial decision confidence\n and correctness') +
style
gg.iii.vi
participants$excluded <- sapply(participants$pid, function(pid){
ts <- which(all.trials$pid == pid)
# overall accuracy of initial decisions
v <- all.trials$initialAnswer[ts] == all.trials$correctAnswer[ts]
m <- mean(as.numeric(v), na.rm = T)
if(m < .6 | m > .85)
return('Accuracy')
# varied use of confidence scale
ts <- which(trials$pid == pid)
cCs <- aggregate(pid ~ confidenceCategory, data = trials[ts, ], FUN = length)
# All confidence categories must be used
if(nrow(cCs) < 3)
return ('Confidence')
# Clarify the numbers on the rules below
# All confidence categories must have at least 5% of the number of trials
if(any(cCs$pid < length(ts)*.05))
return('Confidence.cat')
return(F)
})
all.participants <- participants
participants <- participants[participants$excluded==F, ]
# Remove excluded participants' data from other data frames
trials <- trials[trials$pid %in% participants$pid, ]
advisors <- advisors[advisors$pid %in% participants$pid, ]
questionnaires <- questionnaires[questionnaires$pid %in% participants$pid, ]
df.iv <- aggregate(pid ~ excluded, data = all.participants, FUN = length)
names(df.iv) <- c('exclusionReason', 'count')
print(df.iv)
df.v.i <- NULL
for(col in c('initial', 'final')) {
for(aT in c(5,6,0)) {
colName <- paste0(col,'Correct')
if(aT==adviceTypes$neutral)
aT <- c(adviceTypes$HighAcc, adviceTypes$LowAcc) # hack for including the total
x <- as.numeric(trials[trials$adviceType %in% aT, colName])
m <- mean(x)
cl <- mean_cl_normal(x)
rn <- range(aggregate(trials[trials$adviceType %in% aT, c(colName,'pid','adviceType')],
by = list(trials$pid[trials$adviceType %in% aT]),
FUN = function(x){sum(as.numeric(x))/length(x)})[,colName])
df.v.i <- rbind(df.v.i, data.frame(decision = col,
adviceType = ifelse(length(aT)>1,'Total',getAdviceTypeName(aT)), # hack to label total
target = ifelse(col=='initial',.71,NA),
meanCorrect = m,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.v.i[,-(1:2)] <- round(df.v.i[,-(1:2)],2)
print(df.v.i)
df.v.ii <- NULL
for(aT in c(5,6)) {
if(aT==adviceTypes$neutral)
next()
ts <- trials[trials$adviceType==aT, ]
for(i in 1:(length(confidenceCategories)+3)) {
if(i <= length(confidenceCategories)) {
x <- ts[ts$confidenceCategory==confidenceCategories[i] & ts$initialCorrect==T, ]
name <- names(confidenceCategories[i])
} else {
i <- i - length(confidenceCategories)
if(i==1) {
x <- ts[ts$initialCorrect, ]
name <- 'allCorrect'
} else if(i==2) {
x <- ts[!ts$initialCorrect, ]
name <- 'allWrong'
} else {
x <- ts
name <- 'All'
}
}
m <- mean(as.numeric(x$advisorAgrees))
cl <- mean_cl_normal(as.numeric(x$advisorAgrees))
rn <- range(aggregate(advisorAgrees ~ pid, data = x,
FUN = function(x){sum(as.numeric(x))/length(x)})$advisorAgrees)
df.v.ii <- rbind(df.v.ii, data.frame(adviceType = getAdviceTypeName(aT), # hack to label totalname,
name,
probAgree = m,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.v.ii[,-(1:2)] <- round(df.v.ii[,-(1:2)],2)
print(df.v.ii)
df.v.iii.i <- NULL
for(col in c('initial', 'final')) {
for(correct in list(T,F,c(T,F))) {
colName <- paste0(col,'Confidence')
x <- trials[trials[,paste0(col,'Correct')] %in% correct, ]
m <- mean(x[,colName])
cl <- mean_cl_normal(x[,colName])
rn <- range(aggregate(trials[trials[,paste0(col,'Correct')] %in% correct, c(colName,'pid','adviceType')],
by = list(trials$pid[trials[,paste0(col,'Correct')] %in% correct]),
FUN = function(x){sum(as.numeric(x))/length(x)})[,colName])
df.v.iii.i <- rbind(df.v.iii.i, data.frame(decision = col,
correct = ifelse(length(correct)>1,'Both',correct), # hack to label total
meanConfidence = m,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.v.iii.i[,-(1:2)] <- round(df.v.iii.i[,-(1:2)],2)
print(df.v.iii.i)
df.v.iii.ii <- NULL
for(col in c('initial', 'final')) {
for(aT in c(adviceTypes$HighAcc, adviceTypes$LowAcc, adviceTypes$neutral)) {
if(aT==adviceTypes$neutral)
aT <- c(adviceTypes$HighAcc, adviceTypes$LowAcc) # hack for including the total
colName <- paste0(col,'Confidence')
x <- trials[trials[,"adviceType"] %in% aT, ]
m <- mean(x[,colName])
cl <- mean_cl_normal(x[,colName])
rn <- range(aggregate(trials[trials[,"adviceType"] %in% aT, c(colName,'pid','adviceType')],
by = list(trials$pid[trials[,"adviceType"] %in% aT]),
FUN = function(x){sum(as.numeric(x))/length(x)})[,colName])
df.v.iii.ii <- rbind(df.v.iii.ii, data.frame(decision = col,
adviceType = ifelse(length(aT)>1,'Both',getAdviceTypeName(aT)), # hack to label total
meanConfidence = m,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.v.iii.ii[,-(1:2)] <- round(df.v.iii.ii[,-(1:2)],2)
print(df.v.iii.ii)
df.v.iii.2 <- NULL
for(agree in c(T,F)) {
for(aT in c(adviceTypes$HighAcc, adviceTypes$LowAcc, adviceTypes$neutral)) {
if(aT==adviceTypes$neutral)
aT <- c(adviceTypes$HighAcc, adviceTypes$LowAcc) # hack for including the total
x <- trials[trials$advisorAgrees==agree & trials$adviceType %in% aT, ]
m <- mean(x$finalConfidence)
cl <- mean_cl_normal(x$finalConfidence)
rn <- range(aggregate(finalConfidence ~ pid, data = x,
FUN = function(x){sum(as.numeric(x))/length(x)})$finalConfidence)
df.v.iii.2 <- rbind(df.v.iii.2, data.frame(agree,
advisor = ifelse(length(aT)>1,'Both',getAdviceTypeName(aT)), # hack to label total
meanConfidence = m,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.v.iii.2[,-(1:2)] <- round(df.v.iii.2[,-(1:2)],2)
print('Descriptives: final decision confidence')
df.v.iii.2
df.poly1 <- data.frame(    # These polygon points define a parellelogram marking the limits for the capped influence
x=c(50, 0, 0),
y=c(50, 50, -50)
)
df.poly2 <- df.poly1 * -1
gg.v.iv <- ggplot(trials, aes(x = initialConfSpan, y = finalConfSpan)) +
geom_polygon(data = df.poly1, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_polygon(data = df.poly2, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_point(alpha = 0.2, aes(color = factor(finalCorrect))) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed', size = 1, color = 'black') +
scale_color_discrete(name = 'Final judgement', labels = c('Incorrect', 'Correct')) +
scale_x_continuous(limits = c(-50,50), expand = c(0,0)) +
scale_y_continuous(limits = c(-50,50), expand = c(0,0)) +
facet_grid(~advisorAgrees, labeller = as_labeller(c('FALSE'='Disagree', 'TRUE'='Agree'))) +
labs(title = "Initial vs final confidence",
legend = NULL,
x = 'Initial confidence',
y = "Final confidence") +
coord_fixed() +
style +
theme(panel.spacing = unit(1.5, 'lines'),
plot.margin = unit(c(0,1,0,0.5), 'lines'))
gg.v.iv
df.v.iv <- NULL
for(a in c(T,F)) {
v <- trials[trials$advisorAgrees == a, ]
i <- mean(v$confidenceShiftRaw > 0)
d <- mean(v$confidenceShiftRaw < 0)
n <- mean(v$confidenceShiftRaw == 0)
df.v.iv <- rbind(df.v.iv, data.frame(advisorAgrees = a,
increaseConfPerC = i,
noChangePerC = n,
decreaseConfPerC = d))
}
print(df.v.iv)
df.vi <- NULL
for(agree in list(T,F,c(T,F))) {
for(aT in c(adviceTypes$HighAcc, adviceTypes$LowAcc, adviceTypes$neutral)) {
if(aT==adviceTypes$neutral)
aT <- c(adviceTypes$HighAcc, adviceTypes$LowAcc) # hack for including the total
x <- trials[trials$advisorAgrees %in% agree & trials$adviceType %in% aT, ]
x$adviceCorrect <- x$adviceSide == x$correctAnswer
cl <- mean_cl_normal(x$adviceCorrect)
rn <- range(aggregate(adviceCorrect ~ pid, x, FUN = mean)$adviceCorrect)
df.vi <- rbind(df.vi, data.frame(agree = ifelse(length(agree)>1, 'Both', agree),
advisor = ifelse(length(aT)>1,'Both',getAdviceTypeName(aT)), # hack to label total
meanConfidence = cl$y,
cl95Min = cl$ymin,
cl95Max = cl$ymax,
rangeMin = rn[1],
rangeMax = rn[2]))
}
}
df.vi[,-(1:2)] <- round(df.vi[,-(1:2)],2)
df.vi
tmp <- aggregate(adviceType ~ pid,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.vi.i <- t.test(tmp$adviceType, mu=0.5)
d <- cohensD(tmp$adviceType, mu = 0.5)
tB.vi.i <- ttestBF(tmp$adviceType, mu = 0.5)
printMean(tmp$adviceType, 'Mean HighAcc pick rate')
print('Choice proportion HighAcc vs. chance level (.5)')
prettyPrint(t.vi.i, d)
print('Bayesian examination of above (prior = mean of 0.5, sd as empirically observed)')
print(tB.vi.i)
print(paste0('Evidence strength for preferential HighAcc picking: BF=', round(exp(tB.vi.i@bayesFactor$bf),3)))
tmp <- aggregate(adviceType ~ pid,
data = trials[trials$type==trialTypes$choice
& trials$confidenceCategory==confidenceCategories$medium, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.vi.ii <- t.test(tmp$adviceType, mu=0.5)
d <- cohensD(tmp$adviceType, mu=0.5)
tB.vi.ii <- ttestBF(tmp$adviceType, mu = 0.5)
printMean(tmp$adviceType, 'Mean HighAcc pick rate')
print('Choice proportion HighAcc vs. chance level (.5) for mid-confidence trials')
prettyPrint(t.vi.ii,d)
print('Bayesian examination of above (prior = mean of 0.5, sd as empirically observed)')
print(tB.vi.ii)
print(paste0('Evidence strength for preferential HighAcc picking: BF=', round(exp(tB.vi.ii@bayesFactor$bf),3)))
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
tmp.2 <- aggregate(adviceType ~ pid,
data = trials[trials$type == trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
gg.vi.iii <- ggplot(tmp, aes(x = factor(confidenceCategory), y = adviceType)) +
geom_hline(linetype = "dashed", color = "black", yintercept = .5, size = 1) +
geom_point(aes(color = factor(pid))) +
geom_line(aes(group = factor(pid), color = factor(pid))) +
stat_summary(geom = "errorbar", fun.data = "mean_cl_boot", width = 0.1) +
stat_summary(geom = "point", fun.y = "mean", shape = 23, fill = "black", size = 4) +
geom_point(position = position_jitter(w=0.03, h=0),
aes(x="Overall", color = factor(pid)),
data = tmp.2) +
stat_summary(geom = "errorbar", fun.data = "mean_cl_boot", width = 0.1,
aes(x="Overall"), data = tmp.2) +
stat_summary(geom = "point", fun.y = "mean", shape = 23, fill = "black", size = 4,
aes(x="Overall"), data = tmp.2) +
scale_y_continuous(limits = c(0,1), expand = c(0.05,0)) +
scale_x_discrete(expand = c(0,1), labels = c('Low', 'Medium',
'High', 'Overall')) +
scale_color_discrete(name = 'Participant') +
labs(title = "Advisor preference",
legend = NULL,
x = "Confidence",
y = "P(HighAcc advisor is chosen)") +
style.long
gg.vi.iii
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.i <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('2x2x2 Mixed ANOVA of advisor type x choice x agreement')
print(summary(aov.vii.i))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
tmp$adviceType <- factor(tmp$adviceType)
gg.vii.ii <- ggplot(tmp, aes(advisorAgrees, influence, color = adviceType, fill = adviceType)) +
geom_point(position = position_jitter(w=0.1, h=0), alpha = 0.5) +
stat_summary(geom = "errorbar",
fun.data = "mean_cl_boot",
width = 0.2) +
stat_summary(geom = "point",
fun.y = "mean",
shape = 23, size = 5) +
stat_summary(aes(group = adviceType), fun.y=mean, geom="line") +
facet_grid(.~hasChoice,
labeller = as_labeller(c('FALSE'='Forced trials','TRUE'='Choice trials'))) +
scale_color_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_x_discrete(name = 'Judge-advisor agreement', labels = c('Disagree', 'Agree')) +
labs(title = "Advice Influence",
legend = NULL,
y = "Influence of the advice") +
style
gg.vii.ii
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid,
data = trials[trials$confidenceCategory==confidenceCategories$medium
& trials$finalAnswer==trials$correctAnswer, ],
FUN = mean)
aov.vii.iii <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('As above, looking at only trials where intial decision was correct and made with middle confidence:')
print(summary(aov.vii.iii))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
tmp <- aggregate(rawInfluence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.iv <- aov(rawInfluence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('Original mixed ANOVA using raw influence scores')
print(summary(aov.vii.iv))
print('Means:')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$rawInfluence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$rawInfluence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$rawInfluence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$rawInfluence[!tmp$advisorAgrees], 'Mean|Disagree')
df.viii.i.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
x <- questionnaires[questionnaires$advisorCategory=='b',v]
y <- questionnaires[questionnaires$advisorCategory=='w',v]
bf <- ttestBF(x,y)
df.viii.i.i <- rbind(df.viii.i.i, data.frame(variable = v,
BF = exp(bf@bayesFactor$bf),
mu1 = mean(x),
mu2 = mean(y)))
}
print(df.viii.i.i)
df.viii.i.ii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp <- correlationBF(questionnaires[,v], questionnaires[,'advisorAge'])
df.viii.i.ii <- rbind(df.viii.i.ii, data.frame(variable = v,
corellationBF = exp(tmp@bayesFactor$bf)))
}
print(df.viii.i.ii)
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorPortrait + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iii <- rbind(df.viii.i.iii, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
print(df.viii.i.iii)
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iv <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorName + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iv <- rbind(df.viii.i.iv, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
print(df.viii.i.iv)
aov.viii.ii <- manova(cbind(ability, likeability, benevolence) ~ adviceType * timepoint,# + Error(pid),
data = questionnaires)
print(summary(aov.viii.ii))
df.viii.ii <- NULL
tmp <- questionnaires[ ,c('likeability', 'benevolence', 'ability', 'pid', 'adviceType', 'timepoint')]
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[ ,v]
tmp.2 <- aggregate(v ~ adviceType + timepoint + pid,
data = tmp,
FUN = mean)
for(aT in c(5,6)) {
if(aT == adviceTypes$neutral)
next()
for(tp in unique(tmp.2$timepoint)) {
x <- tmp.2$v[tmp.2$adviceType==aT & tmp.2$timepoint==tp]
df.viii.ii <- rbind(df.viii.ii, data.frame(domain = v,
adviceType=aT,
timepoint=tp,
mu=mean(x),
ci95low=mean_cl_normal(x)$ymin,
ci95hi =mean_cl_normal(x)$ymax))
}
}
}
df.viii.ii[ ,4:6] <- round(df.viii.ii[ ,4:6],2)
df.viii.ii$adviceType <- sapply(df.viii.ii$adviceType, getAdviceTypeName)
df.viii.ii[order(df.viii.ii$timepoint), ]
# TODO ####
# tidy the hell out of this graph. Should allow easy discrimination
# between advice type assessment changes over time.
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
tmp <- melt(tmp, id.vars = c('adviceType', 'timepoint', 'pid'))
gg.viii.iii <- ggplot(tmp, aes(x = variable, y = value, colour = as.factor(timepoint))) +
geom_boxplot() +
scale_y_continuous(limits = c(0,100)) +
facet_grid(~ adviceType) +
style
gg.viii.iii
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.ix.i <- t.test(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
d <- cohensD(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high])
tB.ix.i <- ttestBF(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
print('Choice proportion HighAcc in low- vs high-confidence trials')
prettyPrint(t.ix.i,d)
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low], 'low')
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high], 'high')
print('Bayesian examination of above (prior = mean diff of 0, sd as empirically observed)')
print(tB.ix.i)
print(paste0('Evidence strength for differential high/low confidence picking strategy: BF=',
round(exp(tB.ix.i@bayesFactor$bf),3)))
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
# calculate difference scores
for(i in 1:nrow(tmp))
if(tmp$timepoint[i]==2)
tmp[i,4:6] <- tmp[i, 4:6] - tmp[tmp$timepoint==1
& tmp$pid == tmp$pid[i]
& tmp$adviceType == tmp$adviceType[i], 4:6]
tmp.2 <- aggregate(influence ~ adviceType + pid + hasChoice,
data = trials, FUN = mean)
tmp$influence <- sapply(1:nrow(tmp), function(i){tmp.2$influence[tmp.2$hasChoice
& tmp.2$pid == tmp$pid[i]
& tmp.2$adviceType == tmp$adviceType[i]]})
# The test is a regression with the change in subjective variables as predictors
lm.x.i <- lm(influence ~ ability + benevolence + likeability, data = tmp)
print(summary(lm.x.i))
tmp <- melt(tmp[tmp$timepoint==2, ], id.vars = c('adviceType', 'pid', 'timepoint', 'influence'),
measure.vars = c('likeability', 'ability', 'benevolence'),
variable.name = 'trustDimension', value.name = 'trust')
gg.x.ii <- ggplot(tmp, aes(x = trust, y = influence, colour = factor(adviceType))) +
geom_point(alpha = 0.33) +
geom_smooth(method = 'lm', aes(fill = factor(adviceType)), alpha = 0.1) +
facet_grid(trustDimension ~ .) +
coord_fixed(ratio = 3, expand = F) +
scale_x_continuous(name = 'Trust change') +
scale_y_continuous(name = 'Influence') +
scale_color_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
style
gg.x.ii
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ pid,
data = questionnaires[questionnaires$timepoint==1,],
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.i <- rbind(df.xi.i, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
print(df.xi.i)
tmp.2 <- melt(tmp, id.vars = c('pid'), measure.vars = c('likeability', 'ability', 'benevolence'))
tmp.2$genTrust <- sapply(tmp.2$pid, function(x) tmp$genTrust[tmp$pid==x][1])
gg.xi.i <- ggplot(tmp.2, aes(x = genTrust, y = value)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
facet_grid(variable ~ .) +
style.long
gg.xi.i
tmp <- aggregate(cbind(influence, rawInfluence) ~ pid,
data = trials,
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.ii <- NULL
for(v in c('rawInfluence', 'influence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.ii <- rbind(df.xi.ii, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
print(df.xi.ii)
gg.xi.ii <- ggplot(tmp, aes(x = genTrust, y = influence)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
style.long
gg.xi.ii
