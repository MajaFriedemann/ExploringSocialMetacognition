printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
tmp$adviceType <- factor(tmp$adviceType)
gg.vii.ii <- ggplot(tmp, aes(advisorAgrees, influence, color = adviceType, fill = adviceType)) +
geom_point(position = position_jitter(w=0.1, h=0), alpha = 0.5) +
stat_summary(geom = "errorbar",
fun.data = "mean_cl_boot",
width = 0.2) +
stat_summary(geom = "point",
fun.y = "mean",
shape = 23, size = 5) +
stat_summary(aes(group = adviceType), fun.y=mean, geom="line") +
facet_grid(.~hasChoice,
labeller = as_labeller(c('FALSE'='Forced trials','TRUE'='Choice trials'))) +
scale_color_discrete(name = 'Advisor type', labels = getAdviceTypeNames(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advisor type', labels = getAdviceTypeNames(unique(tmp$adviceType))) +
scale_x_discrete(name = 'Judge-advisor agreement', labels = c('Disagree', 'Agree')) +
labs(title = "Advice Influence",
legend = NULL,
y = "Influence of the advice") +
style
gg.vii.ii
# Influence of advice under varied conditions. Points indicate mean values for a
# participant, while diamonds indicate the mean of participant means, with error
# bars specifying 95% confidence intervals.
tmp$adviceType <- factor(tmp$adviceType)
gg.vii.ii <- ggplot(tmp, aes(advisorAgrees, influence, color = adviceType, fill = adviceType)) +
geom_point(position = position_jitter(w=0.1, h=0), alpha = 0.5) +
stat_summary(geom = "errorbar",
fun.data = "mean_cl_boot",
width = 0.2) +
stat_summary(geom = "point",
fun.y = "mean",
shape = 23, size = 5) +
stat_summary(aes(group = adviceType), fun.y=mean, geom="line") +
facet_grid(.~hasChoice,
labeller = as_labeller(c('FALSE'='Forced trials','TRUE'='Choice trials'))) +
scale_color_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_x_discrete(name = 'Judge-advisor agreement', labels = c('Disagree', 'Agree')) +
labs(title = "Advice Influence",
legend = NULL,
y = "Influence of the advice") +
style
gg.vii.ii
gg.vii.ii <- ggplot(tmp, aes(advisorAgrees, influence, color = adviceType, fill = adviceType)) +
geom_point(position = position_jitter(w=0.1, h=0), alpha = 0.5) +
stat_summary(geom = "errorbar",
fun.data = "mean_cl_boot",
width = 0.2) +
stat_summary(geom = "point",
fun.y = "mean",
shape = 23, size = 5) +
stat_summary(aes(group = adviceType), fun.y=mean, geom="line") +
facet_grid(.~hasChoice,
labeller = as_labeller(c('FALSE'='Forced trials','TRUE'='Choice trials'))) +
scale_color_discrete(name = 'Advisor type') +
scale_fill_discrete(name = 'Advisor type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_x_discrete(name = 'Judge-advisor agreement', labels = c('Disagree', 'Agree')) +
labs(title = "Advice Influence",
legend = NULL,
y = "Influence of the advice") +
style
gg.vii.ii
tmp <- aggregate(influence ~ adviceType + hasChoice + advisorAgrees + pid,
data = trials[trials$confidenceCategory==confidenceCategories$medium
& trials$finalAnswer==trials$correctAnswer, ],
FUN = mean)
aov.vii.iii <- aov(influence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('As above, looking at only trials where intial decision was correct and made with middle confidence:')
print(summary(aov.vii.iii))
print('Means:')
printMean(tmp$influence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$influence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$influence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$influence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$influence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$influence[!tmp$advisorAgrees], 'Mean|Disagree')
tmp <- aggregate(rawInfluence ~ adviceType + hasChoice + advisorAgrees + pid, data = trials, FUN = mean)
print('Running ANOVAs')
aov.vii.iv <- aov(rawInfluence ~ adviceType * hasChoice * advisorAgrees +
Error(pid / (adviceType + hasChoice + advisorAgrees)),
data=tmp)
print('Original mixed ANOVA using raw influence scores')
print(summary(aov.vii.iv))
print('Means:')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$HighAcc], 'Mean|HighAcc')
printMean(tmp$rawInfluence[tmp$adviceType==adviceTypes$LowAcc], 'Mean|LowAcc')
printMean(tmp$rawInfluence[tmp$hasChoice], 'Mean|Choice')
printMean(tmp$rawInfluence[!tmp$hasChoice], 'Mean|Forced')
printMean(tmp$rawInfluence[tmp$advisorAgrees], 'Mean|Agree')
printMean(tmp$rawInfluence[!tmp$advisorAgrees], 'Mean|Disagree')
#   8.i) Bayesian no-difference tests for advisor properties ####
print('Bayesian tests investigating advisor properties')
# We want to show that the randomly assigned advisor race/age/portrait/name had
# no effect. We will do this by showing that they did not differ between
# timepoints.
#     8.i.i) Race
print('8.i.i Race')
df.viii.i.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
x <- questionnaires[questionnaires$advisorCategory=='b',v]
y <- questionnaires[questionnaires$advisorCategory=='w',v]
bf <- ttestBF(x,y)
df.viii.i.i <- rbind(df.viii.i.i, data.frame(variable = v,
BF = exp(bf@bayesFactor$bf),
mu1 = mean(x),
mu2 = mean(y)))
}
print(df.viii.i.i)
#     8.i.ii) Age
print('8.i.ii Age')
df.viii.i.ii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp <- correlationBF(questionnaires[,v], questionnaires[,'advisorAge'])
df.viii.i.ii <- rbind(df.viii.i.ii, data.frame(variable = v,
corellationBF = exp(tmp@bayesFactor$bf)))
}
print(df.viii.i.ii)
#     8.i.iii) Portrait
print('8.i.iii Portrait')
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iii <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorPortrait + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iii <- rbind(df.viii.i.iii, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
print(df.viii.i.iii)
#     8.i.iv) Name
print('8.i.iv Name')
tmp <- questionnaires
tmp$pid <- as.factor(tmp$pid)
df.viii.i.iv <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[,v]
tmp.aov <- anovaBF(v ~ advisorName + pid, data = tmp, whichRandom = 'pid', progress = F)
df.viii.i.iv <- rbind(df.viii.i.iv, data.frame(variable = v,
BF = exp(tmp.aov@bayesFactor$bf)))
}
print(df.viii.i.iv)
# If any of the above do show significant differences then we'll have to show
# that the factors which differ are not systematically linked to the advice type
# in order to demonstrate that they're not responsible for any advice type
# effects we observe
print('8.ii AdviceType x Timepoint MANOVA')
aov.viii.ii <- manova(cbind(ability, likeability, benevolence) ~ adviceType * timepoint,# + Error(pid),
data = questionnaires)
print(summary(aov.viii.ii))
df.viii.ii <- NULL
tmp <- questionnaires[ ,c('likeability', 'benevolence', 'ability', 'pid', 'adviceType', 'timepoint')]
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[ ,v]
tmp.2 <- aggregate(v ~ adviceType + timepoint + pid,
data = tmp,
FUN = mean)
for(aT in adviceTypes) {
if(aT == adviceTypes$neutral)
next()
for(tp in unique(tmp.2$timepoint)) {
x <- tmp.2$v[tmp.2$adviceType==aT & tmp.2$timepoint==tp]
df.viii.ii <- rbind(df.viii.ii, data.frame(domain = v,
adviceType=aT,
timepoint=tp,
mu=mean(x),
ci95low=mean_cl_normal(x)$ymin,
ci95hi =mean_cl_normal(x)$ymax))
}
}
}
df.viii.ii[ ,4:6] <- round(df.viii.ii[ ,4:6],2)
df.viii.ii$adviceType <- sapply(df.viii.ii$adviceType, getAdviceTypeName)
df.viii.ii[order(df.viii.ii$timepoint), ]
df.viii.ii <- NULL
tmp <- questionnaires[ ,c('likeability', 'benevolence', 'ability', 'pid', 'adviceType', 'timepoint')]
for(v in c('likeability', 'ability', 'benevolence')) {
tmp$v <- tmp[ ,v]
tmp.2 <- aggregate(v ~ adviceType + timepoint + pid,
data = tmp,
FUN = mean)
for(aT in c(5,6)) {
if(aT == adviceTypes$neutral)
next()
for(tp in unique(tmp.2$timepoint)) {
x <- tmp.2$v[tmp.2$adviceType==aT & tmp.2$timepoint==tp]
df.viii.ii <- rbind(df.viii.ii, data.frame(domain = v,
adviceType=aT,
timepoint=tp,
mu=mean(x),
ci95low=mean_cl_normal(x)$ymin,
ci95hi =mean_cl_normal(x)$ymax))
}
}
}
df.viii.ii[ ,4:6] <- round(df.viii.ii[ ,4:6],2)
df.viii.ii$adviceType <- sapply(df.viii.ii$adviceType, getAdviceTypeName)
df.viii.ii[order(df.viii.ii$timepoint), ]
tmp <- aggregate(adviceType ~ pid + confidenceCategory,
data = trials[trials$type==trialTypes$choice, ],
FUN = function(x)sum(x==adviceTypes$HighAcc)/length(x))
t.ix.i <- t.test(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
d <- cohensD(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high])
tB.ix.i <- ttestBF(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low],
tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high],
paired = T)
print('Choice proportion HighAcc in low- vs high-confidence trials')
prettyPrint(t.ix.i,d)
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$low], 'low')
printMean(tmp$adviceType[tmp$confidenceCategory==confidenceCategories$high], 'high')
print('Bayesian examination of above (prior = mean diff of 0, sd as empirically observed)')
print(tB.ix.i)
print(paste0('Evidence strength for differential high/low confidence picking strategy: BF=',
round(exp(tB.ix.i@bayesFactor$bf),3)))
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ adviceType + timepoint + pid,
data = questionnaires, FUN = mean)
# calculate difference scores
for(i in 1:nrow(tmp))
if(tmp$timepoint[i]==2)
tmp[i,4:6] <- tmp[i, 4:6] - tmp[tmp$timepoint==1
& tmp$pid == tmp$pid[i]
& tmp$adviceType == tmp$adviceType[i], 4:6]
tmp.2 <- aggregate(influence ~ adviceType + pid + hasChoice,
data = trials, FUN = mean)
tmp$influence <- sapply(1:nrow(tmp), function(i){tmp.2$influence[tmp.2$hasChoice
& tmp.2$pid == tmp$pid[i]
& tmp.2$adviceType == tmp$adviceType[i]]})
# The test is a regression with the change in subjective variables as predictors
lm.x.i <- lm(influence ~ ability + benevolence + likeability, data = tmp)
print(summary(lm.x.i))
print('10.ii Graph of questionnaire-influence correlation')
tmp <- melt(tmp[tmp$timepoint==2, ], id.vars = c('adviceType', 'pid', 'timepoint', 'influence'),
measure.vars = c('likeability', 'ability', 'benevolence'),
variable.name = 'trustDimension', value.name = 'trust')
gg.x.ii <- ggplot(tmp, aes(x = trust, y = influence, colour = factor(adviceType))) +
geom_point(alpha = 0.33) +
geom_smooth(method = 'lm', aes(fill = factor(adviceType)), alpha = 0.1) +
facet_grid(trustDimension ~ .) +
coord_fixed(ratio = 3, expand = F) +
scale_x_continuous(name = 'Trust change') +
scale_y_continuous(name = 'Influence') +
scale_color_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
scale_fill_discrete(name = 'Advice type', labels = getAdviceTypeName(unique(tmp$adviceType))) +
style
gg.x.ii
# The test is a regression with the change in subjective variables as predictors
lm.x.i <- lm(influence ~ ability + benevolence + likeability, data = tmp)
print(summary(lm.x.i))
tmp <- aggregate(cbind(likeability, ability, benevolence) ~ pid,
data = questionnaires[questionnaires$timepoint==1,],
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.i <- NULL
for(v in c('likeability', 'ability', 'benevolence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.i <- rbind(df.xi.i, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
print(df.xi.i)
tmp.2 <- melt(tmp, id.vars = c('pid'), measure.vars = c('likeability', 'ability', 'benevolence'))
tmp.2$genTrust <- sapply(tmp.2$pid, function(x) tmp$genTrust[tmp$pid==x][1])
gg.xi.i <- ggplot(tmp.2, aes(x = genTrust, y = value)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
facet_grid(variable ~ .) +
style.long
gg.xi.i
tmp <- aggregate(cbind(influence, rawInfluence) ~ pid,
data = trials,
FUN = mean)
tmp$genTrust <- sapply(tmp$pid, function(x) genTrustQ$answer[genTrustQ$pid==x & genTrustQ$order==0])
df.xi.ii <- NULL
for(v in c('rawInfluence', 'influence')) {
tmp.2 <- cor.test(tmp[,v], tmp[,'genTrust'])
df.xi.ii <- rbind(df.xi.ii, data.frame(variable = v,
corellation = tmp.2$estimate,
p.value = tmp.2$p.value,
method = tmp.2$method))
}
print(df.xi.ii)
gg.xi.ii <- ggplot(tmp, aes(x = genTrust, y = influence)) +
geom_smooth(method = 'lm') +
geom_point(aes(colour = as.factor(pid))) +
style.long
gg.xi.ii
df.xii <- NULL
for(pid in unique(trials$pid)) {
tmp <- trials[trials$pid==pid, ]
tmp$adviceType <- as.factor(tmp$adviceType)
ans <- glm(adviceType ~ initialConfidence, tmp, family = binomial(link = "logit"))
s <- summary(ans)
df.xii <- rbind(df.xii, data.frame(pid,
coef = s$coefficients[2,1],
p = s$coefficients[2,4]))
}
tmp <- df.xii
names(tmp)[2] <- 'y'
tmp$x <- 0
gg.xii <- ggplot(tmp, aes(x = p)) + geom_freqpoly(binwidth = 0.1)
gg.xii
tmp <- aggregate(influence ~ confidenceCategory + pid, data = trials, FUN = mean)
gg.xiii <- ggplot(tmp, aes(x = confidenceCategory, y = influence)) +
geom_point(aes(colour = as.factor(pid)), alpha = 0.5) +
geom_smooth(method = 'lm',
aes(group = as.factor(pid), colour = as.factor(pid)),
se = F,
alpha = 0.2) +
stat_summary(geom = 'errorbar', fun.data = mean_cl_boot) +
style.long
gg.xiii
summary(aov(influence ~ confidenceCategory, data = tmp))
ggplot(tmp, aes(x = id, y = dotDifference)) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(60,246)) +
style.long +
labs(title = 'Participant {frame_time}') +
transition_time(pid) +
enter_fade() +
ease_aes('sine-in-out')
g <- ggplot(trials, aes(x = id, y = dotDifference)) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(60,246)) +
style.long +
labs(title = 'Participant {frame_time}') +
transition_time(pid) +
enter_fade() +
ease_aes('sine-in-out')
ggplot(trials, aes(x = id, y = dotDifference)) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(60,246)) +
style.long +
labs(title = 'Participant {frame_time}') +
transition_time(pid) +
enter_fade() +
ease_aes('sine-in-out')
animate(g, fps = 1)
g <- ggplot(trials, aes(x = id, y = dotDifference)) +
geom_line() +
geom_smooth(method = 'lm') +
scale_x_continuous(limits = c(60,246)) +
style.long +
labs(title = 'Participant {frame_time}') +
transition_time(pid)
animate(g, fps = 1)
rawString <- '5b273d968ecf3f00016196af
24/08/2018, 02:35
00:38:23
MX5PC2Z4
AWAITING REVIEW
581f7a5a8b59c10001c1751f
24/08/2018, 02:48
N/A
RETURNED
5a9aa65f89de8200013f06a4
24/08/2018, 02:42
01:04:15
MX5PC2Z4
AWAITING REVIEW
59694132739fc30001e0ae05
24/08/2018, 02:43
00:44:05
MX5PC2Z4
AWAITING REVIEW
5b0930cb6cae6100014eca14
24/08/2018, 02:43
N/A
TIMED-OUT
5a910c8a6475f900019f8cbc
24/08/2018, 02:45
N/A
TIMED-OUT
5a962de3b5e2110001c69d4e
24/08/2018, 04:15
00:43:33
MX5PC2Z4
AWAITING REVIEW
5af0ef6a5bbd0b00015ebfb1
24/08/2018, 04:21
N/A
TIMED-OUT
5b6ee654024b250001f442bc '
if(!require(scoring)) {
install.packages('scoring')
library(scoring)
}
citation('scoring')
if(!require(digest)) {
install.packages('digest')
library(digest)
}
citation('digest')
tmp <- all.trials[,c('initialCorrect', 'initialConfidence', 'pid')]
tmp$initialCorrect <- as.numeric(tmp$initialCorrect)
tmp$initialConfidence <- tmp$initialConfidence/50
scores <- brierscore(initialCorrect ~ initialConfidence, data = tmp, group = 'pid')
scores$brieravg
if(exists('rawString')) {
prolificIds <- NULL
matches <- gregexpr('5[a-z0-9]{23}', rawString)
for(x in matches[[1]])
prolificIds <- c(prolificIds, substr(rawString, x, x+23))
}
if(exists('prolificIds')) {
prolificIdHashes <- sapply(prolificIds,digest,algo='sha1',serialize=F)
tmp <- NULL
for(i in 1:length(names(scores$brieravg))) {
pid <- names(scores$brieravg)[i]
proId <- names(prolificIdHashes)[prolificIdHashes %in% all.participants$id[all.participants$pid==pid]]
if(length(proId)>0)
tmp <- rbind(tmp, data.frame(pid,
prolificId = proId,
brieravg = scores$brieravg[i],
excluded = all.participants$excluded[all.participants$pid==pid],
extra = all.participants$debriefComments[all.participants$pid==pid]))
else
print(paste('PID',pid,'has no prolific hash associated'))
}
markers <- quantile(tmp$brieravg[tmp$excluded==F])
for(i in 1:nrow(tmp)) {
tmp$quantile[i] <- which(markers >= tmp$brieravg[i])[1]
tmp$reward[i] <- round(2 - 2/(length(markers)-1)*(tmp$quantile[i]-1),2)
}
tmp$reward[tmp$excluded!=F] <- 0 # no bonus for excluded participants
for(r in 1:nrow(tmp))
print(paste0(tmp$prolificId[r], ', ', tmp$reward[r]))
prolificIds[!(prolificIds %in% tmp$prolificId)]
write.csv(data.frame(id = tmp$prolificId[tmp$reward>0], name = tmp$reward[tmp$reward>0]),
'tmp.csv',
sep = ',',
row.names = F,
col.names = F,
quote = F)
}
tmp
#   5.iv) Graph: Initial vs Final confidence ####
print('5.iv Graph of initial vs final confidence')
# Influence of the advisors is evident in the deviation from the dashed y=x
# line. Points lying below the line indicate a more leftward response from
# initial to final judgement. Points above the line indicate a more rightward
# response in the final judgement. The further away from the y=x line, the
# greater the change from initial to final judgement. Separate plots show
# agreement vs disagreement trials (between the advisor and judge), and separate
# colours indicate whether the judge's final decision was correct or incorrect.
# The shaded area indicates the boundary for the symmetrical influence measure.
# Points outside this area are truncated by moving them vertically until they
# meet the grey area.
df.poly1 <- data.frame(    # These polygon points define a parellelogram marking the limits for the capped influence
x=c(50, 0, 0),
y=c(50, 50, -50)
)
df.poly2 <- df.poly1 * -1
gg.v.iv <- ggplot(trials, aes(x = initialConfSpan, y = finalConfSpan)) +
geom_polygon(data = df.poly1, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_polygon(data = df.poly2, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_point(alpha = 0.2, aes(color = factor(finalCorrect))) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed', size = 1, color = 'black') +
scale_color_discrete(name = 'Final judgement', labels = c('Incorrect', 'Correct')) +
scale_x_continuous(limits = c(-50,50), expand = c(0,0)) +
scale_y_continuous(limits = c(-50,50), expand = c(0,0)) +
facet_grid(~advisorAgrees, labeller = as_labeller(c('FALSE'='Disagree', 'TRUE'='Agree'))) +
labs(title = "Initial vs final confidence",
legend = NULL,
x = 'Initial confidence',
y = "Final confidence") +
coord_fixed() +
style +
theme(panel.spacing = unit(1.5, 'lines'),
plot.margin = unit(c(0,1,0,0.5), 'lines'))
gg.v.iv
df.v.iv <- NULL
for(a in c(T,F)) {
v <- trials[trials$advisorAgrees == a, ]
i <- mean(v$confidenceShiftRaw > 0)
d <- mean(v$confidenceShiftRaw < 0)
n <- mean(v$confidenceShiftRaw == 0)
df.v.iv <- rbind(df.v.iv, data.frame(advisorAgrees = a,
increaseConfPerC = i,
noChangePerC = n,
decreaseConfPerC = d))
}
print(df.v.iv)
ggplot(trials, aes(x = initialConfSpan, y = finalConfSpan, shape = (pid==4))) +
geom_polygon(data = df.poly1, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_polygon(data = df.poly2, aes(x,y), fill = 'grey', alpha = 0.2) +
geom_point(alpha = 0.2, aes(color = factor(finalCorrect))) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed', size = 1, color = 'black') +
scale_color_discrete(name = 'Final judgement', labels = c('Incorrect', 'Correct')) +
scale_x_continuous(limits = c(-50,50), expand = c(0,0)) +
scale_y_continuous(limits = c(-50,50), expand = c(0,0)) +
facet_grid(~advisorAgrees, labeller = as_labeller(c('FALSE'='Disagree', 'TRUE'='Agree'))) +
labs(title = "Initial vs final confidence",
legend = NULL,
x = 'Initial confidence',
y = "Final confidence") +
coord_fixed() +
style +
theme(panel.spacing = unit(1.5, 'lines'),
plot.margin = unit(c(0,1,0,0.5), 'lines'))
