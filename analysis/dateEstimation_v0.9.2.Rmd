---
title: "Date estimation analysis"
output:
  html_document:
    df_print: paged
---

[Script run `r Sys.time()`]

```{r prematter, include = F}

library(knitr)
library(tidyverse)
library(lsr)
library(prettyMD)

opts_chunk$set('echo' = F)

set.seed(20190402)

```

## Load data

```{r}
version <- "0.9.2"

DE <- as.tibble(read.csv("../data/public/dateCheck_trialStream.csv"))
DE.general <- as.tibble(read.csv("../data/private/dateCheck_general-feedback.csv"))

DE <- DE[DE$studyVersion == version, ]
DE.general <- DE.general[DE.general$studyVersion == version, ]

if (F) {
  # assign new ids by sequential qNumber
  DE$newId <- -1
  q <- Inf
  id <- 0
  for (i in 1:nrow(DE)) {
    if (DE$qNumber[i] <= q) {
      id <- id + 1
    }
    q <- DE$qNumber[i]
    DE$newId[i] <- id
  }
  
  DE$oldId <- DE$id
  DE$id <- factor(DE$newId)
  DE$newId <- NULL
}

if (F) {
  # pad out short testing data with simulated stuff
  for (id in unique(DE$id)) {
    tmp <- NULL
    
    n = sum(DE$id == id) 
    if (n < 30) {
      for (i in 1:(30 - n)) {
        # random question not yet answered
        q <- base::sample(unique(DE$qPrompt[!(DE$qPrompt %in% DE$qPrompt[DE$id == id])]), 1)
        qRow <- DE[DE$qPrompt == q, ][1, ]
        r <- DE[DE$id == id, ][1, ]
        r$qPrompt <- q
        r$qTarget <- qRow$qTarget
        r$qTopic <- qRow$qTopic
        r$timeA <- 100
        r$estimate <- rnorm(1, r$qTarget, 10)
        r$after <- rnorm(1, r$estimate - 10, 5)
        r$before <- rnorm(1, r$estimate + 10, 5)
        tmp <- rbind(tmp, r)
      }
    }
    DE <- rbind(DE, tmp)
  }
}

```

### Clean data

Sane responses fulfil all:

* estimate (1825, 1975)

* after <= estimate

* before >= estimate

* after >= 1800

* before <= 2000


```{r}

DE$okayResponse <- factor(T)
levels(DE$okayResponse) <- c(T,
                             "Estimate out of range",
                             "After out of range",
                             "Before out of range",
                             "After after estimate",
                             "Before before estimate")

DE$okayResponse[DE$estimate > 1975 | DE$estimate < 1825] <- "Estimate out of range"
DE$okayResponse[DE$after < 1800] <- "After out of range"
DE$okayResponse[DE$before > 2000] <- "Before out of range"
DE$okayResponse[DE$after > DE$estimate] <- "After after estimate"
DE$okayResponse[DE$before < DE$estimate] <- "Before before estimate"

kable(table(DE$okayResponse))

```

## Participants performance

```{r}

DE.pSummary <- NULL
for (id in unique(DE$id)) {
  tmp <- DE[DE$id == id, ]
  tmp$error <- abs(tmp$estimate - tmp$qTarget)
  x <- tibble(id, 
              questionCount = nrow(tmp),
              hitRate = mean(tmp$estimate == tmp$qTarget),
              bracketRate = mean(tmp$after <= tmp$qTarget &
                                   tmp$before >= tmp$qTarget),
              goodAnswerRate = mean(tmp$okayResponse == T),
              meanError = mean(tmp$error),
              sdError = sd(tmp$error),
              meanBracketWidth = mean(tmp$before - tmp$after),
              sdBracketWidth = sd(tmp$before - tmp$after),
              meanRT = mean(tmp$timeA))
  
  DE.pSummary <- rbind(DE.pSummary, x)
}

DE.general[, 4:6] <- DE.general[, 4:6] / 100
DE.pSummary <- left_join(DE.pSummary, DE.general[, 3:6], by = "id")

kable(num2str(DE.pSummary[order(DE.pSummary$bracketRate, decreasing = T), ]))

```


Before we remove outliers, we want a look at how the data stack up (so when we throw away data we know what we're losing):

```{r}

DE$error <- abs(DE$estimate - DE$qTarget)
DE$bracketed <- as.numeric(DE$after <= DE$qTarget & DE$before >= DE$qTarget)
DE$bWidth <- DE$before - DE$after
DE$hit <- as.numeric(DE$estimate == DE$qTarget)

vars <- c('error', 'timeA', 'bracketed', 'bWidth', 'hit')
DE.p <- NULL
for (id in unique(DE$id)) {
  tmp <- DE[DE$id == id, ]
  for (v in vars) {
    cl <- mean_cl_normal(tmp[[v]])
    myRow <- tibble(id, variable = v, mean = cl$y, 
                    cl95L = cl$ymin, cl95H = cl$ymax)
    
    DE.p <- rbind(DE.p, myRow)
  }
}

ggplot(DE.p, aes(x = "", 
                 y = mean, ymin = cl95L, ymax = cl95H, colour = id)) +
  geom_violin(aes(group = 1), color = NA, fill = "grey90") +
  geom_boxplot(aes(group = 1), fill = NA, outlier.color = NA) +
  geom_point(position = position_dodge(width = .75), alpha = .5) +
  facet_wrap(.~variable, labeller = label_both, scales = "free_y") +
  labs(x = "", y = "mean +/- 95% CI") + 
  theme_light()

```

From here on down we remove invalid responses and participants who over- and underperformed. 

First we drop the `r sum(DE.pSummary$questionCount != 50)` participants who did the wrong number of questions. 

Next we drop the `r sum(DE.pSummary$goodAnswerRate < .80)` participants who failed to provide at least 80% sensible answers (of whom `r sum(DE.pSummary$meanBracketWidth < 0)` probably got 'after' and 'before' dates the wrong way around). 

```{r}

# remove dumb responses
DE <- DE[DE$okayResponse == T, ]

# remove bad participants
DE.pSummary$include <- T
DE.pSummary$include[DE.pSummary$questionCount != 50] <- "qCount"
DE.pSummary$include[DE.pSummary$goodAnswerRate < .80] <- "badAnswers"

ok <- DE.pSummary$id[DE.pSummary$include == T]

DE.pSummary <- DE.pSummary[DE.pSummary$include == T, ]
DE <- DE[DE$id %in% ok, ]

```

Having removed those, we then remove the `r sum(abs(scale(DE.pSummary$hitRate)) > 2)` participants with hitrate > 2SD away from the population mean, because they probably looked up the answers (this is not a throwaway; individual answers have been checked and suggest a pattern). 

Finally, we remove the `r sum(abs(scale(DE.pSummary$meanBracketWidth)) > 2)` participants with a mean bracket width > 2SD away from the population mean because they're not easily comparable with the others.

```{r}

DE.pSummary$include[abs(scale(DE.pSummary$hitRate)) > 2] <- "accuracy>2sd"
DE.pSummary$include[abs(scale(DE.pSummary$meanBracketWidth)) > 2] <- "bracketWidth>2sd"

ok <- DE.pSummary$id[DE.pSummary$include == T]

DE.pSummary <- DE.pSummary[DE.pSummary$include == T, ]
DE <- DE[DE$id %in% ok, ]

```

With those participants removed, we can provide some general information about performance based on the `r nrow(DE.pSummary)` participants who remain:

```{r}

tmp <- NULL
for (v in colnames(DE.pSummary)) {
  if (is.numeric(DE.pSummary[[v]])) {
    m <- mean(DE.pSummary[[v]])
    s <- sd(DE.pSummary[[v]])
    tmp <- rbind(tmp, tibble(mean = m, sd = s, var = v))
  }
}

kable(num2str(tmp))

```

Having filtered out those who performed suspiciously, those who remain appear to have performed the task properly, getting few questions exactly right, answering almost all questions sensibly, and identifying the correct period approximately half the time. 

### Performance overview

```{r}

ggplot(DE.p, aes(x = "", 
                 y = mean, ymin = cl95L, ymax = cl95H, colour = id)) +
  geom_violin(aes(group = 1), color = NA, fill = "grey90") +
  geom_boxplot(aes(group = 1), fill = NA, outlier.color = NA) +
  geom_point(position = position_dodge(width = .75), alpha = .5) +
  facet_wrap(.~variable, labeller = label_both, scales = "free_y") +
  labs(x = "", y = "mean +/- 95% CI") + 
  theme_light()

```

## Experiment feedback

```{r}

DE.feedback <- gather(DE.pSummary, key = "question", value = "rating", hard_easy:tooLong_tooShort)

ggplot(DE.feedback,  aes(x = "", y = rating, colour = id)) +
  geom_violin(aes(group = 1), colour = NA, fill = "grey90") +
  geom_point(position = position_dodge(width = .75), alpha = .5) +
  stat_summary(geom = "point", aes(group = 1), fun.y = mean) +
  stat_summary(geom = "errorbar", aes(group = 1), fun.data = mean_cl_normal) +
  facet_wrap(.~question, labeller = label_both) +
  labs(x = "", y = "mean rating") + 
  theme_light()

```

### Difficulty rating vs hit/bracket rate

```{r}

eq <- lm(hitRate ~ hard_easy, DE.pSummary)

ggplot(DE.pSummary, aes(x = hard_easy, y = hitRate, color = id)) +
  geom_point() +
  geom_smooth(method = "lm", aes(group = 1)) + 
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  coord_fixed() +
  annotate(geom = "text", x = .5, y = 1, label = 
             paste0("y = ", round(eq$coefficients[2], 2), "x + ",
                    round(eq$coefficients[1], 2), "\n",
                    "p = ", round(summary(eq)$coefficients[2,4], 3))) +
  theme_light()

```


```{r}

eq <- lm(bracketRate ~ hard_easy, DE.pSummary)

ggplot(DE.pSummary, aes(x = hard_easy, y = bracketRate, color = id)) +
  geom_point() +
  geom_smooth(method = "lm", aes(group = 1)) + 
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  coord_fixed() +
  annotate(geom = "text", x = .5, y = 1, label = 
             paste0("y = ", round(eq$coefficients[2], 2), "x + ",
                    round(eq$coefficients[1], 2), "\n",
                    "p = ", round(summary(eq)$coefficients[2,4], 3))) +
  theme_light()

```

## Further performance investigations

### Bracket rate by bracket width

```{r}

eq <- lm(bracketRate ~ meanBracketWidth, DE.pSummary)

ggplot(DE.pSummary, aes(x = meanBracketWidth, y = bracketRate, color = id)) +
  geom_point() +
  geom_smooth(method = "lm", aes(group = 1)) + 
  scale_y_continuous(limits = c(0, 1)) +
  annotate(geom = "text", x = .5, y = 1, hjust = 0,
           label = paste0("y = ", round(eq$coefficients[2], 2), "x + ",
                    round(eq$coefficients[1], 2), "\n",
                    "p = ", round(summary(eq)$coefficients[2,4], 3))) +
  theme_light()

```


## Performance by item

Sorted by bracketed %, decreasing.

```{r}

DE.i <- NULL
DE.iW <- NULL # wide version
for (q in unique(DE$qPrompt)) {
  tmp <- DE[DE$qPrompt == q, ]
  wRow <- tibble(q, 
                 qShort = substr(q, 0, 20), 
                 target = tmp$qTarget[1], 
                 topic = tmp$qTopic[1],
                 n = nrow(tmp))
  
  for (v in vars) {
    cl <- mean_cl_normal(tmp[[v]])
    myRow <- tibble(q, 
                    qShort = substr(q, 0, 20), 
                    target = tmp$qTarget[1], 
                    topic = tmp$qTopic[1],
                    n = nrow(tmp),
                    variable = v, 
                    mean = mean(tmp[[v]]), 
                    sd = sd(tmp[[v]]))
    
    DE.i <- rbind(DE.i, myRow)
    
    x <- tibble(mean = mean(tmp[[v]]), sd = sd(tmp[[v]]))
    names(x) <- paste(v, c("m", "sd"), sep = ".")
    wRow <- cbind(wRow, x)
  }
    
  DE.iW <- rbind(DE.iW, wRow)
}

DE.iW <- as.tibble(DE.iW)

kable(num2str(DE.iW[order(DE.iW$bracketed.m, DE.iW$n, decreasing = T), -1]))

```

```{r}

DE.i <- DE.i[order(DE.i$topic), ]
DE.i$qShort <- factor(DE.i$qShort, levels = unique(DE.i$qShort))

m <- aggregate(mean ~ variable, DE.i, mean)

for (cat in unique(DE.i$topic)) {
  tmp <- DE.i[DE.i$topic == cat, ]
  
  gg <- ggplot(tmp, aes(x = qShort, 
                   y = mean, ymin = mean - sd, ymax = mean + sd)) +
    geom_hline(aes(yintercept = mean),
               data = aggregate(mean ~ variable, DE.i, mean)) +
    geom_point() +
    geom_errorbar() +
    facet_grid(variable~., labeller = label_value, scales = "free_y") +
    labs(x = "", y = "mean +/- SD") + 
    theme_light() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
  
  print(gg)
}


```

(This might look better rotated through 90 degrees)

### Recommended stimuli

We examine item performance in terms of response accuracy (hitrate), response times, bracketing rates (i.e. the proportion of participants for whom the event occurs between their 'after' and 'before' dates), and bracket widths (i.e. the distance between their 'after' and 'before' dates).

The intuitions about these measures are as follows:  

* accuracy

  * a high hit rate suggests that the answer is quite obvious; many participants 'just know' the answer  
  
  * bracketing widths on questions with high hit rates, and which a participant gets correct, may be indicative of a base level of confidence  
  
* response times  

  * short response times can suggest extremes; either participants find the question very easy, or they know rapidly that they cannot sensibly guess at the answer
  
  * long response times and high accuracy may indicate looking up the answers  
  
* bracketing rates  

  * high bracketing rates indicate participants have a good sense of the general period in which something happened
  
  * most usefully interpreted in conjunction with bracket widths
  
* bracket widths

  * narrow bracket widths suggest that the period in which a date might occur is well known.
  
  * in isolation, bracket widths are the best indicator of the difficulty of a question
  
Combining these, the best questions will have moderate response times and bracket widths, will have high bracketing rates, and will have accuracy rates which are not too high. 

We can aim for something like: 

* the true answer should be closer to the mean estimate than either the mean after or mean before date

* <= 33% accuracy

* \>= 50% bracketing rate

* bracket widths and response times in the middle 50% of responses

```{r}

DE.qs <- DE.iW

DE.qs$error.a <- sapply(1:nrow(DE.qs), function(x) 
  abs(mean(DE$after[DE$qPrompt == DE.qs$q[x]] - DE.qs$target[x])))
DE.qs$error.b <- sapply(1:nrow(DE.qs), function(x) 
  abs(mean(DE$before[DE$qPrompt == DE.qs$q[x]] - DE.qs$target[x])))

DE.qs$include <- rep(T, nrow(DE.qs))

DE.qs$include[DE.qs$error.m > DE.qs$error.a] <- "afterCloser"
DE.qs$include[DE.qs$include == T & DE.qs$error.m > DE.qs$error.b] <- "beforeCloser"

DE.qs$include[DE.qs$hit.m > .33] <- "accuracyTooHigh"
DE.qs$include[DE.qs$include == T & DE.qs$bracketed.m <= .50] <- "bracketRateTooLow"
x <- quantile(DE.qs$timeA.m[DE.qs$include == T])
y <- quantile(DE.qs$bWidth.m[DE.qs$include == T])
DE.qs$include[DE.qs$include == T & DE.qs$bWidth.m < y[2]] <- paste0("bracketWidth<", 
                                                                    round(y[2],2))
DE.qs$include[DE.qs$include == T & DE.qs$bWidth.m > y[4]] <- paste0("bracketWidth>", 
                                                                    round(y[4],2))
DE.qs$include[DE.qs$include == T & DE.qs$timeA.m < x[2]] <- paste0("rt<", 
                                                                   round(x[2],2))
DE.qs$include[DE.qs$include == T & DE.qs$timeA.m > x[4]] <- paste0("rt>", 
                                                                   round(x[4],2))

kable(table(DE.qs$include))

# DE.qs <- DE.qs[DE.qs$include == T, ]

```

### Individual item plots

```{r}

for (q in unique(DE.qs$q)) {
  tmp <- DE[DE$qPrompt == q, ]
  
  if (nrow(tmp) < 2)
    next()
  
  title <- paste0("(", nrow(tmp), ") ", tmp$qPrompt[1])
  
  tmp.gg <- ggplot(tmp) +
    # correct answer - dashed line
    geom_vline(aes(xintercept = tmp$qTarget[1], linetype = "dashed")) +
    # density of after/estimate/before
    geom_density(aes(x = after, fill = "after"), color = NA, alpha = 0.5) +
    geom_density(aes(x = before, fill = "before"), color = NA, alpha = 0.5) +
    geom_density(aes(x = estimate,  fill = "estimate"), color = NA, alpha = 0.75) +
    # mean after/estimate/before with 95% CI
    geom_point(aes(x = mean(estimate), y = .18, color = "estimate")) +
    geom_errorbarh(aes(xmin = ciMean(estimate)[1], xmax = ciMean(estimate)[2], 
                       y = .18, color = "estimate")) +
    geom_point(aes(x = mean(after), y = .17, color = "after")) +
    geom_errorbarh(aes(xmin = ciMean(after)[1], xmax = ciMean(after)[2], 
                       y = .17, color = "after")) +
    geom_point(aes(x = mean(before), y = .19, color = "before")) +
    geom_errorbarh(aes(xmin = ciMean(before)[1], xmax = ciMean(before)[2], 
                       y = .19, color = "before")) +
    # labels etc.
    scale_linetype_identity(name = "", labels = c("actual date"), guide = "legend") +
    scale_fill_discrete(name = "answer density") +
    scale_color_discrete(name = "answer +/- 95% confidence") +
    scale_x_continuous(limits = c(1800, 2000)) +
    scale_y_continuous(limits = c(0, .2)) +
    labs(title = title, x = "year") +
    guides(linetype = guide_legend(order = 1)) + 
    theme_light() 
    
  print(tmp.gg)
}

```

